{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4fcc29",
   "metadata": {
    "id": "da4fcc29"
   },
   "source": [
    "\n",
    "# IoT-based Multimodal Pipeline for Early Mastitis Detection\n",
    "This notebook provides a robust, leak-safe and energy-aware pipeline:\n",
    "- **Tabular model** on clinical ground truth (CSV)\n",
    "- **Imaging model** (frozen EfficientNet features + LR) on image labels\n",
    "- **Cross-modal bridge** (tab→image embeddings) enabling fusion even when cohorts are not perfectly aligned\n",
    "- **Fail-safe fusion** with proper clinical evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175e241",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5175e241",
    "outputId": "b9efd3a3-4bae-45e9-a41b-053587f9733b"
   },
   "outputs": [],
   "source": [
    "# ===== 1) Configuration & Paths =====\n",
    "# Purpose: centralise environment detection (Colab vs local), define base paths for data and images,\n",
    "# and set global runtime options (seeds, batch size, GPU toggle). Keeping this in one place makes the\n",
    "# rest of the notebook easier to audit and reproduce.\n",
    "\n",
    "import os, random, json, re, glob, math, shutil, time, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Detect whether we are running inside Google Colab.\n",
    "# If true, we mount Drive to access project data stored in MyDrive.\n",
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Mount Google Drive for data I/O (figures, CSVs, image folders).\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    BASE_DRIVE = \"/content/drive/MyDrive\"\n",
    "else:\n",
    "    # Fallback to the current working directory when running locally.\n",
    "    BASE_DRIVE = os.getcwd()\n",
    "\n",
    "# Define project-level directories and file paths.\n",
    "# Note: do not rename these without updating downstream cells that rely on them.\n",
    "PROJECT_DIR = os.path.join(BASE_DRIVE, \"Mastitis_illness_cow\", \"datasets\")\n",
    "TABULAR_CSV_PATH = os.path.join(PROJECT_DIR, \"clinical_mastitis_cows_version1.csv\")\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"images\")\n",
    "LABEL_DIR = os.path.join(PROJECT_DIR, \"labels\")\n",
    "\n",
    "# Runtime knobs for the imaging branch. Toggle GPU if a CUDA device is available.\n",
    "USE_GPU_FOR_IMAGE_MODEL = True\n",
    "BATCH_SIZE_IMAGE = 32\n",
    "\n",
    "# Global reproducibility seed. Keep fixed for consistent splits and initialisations.\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "def seed_all_torch(seed=42):\n",
    "    \"\"\"\n",
    "    Set PyTorch-specific seeds and deterministic flags when available.\n",
    "    This stabilises results across runs on machines with CUDA/CuDNN.\n",
    "    Safe no-op if PyTorch is not installed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    except Exception:\n",
    "        # Silently continue if torch is unavailable in this environment.\n",
    "        pass\n",
    "\n",
    "# Apply torch seeding (if PyTorch is present); does not affect environments without torch.\n",
    "seed_all_torch(SEED)\n",
    "\n",
    "# Quick visibility checks so that path issues are caught early during runtime.\n",
    "print(\"IN_COLAB:\", IN_COLAB)\n",
    "print(\"BASE_DRIVE:\", BASE_DRIVE)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
    "print(\"CSV exists:\", os.path.exists(TABULAR_CSV_PATH))\n",
    "print(\"IMAGE_DIR exists:\", os.path.exists(IMAGE_DIR))\n",
    "print(\"LABEL_DIR exists:\", os.path.exists(LABEL_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b4370",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "105b4370",
    "outputId": "5fd02b8a-69c8-468f-ff8e-852713d291cd"
   },
   "outputs": [],
   "source": [
    "# ===== 2) ADAPTIVE TASK: RISK_NEXT (visits) → RISK_WITHIN (days) → fallback D_proximity (visit-level) =====\n",
    "# Purpose: derive a robust visit-level target (risk_next) using a progressive strategy.\n",
    "# 1) Prefer a “next-K visits” definition if it yields enough positives across visits and cows.\n",
    "# 2) Otherwise try a “within-H days” definition (time-based risk window).\n",
    "# 3) If neither yields sufficient positives, fall back to a proximity-based proxy (last K visits before onset).\n",
    "\n",
    "import os, re, glob, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Utilities ---------------------------------------------------------------\n",
    "def digits_only(x: str) -> str:\n",
    "    \"\"\"Keep only digits from an identifier; return 'nan' for missing values.\"\"\"\n",
    "    if pd.isna(x): return \"nan\"\n",
    "    return re.sub(r\"\\D\", \"\", str(x))\n",
    "\n",
    "def strip_leading_zeros(x: str) -> str:\n",
    "    \"\"\"Remove leading zeros from a digit string; return 'nan' for empty/missing.\"\"\"\n",
    "    if x in (\"nan\", \"\", None): return \"nan\"\n",
    "    s = x.lstrip(\"0\"); return s if s else \"0\"\n",
    "\n",
    "def resolve_tabular_path(filename_default=\"clinical_mastitis_cows_version1.csv\") -> str:\n",
    "    \"\"\"\n",
    "    Locate the tabular CSV by checking:\n",
    "    1) the global TABULAR_CSV_PATH (if defined),\n",
    "    2) /mnt/data,\n",
    "    3) current working directory,\n",
    "    4) recursive search under PROJECT_DIR.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        TABULAR_CSV_PATH if 'TABULAR_CSV_PATH' in globals() else None,\n",
    "        os.path.join('/mnt/data', filename_default),\n",
    "        os.path.join(os.getcwd(), filename_default),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c and os.path.exists(c):\n",
    "            print(\"Using tabular CSV at:\", c); return c\n",
    "    for p in glob.glob(os.path.join(PROJECT_DIR, \"**\", filename_default), recursive=True):\n",
    "        if os.path.exists(p):\n",
    "            print(\"Found tabular CSV via recursive search at:\", p); return p\n",
    "    raise FileNotFoundError(\"Cannot locate tabular CSV. Check PROJECT_DIR/paths.\")\n",
    "\n",
    "# --- Hyperparameters and minimum thresholds ---------------------------------\n",
    "K_LIST   = [3, 5, 7, 10, 14, 21, 30]   # lookahead in number of future visits\n",
    "H_LIST   = [3, 5, 7, 10, 14, 21, 30]   # lookahead horizon in days\n",
    "MIN_POS_VISITS = 50                    # minimum acceptable count of positive visits\n",
    "MIN_POS_COWS   = 30                    # minimum acceptable count of cows with ≥1 positive visit\n",
    "\n",
    "# --- Load tabular data -------------------------------------------------------\n",
    "TABULAR_CSV_RESOLVED = resolve_tabular_path()\n",
    "tab = pd.read_csv(TABULAR_CSV_RESOLVED)\n",
    "print(\"[Tabular] Columns:\", list(tab.columns))\n",
    "\n",
    "# Key columns (auto-detected based on common names).\n",
    "COW_ID_COL = next((c for c in [\"Cow_ID\",\"cow_id\",\"CowID\",\"animal_id\",\"Animal_ID\",\"subject_id\",\"id\",\"ID\"] if c in tab.columns), None)\n",
    "TIME_COL   = next((c for c in [\"Day\",\"day\",\"time\",\"Time\",\"Days\",\"days\"] if c in tab.columns), None)\n",
    "RAW_TARGET = next((c for c in [\"class1\",\"Class1\",\"Label\",\"label\",\"mastitis\",\"status\",\"target\",\"class\",\"disease\",\"outcome\",\"y\"] if c in tab.columns), None)\n",
    "if COW_ID_COL is None: raise KeyError(\"Cow ID column not found.\")\n",
    "if TIME_COL   is None: raise KeyError(\"Time column (e.g., 'Day') not found.\")\n",
    "if RAW_TARGET is None: raise KeyError(\"Binary target column (e.g., 'class1') not found.\")\n",
    "\n",
    "# Normalise IDs and cast types for time and labels.\n",
    "tab[\"Cow_ID_norm\"]  = tab[COW_ID_COL].astype(str).map(digits_only).map(strip_leading_zeros)\n",
    "tab[\"Cow_ID_match\"] = tab[\"Cow_ID_norm\"]\n",
    "KEY = \"Cow_ID_match\"\n",
    "print(\n",
    "    \"[CowID] Tabular Cow_ID normalised. Unique (non-nan):\",\n",
    "    tab[\"Cow_ID_norm\"].replace(\"nan\", np.nan).dropna().nunique()\n",
    ")\n",
    "\n",
    "tab[TIME_COL]   = pd.to_numeric(tab[TIME_COL], errors=\"coerce\")\n",
    "tab[RAW_TARGET] = pd.to_numeric(tab[RAW_TARGET], errors=\"coerce\").fillna(0).astype(int)\n",
    "tab = tab[tab[KEY].ne(\"nan\")].copy().sort_values([KEY, TIME_COL]).reset_index(drop=True)\n",
    "\n",
    "# ---------- Visit-level label constructors ----------------------------------\n",
    "def build_risk_nextK_visits(df, K=3, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET):\n",
    "    \"\"\"\n",
    "    Visit-based risk: label a visit as 1 if any of the next K visits is positive.\n",
    "    Exclude visits that are already positive at time t (set to -1 and filtered out).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for cow, g in df.groupby(key, sort=False):\n",
    "        g = g.sort_values(tcol, na_position=\"last\").reset_index(drop=True)\n",
    "        y = g[ycol].values.astype(int); n = len(g)\n",
    "        y_next = np.full(n, -1, dtype=int)  # -1 = invalid input (already positive at t)\n",
    "        for t in range(n):\n",
    "            if y[t] == 1:\n",
    "                y_next[t] = -1\n",
    "            else:\n",
    "                if t == n - 1:\n",
    "                    y_next[t] = 0\n",
    "                else:\n",
    "                    t2 = min(n - 1, t + K)\n",
    "                    y_next[t] = int((y[t+1:t2+1] == 1).any())\n",
    "        g2 = g.copy(); g2[\"risk_next\"] = y_next\n",
    "        rows.append(g2)\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    out = out[out[\"risk_next\"] != -1].copy()\n",
    "    out[\"risk_next\"] = out[\"risk_next\"].astype(int)\n",
    "    return out\n",
    "\n",
    "def build_risk_withinH_days(df, H=7, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET):\n",
    "    \"\"\"\n",
    "    Time-based risk: label a visit as 1 if a positive event occurs within H days after this visit.\n",
    "    Exclude visits that are already positive at time t (set to -1 and filtered out).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for cow, g in df.groupby(key, sort=False):\n",
    "        g = g.sort_values(tcol, na_position=\"last\").reset_index(drop=True)\n",
    "        y = g[ycol].values.astype(int); tvals = g[tcol].values.astype(float); n = len(g)\n",
    "        rn = np.zeros(n, dtype=int)\n",
    "        for t in range(n):\n",
    "            if y[t] == 1:\n",
    "                rn[t] = -1  # already positive at this visit → not a valid input\n",
    "            else:\n",
    "                # Is there a future positive with Δday in (0..H]?\n",
    "                future_idx = np.where((tvals > tvals[t]) & (tvals - tvals[t] <= H))[0]\n",
    "                rn[t] = int(any(y[j] == 1 for j in future_idx))\n",
    "        g2 = g.copy(); g2[\"risk_next\"] = rn\n",
    "        rows.append(g2)\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    out = out[out[\"risk_next\"] != -1].copy()\n",
    "    out[\"risk_next\"] = out[\"risk_next\"].astype(int)\n",
    "    return out\n",
    "\n",
    "def build_proximity_visit_level(df, K=3, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET):\n",
    "    \"\"\"\n",
    "    Fallback proxy: mark as 1 the last K visits before the first onset,\n",
    "    **including** the onset visit itself (i.e., a proximity-based signal).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for cow, g in df.groupby(key, sort=False):\n",
    "        g = g.sort_values(tcol, na_position=\"last\").reset_index(drop=True)\n",
    "        y = g[ycol].values.astype(int); n = len(g)\n",
    "        rn = np.zeros(n, dtype=int)\n",
    "        pos = np.where(y == 1)[0]\n",
    "        if len(pos) > 0:\n",
    "            i0 = int(pos[0])\n",
    "            j0 = max(0, i0 - (K - 1))\n",
    "            rn[j0:i0+1] = 1  # onset included\n",
    "        g2 = g.copy(); g2[\"risk_next\"] = rn\n",
    "        rows.append(g2)\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    # Note: we deliberately do not exclude positive visits here; this is a proximity proxy at visit-level.\n",
    "    out[\"risk_next\"] = out[\"risk_next\"].astype(int)\n",
    "    return out\n",
    "\n",
    "# ---------- Adaptive search for the best label definition --------------------\n",
    "chosen = None\n",
    "\n",
    "# 1) Next-K visits\n",
    "for K in K_LIST:\n",
    "    cand = build_risk_nextK_visits(tab, K=K, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET)\n",
    "    pos_v = int((cand[\"risk_next\"] == 1).sum())\n",
    "    pos_c = int(cand.groupby(KEY)[\"risk_next\"].max().sum())\n",
    "    print(f\"[TRY] RISK_NEXT@{K}visits | visits pos={pos_v} | cows pos={pos_c}\")\n",
    "    if pos_v >= MIN_POS_VISITS and pos_c >= MIN_POS_COWS:\n",
    "        chosen = (\"RISK_NEXT_visits\", K, cand); break\n",
    "\n",
    "# 2) Within-H days\n",
    "if chosen is None:\n",
    "    for H in H_LIST:\n",
    "        cand = build_risk_withinH_days(tab, H=H, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET)\n",
    "        pos_v = int((cand[\"risk_next\"] == 1).sum())\n",
    "        pos_c = int(cand.groupby(KEY)[\"risk_next\"].max().sum())\n",
    "        print(f\"[TRY] RISK_WITHIN@{H}days | visits pos={pos_v} | cows pos={pos_c}\")\n",
    "        if pos_v >= MIN_POS_VISITS and pos_c >= MIN_POS_COWS:\n",
    "            chosen = (\"RISK_WITHIN_days\", H, cand); break\n",
    "\n",
    "# 3) Fallback proximity (visit-level)\n",
    "if chosen is None:\n",
    "    K_fallback = 3\n",
    "    cand = build_proximity_visit_level(tab, K=K_fallback, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET)\n",
    "    pos_v = int((cand[\"risk_next\"] == 1).sum())\n",
    "    pos_c = int(cand.groupby(KEY)[\"risk_next\"].max().sum())\n",
    "    print(f\"[FALLBACK] PROXIMITY@{K_fallback}vis | visits pos={pos_v} | cows pos={pos_c}\")\n",
    "    chosen = (\"PROXIMITY_visits\", K_fallback, cand)\n",
    "\n",
    "TASK_MODE, HYPER, df_risk = chosen\n",
    "print(\n",
    "    f\"[CHOSEN] {TASK_MODE} param={HYPER} | visits pos={int((df_risk['risk_next']==1).sum())} \"\n",
    "    f\"| cows pos={int(df_risk.groupby(KEY)['risk_next'].max().sum())} | N={len(df_risk)}\"\n",
    ")\n",
    "\n",
    "# ---------- Leak-safe split by cow ------------------------------------------\n",
    "# We split by cow so the same animal never appears across train/val/test,\n",
    "# preventing identity leakage and overly optimistic metrics.\n",
    "cow_any = df_risk.groupby(KEY)[\"risk_next\"].max().astype(int)\n",
    "all_cows = np.array(sorted(cow_any.index.astype(str)))\n",
    "y_cows   = cow_any.reindex(all_cows).values\n",
    "\n",
    "if len(np.unique(y_cows)) < 2:\n",
    "    print(\"[WARN] Per-cow single class. Using non-stratified split.\")\n",
    "    tr_c, te_c = train_test_split(all_cows, test_size=0.20, random_state=42)\n",
    "else:\n",
    "    tr_c, te_c = train_test_split(all_cows, test_size=0.20, stratify=y_cows, random_state=42)\n",
    "\n",
    "mask_tv = np.isin(all_cows, tr_c)\n",
    "tv_cows = all_cows[mask_tv]\n",
    "tv_y    = cow_any.reindex(tv_cows).values\n",
    "if len(np.unique(tv_y)) < 2:\n",
    "    tr_cows, val_cows = train_test_split(tv_cows, test_size=0.25, random_state=42)\n",
    "else:\n",
    "    tr_cows, val_cows = train_test_split(tv_cows, test_size=0.25, stratify=tv_y, random_state=42)\n",
    "\n",
    "print(f\"[Split] Train cows: {len(tr_cows)} | Val cows: {len(val_cows)} | Test cows: {len(te_c)}\")\n",
    "print(f\"[READY] TASK_MODE='{TASK_MODE}' | label='risk_next' | hyper={HYPER}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RiMFt20wcEjE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RiMFt20wcEjE",
    "outputId": "fdf274e3-e702-4102-85fd-e78dfafc5525"
   },
   "outputs": [],
   "source": [
    "# ===== 2.5) Visit-level feature engineering (leak-safe) & cow-aligned splits =====\n",
    "# Purpose: build leakage-safe visit-level features, strictly separated per split (train/val/test),\n",
    "# while keeping cows disjoint across splits. We also include robust key/target de-duplication.\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --------- Context and fallback split ----------------------------------------\n",
    "assert 'tab' in globals(), \"Run Cell 2 first: the DataFrame 'tab' is missing.\"\n",
    "\n",
    "KEY = \"Cow_ID_match\"\n",
    "YCOL_CANDIDATES = [\"risk_next\", \"early\", \"class1\", \"Label\", \"label\"]\n",
    "YCOL = next((c for c in YCOL_CANDIDATES if c in tab.columns), None)\n",
    "if YCOL is None:\n",
    "    raise KeyError(f\"No target column found in 'tab'. Expected one of: {YCOL_CANDIDATES}\")\n",
    "\n",
    "if KEY not in tab.columns:\n",
    "    raise KeyError(f\"Key {KEY} missing in 'tab'; please verify Cell 2.\")\n",
    "\n",
    "# --------- Robust utilities: de-duplicate target and key ---------------------\n",
    "def coerce_and_dedup_target(df: pd.DataFrame, ycol: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure a single integer target column ycol exists in df.\n",
    "    - If missing, create it as zeros.\n",
    "    - If multiple columns with the same name exist (rare in merged frames),\n",
    "      take the row-wise max of their numeric casts.\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if c == ycol]\n",
    "    if len(cols) == 0:\n",
    "        df[ycol] = 0\n",
    "        return df\n",
    "    if len(cols) == 1:\n",
    "        df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\").fillna(0).astype(int)\n",
    "        return df\n",
    "    comb = df[cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0).max(axis=1).astype(int)\n",
    "    df = df.drop(columns=cols, errors=\"ignore\")\n",
    "    df[ycol] = comb\n",
    "    return df\n",
    "\n",
    "def coerce_and_dedup_key(df: pd.DataFrame, key: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure a single key column exists in df.\n",
    "    - If multiple duplicate-named columns appear, keep the first non-NaN per row.\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if c == key]\n",
    "    if len(cols) == 0:\n",
    "        raise KeyError(f\"Key {key} absent after preprocessing.\")\n",
    "    if len(cols) == 1:\n",
    "        df[key] = df[key].astype(str)\n",
    "        return df\n",
    "    # Combine by taking the first non-NaN per row.\n",
    "    tmp = (df[cols].astype(str).replace({\"nan\": np.nan, \"None\": np.nan}))\n",
    "    comb = tmp.bfill(axis=1).iloc[:, 0].astype(str)\n",
    "    df = df.drop(columns=cols, errors=\"ignore\")\n",
    "    df[key] = comb\n",
    "    return df\n",
    "\n",
    "# Initial de-duplication on 'tab'\n",
    "tab = coerce_and_dedup_key(tab, KEY)\n",
    "tab = coerce_and_dedup_target(tab, YCOL)\n",
    "\n",
    "# If tr_cows/val_cows/test_cows do NOT exist, reconstruct them now (leak-safe group split)\n",
    "if not all(k in globals() for k in [\"tr_cows\",\"val_cows\",\"test_cows\"]):\n",
    "    print(\"[2.5 Fallback] Rebuilding cow-based splits…\")\n",
    "    cow_y = tab.groupby(KEY)[YCOL].max().astype(int)\n",
    "    all_cows = np.array(sorted(cow_y.index.astype(str)))\n",
    "    if cow_y.nunique() < 2:\n",
    "        tr_all, te_all = train_test_split(all_cows, test_size=0.20, random_state=42, shuffle=True)\n",
    "    else:\n",
    "        tr_all, te_all = train_test_split(\n",
    "            all_cows, test_size=0.20,\n",
    "            stratify=cow_y.reindex(all_cows).values, random_state=42\n",
    "        )\n",
    "    tv_labels = cow_y.reindex(tr_all).values\n",
    "    if len(np.unique(tv_labels)) < 2:\n",
    "        tr_cows, val_cows = train_test_split(tr_all, test_size=0.25, random_state=42, shuffle=True)\n",
    "    else:\n",
    "        tr_cows, val_cows = train_test_split(\n",
    "            tr_all, test_size=0.25, stratify=tv_labels, random_state=42\n",
    "        )\n",
    "    test_cows = te_all\n",
    "    print(f\"[2.5 Fallback] Train cows: {len(tr_cows)} | Val cows: {len(val_cows)} | Test cows: {len(test_cows)}\")\n",
    "\n",
    "# --------- Visit-ordered base copy ------------------------------------------\n",
    "base = tab.copy()\n",
    "if \"Day\" in base.columns:\n",
    "    base = base.sort_values([KEY, \"Day\"]).reset_index(drop=True)\n",
    "else:\n",
    "    base = (\n",
    "        base.sort_values([KEY])\n",
    "            .assign(_visit_idx = base.groupby(KEY).cumcount())\n",
    "            .sort_values([KEY, \"_visit_idx\"])\n",
    "            .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# --------- Select numeric columns for feature engineering --------------------\n",
    "exclude_cols = {KEY, YCOL, \"Cow_ID_norm\", \"onset_day\", \"Breed\", \"Previous_Mastits_status\"}\n",
    "num_cols_all = (\n",
    "    base.drop(columns=[c for c in exclude_cols if c in base.columns], errors=\"ignore\")\n",
    "        .select_dtypes(include=[np.number])\n",
    "        .columns.tolist()\n",
    ")\n",
    "if len(num_cols_all) == 0:\n",
    "    raise RuntimeError(\"No numeric columns available for feature engineering.\")\n",
    "\n",
    "# --------- Utility functions -------------------------------------------------\n",
    "def split_by_cows(df, cows):\n",
    "    \"\"\"Filter df to keep only rows belonging to the provided cow IDs.\"\"\"\n",
    "    return df[df[KEY].astype(str).isin(set(map(str, cows)))].reset_index(drop=True)\n",
    "\n",
    "def add_time_features(df: pd.DataFrame, num_cols) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build simple per-cow temporal features (leak-safe):\n",
    "    - lag1 for each numeric variable,\n",
    "    - rolling means over 3 and 5 visits,\n",
    "    - first differences for raw and rolling means,\n",
    "    - per-cow expanding z-score (normalising by expanding mean/std).\n",
    "    Missing values introduced by lags/rolling are filled with 0 for robustness.\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    d = coerce_and_dedup_key(d, KEY)\n",
    "    if \"Day\" in d.columns:\n",
    "        d = d.sort_values([KEY, \"Day\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        if \"_visit_idx\" not in d.columns:\n",
    "            d[\"_visit_idx\"] = d.groupby(KEY).cumcount()\n",
    "        d = d.sort_values([KEY, \"_visit_idx\"]).reset_index(drop=True)\n",
    "\n",
    "    for c in num_cols:\n",
    "        grp = d.groupby(KEY)[c]\n",
    "        d[f\"{c}_lag1\"]    = grp.shift(1)\n",
    "\n",
    "        r3 = grp.rolling(3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        r5 = grp.rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        d[f\"{c}_r3_mean\"] = r3\n",
    "        d[f\"{c}_r5_mean\"] = r5\n",
    "\n",
    "        d[f\"{c}_d1\"]      = grp.diff(1)\n",
    "        d[f\"{c}_r3_d1\"]   = d[f\"{c}_r3_mean\"].groupby(d[KEY]).diff(1)\n",
    "        d[f\"{c}_r5_d1\"]   = d[f\"{c}_r5_mean\"].groupby(d[KEY]).diff(1)\n",
    "\n",
    "        exp_mean = grp.expanding().mean().reset_index(level=0, drop=True)\n",
    "        exp_std  = grp.expanding().std().reset_index(level=0, drop=True).replace(0, np.nan)\n",
    "        z = (d[c] - exp_mean) / exp_std\n",
    "        d[f\"{c}_z_cow\"] = z.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    fe_cols = [c for c in d.columns if c not in df.columns]\n",
    "    d[fe_cols] = d[fe_cols].fillna(0)\n",
    "    # Safety: ensure the key column is clean and unique after feature creation.\n",
    "    d = coerce_and_dedup_key(d, KEY)\n",
    "    return d\n",
    "\n",
    "def take_last_k(df, k=6):\n",
    "    \"\"\"\n",
    "    Keep only the last k visits per cow (recent-history focus).\n",
    "    If 'Day' is absent, use a synthetic visit index to define ordering.\n",
    "    \"\"\"\n",
    "    d = coerce_and_dedup_key(df.copy(), KEY)\n",
    "    if \"Day\" in d.columns:\n",
    "        d[\"_rank_last\"] = d.groupby(KEY)[\"Day\"].rank(method=\"first\", ascending=False)\n",
    "    else:\n",
    "        if \"_visit_idx\" not in d.columns:\n",
    "            d[\"_visit_idx\"] = d.groupby(KEY).cumcount()\n",
    "        d[\"_rank_last\"] = d.groupby(KEY)[\"_visit_idx\"].rank(method=\"first\", ascending=False)\n",
    "    out = d[d[\"_rank_last\"] <= k].drop(columns=[\"_rank_last\"])\n",
    "    return coerce_and_dedup_key(out.reset_index(drop=True), KEY)\n",
    "\n",
    "def drop_degenerate(train_df, val_df, test_df, key, ycol):\n",
    "    \"\"\"\n",
    "    Remove degenerate feature columns (all-NaN or zero-variance on train).\n",
    "    Keep only numeric predictors plus key and target; ensure final de-duplication.\n",
    "    Returns filtered train/val/test and the list of dropped columns.\n",
    "    \"\"\"\n",
    "    # Ensure exactly one key/target column each.\n",
    "    train_df = coerce_and_dedup_key(coerce_and_dedup_target(train_df, ycol), key)\n",
    "    val_df   = coerce_and_dedup_key(coerce_and_dedup_target(val_df,   ycol), key)\n",
    "    test_df  = coerce_and_dedup_key(coerce_and_dedup_target(test_df,  ycol), key)\n",
    "\n",
    "    keep = []\n",
    "    for c in train_df.columns:\n",
    "        if c in {key, ycol, \"Day\", \"_visit_idx\", \"Cow_ID_norm\"}:\n",
    "            keep.append(c); continue\n",
    "        if str(train_df[c].dtype).startswith((\"float\",\"int\")):\n",
    "            col = train_df[c]\n",
    "            if col.isna().all():                 # all NaN\n",
    "                continue\n",
    "            if col.nunique(dropna=True) <= 1:    # zero variance\n",
    "                continue\n",
    "            keep.append(c)\n",
    "    tr2 = train_df[[k for k in keep if k in train_df.columns] + [key, ycol]].copy()\n",
    "    va2 = val_df[[k for k in keep if k in val_df.columns] + [key, ycol]].copy()\n",
    "    te2 = test_df[[k for k in keep if k in test_df.columns] + [key, ycol]].copy()\n",
    "\n",
    "    # Final de-duplication for safety.\n",
    "    tr2 = coerce_and_dedup_key(coerce_and_dedup_target(tr2, ycol), key)\n",
    "    va2 = coerce_and_dedup_key(coerce_and_dedup_target(va2, ycol), key)\n",
    "    te2 = coerce_and_dedup_key(coerce_and_dedup_target(te2, ycol), key)\n",
    "\n",
    "    dropped = sorted(list(set(train_df.columns) - set(tr2.columns)))\n",
    "    return tr2, va2, te2, dropped\n",
    "\n",
    "def safe_target_series(df: pd.DataFrame, ycol: str) -> pd.Series:\n",
    "    \"\"\"Return a single integer Series for the target, consolidating multi-columns if needed.\"\"\"\n",
    "    obj = df[ycol]\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        y = obj.apply(pd.to_numeric, errors=\"coerce\").fillna(0).max(axis=1)\n",
    "    else:\n",
    "        y = pd.to_numeric(obj, errors=\"coerce\").fillna(0)\n",
    "    return y.astype(int)\n",
    "\n",
    "def count_pos_visits(df, ycol):\n",
    "    \"\"\"Count visits labelled positive (1) using the safe target series.\"\"\"\n",
    "    y = safe_target_series(df, ycol)\n",
    "    return int((y == 1).sum())\n",
    "\n",
    "def count_pos_cows(df, key, ycol):\n",
    "    \"\"\"\n",
    "    Count cows with at least one positive visit.\n",
    "    Uses a single clean key column and the max over visits per cow.\n",
    "    \"\"\"\n",
    "    df = coerce_and_dedup_key(df.copy(), key)\n",
    "    y = safe_target_series(df, ycol)\n",
    "    per_cow = df.assign(__y=y).groupby(key)[\"__y\"].max()\n",
    "    return int(per_cow.sum())\n",
    "\n",
    "# --------- Split-specific (no-leak) feature engineering ---------------------\n",
    "train_raw = split_by_cows(base, tr_cows)\n",
    "val_raw   = split_by_cows(base, val_cows)\n",
    "test_raw  = split_by_cows(base, test_cows)\n",
    "\n",
    "# De-duplicate key/target BEFORE feature engineering.\n",
    "train_raw = coerce_and_dedup_key(coerce_and_dedup_target(train_raw, YCOL), KEY)\n",
    "val_raw   = coerce_and_dedup_key(coerce_and_dedup_target(val_raw,   YCOL), KEY)\n",
    "test_raw  = coerce_and_dedup_key(coerce_and_dedup_target(test_raw,  YCOL), KEY)\n",
    "\n",
    "train_fe = add_time_features(train_raw, num_cols_all)\n",
    "val_fe   = add_time_features(val_raw,   num_cols_all)\n",
    "test_fe  = add_time_features(test_raw,  num_cols_all)\n",
    "\n",
    "# --------- Keep only the last K visits per cow ------------------------------\n",
    "V_LAST = 6\n",
    "train_sel = take_last_k(train_fe, V_LAST)\n",
    "val_sel   = take_last_k(val_fe,   V_LAST)\n",
    "test_sel  = take_last_k(test_fe,  V_LAST)\n",
    "\n",
    "# De-duplicate key/target AGAIN (post FE/filters)\n",
    "train_sel = coerce_and_dedup_key(coerce_and_dedup_target(train_sel, YCOL), KEY)\n",
    "val_sel   = coerce_and_dedup_key(coerce_and_dedup_target(val_sel,   YCOL), KEY)\n",
    "test_sel  = coerce_and_dedup_key(coerce_and_dedup_target(test_sel,  YCOL), KEY)\n",
    "\n",
    "# --------- Drop degenerate columns ------------------------------------------\n",
    "train_df, val_df, test_df, dropped_cols = drop_degenerate(train_sel, val_sel, test_sel, KEY, YCOL)\n",
    "\n",
    "# --------- Diagnostics -------------------------------------------------------\n",
    "print(f\"[FE-visit] rows — TRAIN {train_df.shape} | VAL {val_df.shape} | TEST {test_df.shape}\")\n",
    "print(f\"[FE-visit] visits+ ({YCOL}) — TR {count_pos_visits(train_df,YCOL)} | VA {count_pos_visits(val_df,YCOL)} | TE {count_pos_visits(test_df,YCOL)}\")\n",
    "print(f\"[FE-visit] cows+ (max-per-cow over visits) — TR {count_pos_cows(train_df,KEY,YCOL)} | VA {count_pos_cows(val_df,KEY,YCOL)} | TE {count_pos_cows(test_df,KEY,YCOL)}\")\n",
    "feat_cnt = len([c for c in train_df.columns if c not in {KEY,YCOL,'Day','_visit_idx','Cow_ID_norm'}])\n",
    "print(f\"[READY] KEY='{KEY}' | YCOL='{YCOL}' | Num features={feat_cnt}\")\n",
    "if dropped_cols:\n",
    "    print(f\"[NOTE] Dropped degenerate columns: {dropped_cols[:10]}{' ...' if len(dropped_cols)>10 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61255a13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61255a13",
    "outputId": "d52fe817-0487-4268-a901-a9d9274879b6"
   },
   "outputs": [],
   "source": [
    "# ===== 3) Image Index Builder (YOLO-style or flat) — robust cow-id parsing =====\n",
    "# Builds df_images with: [stem, image_path, label, Cow_ID_raw, Cow_ID_norm, Cow_ID_match]\n",
    "# ID heuristics (priority order):\n",
    "#   1) FLIR#### in the filename stem (FLIR#### / FLIR-#### / FLIR_####)\n",
    "#   2) #### immediately before `_jpg` in the stem\n",
    "#   3) parent folder name ending with ####\n",
    "#   4) first 3–6 digit sequence in the stem (excluding any `.rf.*` suffix)\n",
    "# Fallback: use all digits from the stem and keep the last 4 as a guess.\n",
    "\n",
    "import os, re, glob, pandas as pd, numpy as np\n",
    "\n",
    "def discover_images_labels(image_dir, label_dir):\n",
    "    \"\"\"\n",
    "    Scan the image and label directories.\n",
    "    Returns:\n",
    "      images: list of image paths (common formats)\n",
    "      label_txts: YOLO .txt annotation files (if any)\n",
    "      label_csvs: optional CSV label files (if any)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\"):\n",
    "        images += glob.glob(os.path.join(image_dir, \"**\", ext), recursive=True)\n",
    "    images = sorted(list(set(images)))\n",
    "    label_txts = glob.glob(os.path.join(label_dir, \"**\", \"*.txt\"), recursive=True)\n",
    "    label_csvs = glob.glob(os.path.join(label_dir, \"**\", \"*.csv\"), recursive=True)\n",
    "    return images, label_txts, label_csvs\n",
    "\n",
    "def stem_of(path):\n",
    "    \"\"\"Return filename stem without extension.\"\"\"\n",
    "    b = os.path.basename(path); s, _ = os.path.splitext(b); return s\n",
    "\n",
    "def parse_yolo_label_file(txt_path):\n",
    "    \"\"\"\n",
    "    Parse a YOLO label file.\n",
    "    Convention used here: an image is considered positive (1) if any class ID != 0 is present.\n",
    "    Otherwise it is negative (0). If the file cannot be parsed, return 0 by default.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            lines = [ln.strip() for ln in f if ln.strip()]\n",
    "        if not lines: return 0\n",
    "        first_cols = [int(float(ln.split()[0])) for ln in lines if ln.split()]\n",
    "        return 1 if any(c != 0 for c in first_cols) else 0\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "# ---- Cow ID parsing helpers ----\n",
    "def digits_only(x: str) -> str:\n",
    "    \"\"\"Keep digits only; return 'nan' if value is missing.\"\"\"\n",
    "    if pd.isna(x): return \"nan\"\n",
    "    return re.sub(r\"\\D\", \"\", str(x))\n",
    "\n",
    "def strip_leading_zeros(x: str) -> str:\n",
    "    \"\"\"Remove leading zeros from a digit string; return 'nan' when empty.\"\"\"\n",
    "    if x in (\"nan\",\"\",None): return \"nan\"\n",
    "    s = x.lstrip(\"0\")\n",
    "    return s if s else \"0\"\n",
    "\n",
    "def infer_cow_id_from_path(path: str, stem: str) -> str:\n",
    "    \"\"\"\n",
    "    Try, in order:\n",
    "    1) FLIR#### or FLIR-#### or FLIR_#### in the stem\n",
    "    2) #### immediately before '_jpg'\n",
    "    3) parent folder ending with ####\n",
    "    4) first 3–6 digit sequence in the stem before any '.rf' segment\n",
    "    Fallback: take all digits from the stem-no-rf and keep the last 4 if length ≥ 3.\n",
    "    \"\"\"\n",
    "    st = stem\n",
    "\n",
    "    # 1) FLIR#### (3–6 digits)\n",
    "    m = re.search(r'FLIR[_-]?(\\d{3,6})', st, re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    # 2) #### before _jpg\n",
    "    m = re.search(r'(\\d{3,6})(?=_jpg\\b)', st, re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    # 3) parent folder\n",
    "    parent = os.path.basename(os.path.dirname(path))\n",
    "    m = re.search(r'(\\d{3,6})$', parent)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    # 4) first 3–6 digit sequence in the stem before the '.rf' segment (if present)\n",
    "    st_no_rf = st.split(\".rf\")[0]\n",
    "    m = re.search(r'(\\d{3,6})', st_no_rf)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    # Fallback: collect all digits, keep last 4 as a best-effort guess\n",
    "    d = digits_only(st_no_rf)\n",
    "    if len(d) >= 3:\n",
    "        return d[-4:]\n",
    "    return \"nan\"\n",
    "\n",
    "# ---- Scan -------------------------------------------------------------------\n",
    "images, yolo_txts, label_csvs = discover_images_labels(IMAGE_DIR, LABEL_DIR)\n",
    "\n",
    "# Map stem -> label\n",
    "label_map = {}\n",
    "\n",
    "# 1) YOLO .txt labels\n",
    "for p in yolo_txts:\n",
    "    st = stem_of(p)\n",
    "    label_map[st] = parse_yolo_label_file(p)\n",
    "\n",
    "# 2) Optional CSV labels (if present)\n",
    "for csvp in label_csvs:\n",
    "    try:\n",
    "        d = pd.read_csv(csvp)\n",
    "        cols_lower = {c.lower(): c for c in d.columns}\n",
    "        labcol = cols_lower.get(\"label\") or cols_lower.get(\"labels\")\n",
    "        namecol = None\n",
    "        for c in d.columns:\n",
    "            if any(k in c.lower() for k in [\"file\",\"image\",\"name\",\"stem\",\"path\"]):\n",
    "                namecol = c; break\n",
    "        if labcol and namecol:\n",
    "            for _, r in d.iterrows():\n",
    "                st = stem_of(str(r[namecol]))\n",
    "                label_map[st] = int(r[labcol])\n",
    "    except Exception as e:\n",
    "        print(\"[Labels][WARN] Could not parse CSV:\", csvp, \"err:\", e)\n",
    "\n",
    "rows = []\n",
    "for p in images:\n",
    "    st = stem_of(p)\n",
    "    lab = label_map.get(st, None)\n",
    "    if lab is None:\n",
    "        # Skip images without labels (we only index labelled samples)\n",
    "        continue\n",
    "    cow_raw = infer_cow_id_from_path(p, st)\n",
    "    rows.append({\"stem\": st, \"image_path\": p, \"label\": int(lab), \"Cow_ID_raw\": cow_raw})\n",
    "\n",
    "df_images = pd.DataFrame(rows)\n",
    "\n",
    "if len(df_images) == 0:\n",
    "    print(\"[Images][WARN] No labelled images found. Check folders or labels.\")\n",
    "else:\n",
    "    # Normalise IDs consistently with the tabular side (digits → strip leading zeros).\n",
    "    df_images[\"Cow_ID_norm\"] = df_images[\"Cow_ID_raw\"].map(digits_only).map(strip_leading_zeros)\n",
    "    df_images[\"Cow_ID_match\"] = df_images[\"Cow_ID_norm\"]\n",
    "\n",
    "    print(f\"[Images] df_images shape: {df_images.shape}\")\n",
    "    print(df_images.head(10))\n",
    "\n",
    "    # ---- Diagnostics: check plausible ID lengths (3–6) ----------------------\n",
    "    lengths = df_images[\"Cow_ID_match\"].replace(\"nan\", np.nan).dropna().map(len)\n",
    "    print(\"[Images][Diag] Cow_ID_match length stats:\", lengths.describe().to_dict())\n",
    "\n",
    "    # ---- Diagnostics: overlap with the tabular set (if available from Cell 2) ----\n",
    "    if 'df' in globals() and 'COW_ID_FOR_ALIGNMENT' in globals():\n",
    "        key = COW_ID_FOR_ALIGNMENT\n",
    "        tab_cows = set(df[key].astype(str).unique())\n",
    "        img_cows = set(df_images[\"Cow_ID_match\"].astype(str).unique())\n",
    "        inter = tab_cows & img_cows\n",
    "        # Class distribution for images within the overlap\n",
    "        pos_in_overlap = df_images[df_images[\"Cow_ID_match\"].isin(inter)][\"label\"].sum()\n",
    "        print(f\"[Overlap] Cows in TAB: {len(tab_cows)} | in IMG: {len(img_cows)} | intersection: {len(inter)} | image-positives in ∩: {pos_in_overlap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47ef33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312,
     "referenced_widgets": [
      "81e335e27c414781916fdc0f58f24e40",
      "914cb81fbe384ed4b3d94003879c5e4b",
      "69706d6fb6af4a4dbaa212d8bf12aab9",
      "ff783b51eb2f4dd891f767286e5efab9",
      "965ff089fed04c4b9e7daf2ed4b8bb8a",
      "761f8b9a5a60457eaf81e25c56666979",
      "f00ed51a7ba2432c836ecde7bcd64c1b",
      "877c2771634f47ee9d9ff094c31607e4",
      "fd7c8f7ef97d4d48b96cca2f0c5b1e3e",
      "caff951dfad746b78078436787ca2bef",
      "87088db11a7d4dca93af4f618aa3da60"
     ]
    },
    "id": "7c47ef33",
    "outputId": "5cbe4a65-6322-41a2-aa28-20e636ccf5a6"
   },
   "outputs": [],
   "source": [
    "# ===== 4) Imaging model — EfficientNet frozen + Augment + TTA + cow-stratified image-only split =====\n",
    "# Purpose: train an image-only branch using a frozen EfficientNet as a feature extractor.\n",
    "# We build a cow-stratified TRAIN/VAL/TEST split on images, apply data augmentation for TRAIN,\n",
    "# optionally oversample the minority class, and use Test-Time Augmentation (TTA) at evaluation.\n",
    "# Outputs include image-level metrics and per-cow aggregated probabilities.\n",
    "\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from PIL import Image\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.RandomState(SEED)\n",
    "IMG_SIZE = 224\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PIN_MEM = torch.cuda.is_available()\n",
    "\n",
    "# --------- Image split configuration -----------------------------------------\n",
    "IMG_TRAIN_FRAC = 0.60\n",
    "IMG_VAL_FRAC   = 0.20   # the remaining proportion goes to TEST\n",
    "K_VIEWS_TRAIN  = 5      # number of augmentation views per TRAIN image\n",
    "USE_OVERSAMPLING = True # oversample the minority class on TRAIN\n",
    "TTA_N_VIEWS    = 8      # number of TTA views for VAL/TEST (0 disables TTA)\n",
    "\n",
    "# --------- Transforms ---------------------------------------------------------\n",
    "train_tf = T.Compose([\n",
    "    T.RandomResizedCrop(IMG_SIZE, scale=(0.90, 1.00), ratio=(0.98, 1.02)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomAffine(degrees=7, translate=(0.03, 0.03), scale=(0.98, 1.02)),\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 0.8)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "eval_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# --------- Backbone feature extractor ----------------------------------------\n",
    "try:\n",
    "    import timm\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Please install timm: pip install timm\") from e\n",
    "\n",
    "class EffNetFeats(nn.Module):\n",
    "    \"\"\"\n",
    "    Frozen EfficientNet feature extractor: outputs global average pooled features (no classifier head).\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"efficientnet_b0\"):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool=\"avg\")\n",
    "        for p in self.backbone.parameters(): p.requires_grad = False\n",
    "    def forward(self, x): return self.backbone(x)\n",
    "\n",
    "feat_net = EffNetFeats(\"efficientnet_b0\").to(device).eval()\n",
    "\n",
    "# --------- Dataset ------------------------------------------------------------\n",
    "class ImageDatasetK(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset wrapper that can expose K augmented views per underlying image.\n",
    "    Labels are repeated accordingly; augmentation is controlled by the transform provided.\n",
    "    \"\"\"\n",
    "    def __init__(self, df_rows, transform, k_views=1):\n",
    "        self.paths  = df_rows[\"image_path\"].tolist()\n",
    "        self.labels = df_rows[\"label\"].astype(int).tolist()\n",
    "        self.tf = transform; self.k = max(1, int(k_views))\n",
    "    def __len__(self): return len(self.paths) * self.k\n",
    "    def __getitem__(self, idx):\n",
    "        i = idx % len(self.paths)\n",
    "        im = Image.open(self.paths[i]).convert(\"RGB\")\n",
    "        return self.tf(im), self.labels[i]\n",
    "\n",
    "def extract_features(dloader):\n",
    "    \"\"\"\n",
    "    Run the frozen backbone to obtain feature vectors and return (X, y).\n",
    "    This function is used for TRAIN/VAL/TEST loaders alike.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dloader:\n",
    "            xb = xb.to(device)\n",
    "            feats = feat_net(xb).cpu().numpy()\n",
    "            X.append(feats); y.append(np.array(yb))\n",
    "    X = np.vstack(X) if len(X) else np.zeros((0, feat_net.backbone.num_features))\n",
    "    y = np.concatenate(y) if len(y) else np.array([])\n",
    "    return X, y\n",
    "\n",
    "# --------- TTA predictor ------------------------------------------------------\n",
    "def predict_with_tta(paths, clf, n_views=TTA_N_VIEWS):\n",
    "    \"\"\"\n",
    "    Compute classifier probabilities with optional Test-Time Augmentation.\n",
    "    When n_views > 0, we recompute features multiple times with mild, label-preserving jitter,\n",
    "    and average the predicted probabilities across views.\n",
    "    \"\"\"\n",
    "    if n_views <= 0:\n",
    "        ds = ImageDatasetK(pd.DataFrame({\"image_path\":paths, \"label\":[0]*len(paths)}), eval_tf, k_views=1)\n",
    "        dl = DataLoader(ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=PIN_MEM)\n",
    "        X,_ = extract_features(dl)\n",
    "        return clf.predict_proba(X)[:,1]\n",
    "    # n augmented evaluation views (light augmentations)\n",
    "    aug_eval = T.Compose([\n",
    "        T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomAffine(degrees=3, translate=(0.01, 0.01), scale=(0.995,1.005)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ])\n",
    "    all_probs = []\n",
    "    for _ in range(n_views):\n",
    "        ds = ImageDatasetK(pd.DataFrame({\"image_path\":paths, \"label\":[0]*len(paths)}), aug_eval, k_views=1)\n",
    "        dl = DataLoader(ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=PIN_MEM)\n",
    "        X,_ = extract_features(dl)\n",
    "        all_probs.append(clf.predict_proba(X)[:,1])\n",
    "    return np.mean(np.vstack(all_probs), axis=0)\n",
    "\n",
    "# --------- Build an image-only, cow-stratified split -------------------------\n",
    "if 'df_images' not in globals() or len(df_images)==0:\n",
    "    print(\"No df_images available. Skipping image model.\")\n",
    "else:\n",
    "    KEY = \"Cow_ID_match\" if \"Cow_ID_match\" in df_images.columns else \"Cow_ID_norm\"\n",
    "    dfi = df_images.copy()\n",
    "    dfi[KEY] = dfi[KEY].astype(str)\n",
    "\n",
    "    cows = dfi.groupby(KEY)['label'].max().reset_index()\n",
    "    y_cow = cows['label'].values.astype(int)\n",
    "    C = cows[KEY].values.astype(str)\n",
    "\n",
    "    # Cow-level stratified split: TRAIN / (VAL+TEST)\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=(1.0-IMG_TRAIN_FRAC), random_state=SEED)\n",
    "    tr_idx, tmp_idx = next(sss1.split(C, y_cow))\n",
    "    C_tr, C_tmp = C[tr_idx], C[tmp_idx]; y_tr, y_tmp = y_cow[tr_idx], y_cow[tmp_idx]\n",
    "\n",
    "    # Split (VAL / TEST) from the temporary pool\n",
    "    test_frac_rel = (1.0 - IMG_TRAIN_FRAC - IMG_VAL_FRAC) / (1.0 - IMG_TRAIN_FRAC)\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=test_frac_rel, random_state=SEED)\n",
    "    va_idx_rel, te_idx_rel = next(sss2.split(C_tmp, y_tmp))\n",
    "    C_va, C_te = C_tmp[va_idx_rel], C_tmp[te_idx_rel]\n",
    "\n",
    "    tr_img = dfi[dfi[KEY].isin(set(C_tr))].reset_index(drop=True)\n",
    "    va_img = dfi[dfi[KEY].isin(set(C_va))].reset_index(drop=True)\n",
    "    te_img = dfi[dfi[KEY].isin(set(C_te))].reset_index(drop=True)\n",
    "\n",
    "    print(f\"[Imaging|Split image-only] COWS — TRAIN: {len(C_tr)} | VAL: {len(C_va)} | TEST: {len(C_te)}\")\n",
    "    print(f\"[Imaging|Split image-only] IMAGES — TRAIN: {len(tr_img)} | VAL: {len(va_img)} | TEST: {len(te_img)}\")\n",
    "    print(f\"[Imaging|Class balance] cows TRAIN pos={y_tr.sum()}/{len(y_tr)} | VAL pos={y_tmp[va_idx_rel].sum()}/{len(va_idx_rel)} | TEST pos={y_tmp[te_idx_rel].sum()}/{len(te_idx_rel)}\")\n",
    "\n",
    "    # --------- Dataset + (optional) oversampling ------------------------------\n",
    "    train_ds = ImageDatasetK(tr_img, transform=train_tf, k_views=K_VIEWS_TRAIN)\n",
    "    val_ds   = ImageDatasetK(va_img, transform=eval_tf,   k_views=1)\n",
    "    test_ds  = ImageDatasetK(te_img, transform=eval_tf,   k_views=1)\n",
    "\n",
    "    # Minority-class oversampling on TRAIN (at image level, replicated across K views)\n",
    "    y_train_base = tr_img[\"label\"].astype(int).values\n",
    "    class_counts = np.bincount(y_train_base) if y_train_base.size else np.array([0,0])\n",
    "    sampler = None\n",
    "    if USE_OVERSAMPLING and class_counts.size==2 and class_counts.min()>0:\n",
    "        class_weights = 1.0 / class_counts\n",
    "        # replicate weights for the K views\n",
    "        sample_weights = np.array([class_weights[y_train_base[i % len(y_train_base)]] for i in range(len(train_ds))])\n",
    "        sampler = WeightedRandomSampler(weights=torch.from_numpy(sample_weights).float(),\n",
    "                                        num_samples=len(train_ds), replacement=True)\n",
    "\n",
    "    # Dataloaders\n",
    "    tr_dl = DataLoader(train_ds, batch_size=32, shuffle=(sampler is None), sampler=sampler,\n",
    "                       num_workers=2, pin_memory=PIN_MEM)\n",
    "    va_dl = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=PIN_MEM)\n",
    "    te_dl = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=PIN_MEM) if len(te_img)>0 else None\n",
    "\n",
    "    # --------- LOG: how many effective samples does TRAIN see? ----------------\n",
    "    print(f\"[Imaging|Train loader] items={len(train_ds)}  (base_imgs={len(tr_img)} × K_VIEWS={K_VIEWS_TRAIN})\"\n",
    "          + (f\"  | oversampling=ON\" if sampler is not None else \"  | oversampling=OFF\"))\n",
    "\n",
    "    # --------- Feature extraction --------------------------------------------\n",
    "    def extract_all(dl):\n",
    "        X,y = extract_features(dl); return X,y\n",
    "    Xtr, ytr = extract_all(tr_dl)\n",
    "    Xva, yva = extract_all(va_dl)\n",
    "    if te_dl is not None:\n",
    "        Xte, yte = extract_all(te_dl)\n",
    "    else:\n",
    "        Xte, yte = np.zeros((0, Xtr.shape[1])) if Xtr.size else np.array([]), np.array([])\n",
    "\n",
    "    # MixUp in feature space (label-preserving interpolation in embedding space)\n",
    "    def feature_mixup(X, y, alpha=0.4, n_new=None, rng=rng):\n",
    "        if X.shape[0] < 2: return X, y\n",
    "        if n_new is None: n_new = X.shape[0] // 2\n",
    "        i1 = rng.randint(0, X.shape[0], n_new); i2 = rng.randint(0, X.shape[0], n_new)\n",
    "        lam = rng.beta(alpha, alpha, size=n_new)[:,None]\n",
    "        Xn = lam*X[i1] + (1-lam)*X[i2]\n",
    "        yn = ((lam[:,0]*y[i1] + (1-lam[:,0])*y[i2]) >= 0.5).astype(int)\n",
    "        return np.vstack([X, Xn]), np.concatenate([y, yn])\n",
    "\n",
    "    if Xtr.shape[0] > 0 and len(np.unique(ytr))>=2:\n",
    "        Xtr_aug, ytr_aug = feature_mixup(Xtr, ytr, alpha=0.4, n_new=Xtr.shape[0]//2)\n",
    "        clf = LogisticRegression(max_iter=4000, class_weight='balanced', solver='lbfgs')\n",
    "        clf.fit(Xtr_aug, ytr_aug)\n",
    "\n",
    "        # --- Predictions with/without TTA ------------------------------------\n",
    "        # (TTA recomputes features from raw images; Xva/Xte above are without TTA)\n",
    "        p_val_img  = predict_with_tta(va_img['image_path'].tolist(), clf, n_views=TTA_N_VIEWS)\n",
    "        p_test_img = predict_with_tta(te_img['image_path'].tolist(), clf, n_views=TTA_N_VIEWS) if len(te_img)>0 else np.array([])\n",
    "\n",
    "        if len(np.unique(yva))==2:\n",
    "            print(f\"[Imaging] VAL image-level — AUROC={roc_auc_score(yva,p_val_img):.4f} | AUPRC={average_precision_score(yva,p_val_img):.4f} | N={len(yva)}\")\n",
    "        if len(yte)>0 and len(np.unique(yte))==2:\n",
    "            print(f\"[Imaging] TEST image-level — AUROC={roc_auc_score(yte,p_test_img):.4f} | AUPRC={average_precision_score(yte,p_test_img):.4f} | N={len(yte)}\")\n",
    "    else:\n",
    "        print(\"[Imaging][WARN] Not enough training images or only one class in training. Skipping classifier.\")\n",
    "        p_val_img = np.array([]); p_test_img = np.array([])\n",
    "\n",
    "    # --------- Per-cow aggregation (always valid under this split) -----------\n",
    "    def agg_per_cow(df_rows: pd.DataFrame, probs: np.ndarray, cow_col: str, target_col=\"label\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Aggregate image-level probabilities to cow-level by mean; cow label is max over images.\n",
    "        Returns a DataFrame with [cow_id, y, p_img, n] where p_img is mean per cow and n is image count.\n",
    "        \"\"\"\n",
    "        tmp = df_rows.copy(); tmp[\"proba\"] = probs\n",
    "        return tmp.groupby(cow_col).agg(y=(target_col,\"max\"), p=(\"proba\",\"mean\"), n=(\"proba\",\"count\")).reset_index()\n",
    "\n",
    "    val_img_cow  = agg_per_cow(va_img, p_val_img,  cow_col=KEY, target_col=\"label\").rename(columns={\"p\":\"p_img\"})\n",
    "    test_img_cow = agg_per_cow(te_img, p_test_img, cow_col=KEY, target_col=\"label\").rename(columns={\"p\":\"p_img\"}) if len(te_img)>0 else None\n",
    "\n",
    "    print(f\"[Imaging] Output per-cow — VAL cows: {len(val_img_cow)} | TEST cows: {0 if test_img_cow is None else len(test_img_cow)}\")\n",
    "    print(\"Images available for training:\", bool(len(p_val_img)>0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yz0cKRBN3mMo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yz0cKRBN3mMo",
    "outputId": "b3e04434-0b56-4454-da31-244fd8cb378d"
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Cell 5 — v11 (robust past-only features + LR ⊕ HGB + tuned pooling)\n",
    "# Objective: increase TEST AUPRC without saturating. Pre-event is applied only in the pooling step.\n",
    "# =======================\n",
    "import numpy as np, pandas as pd, warnings, math\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Ensure prior cells built the split-specific DataFrames.\n",
    "assert 'train_df' in globals() and 'val_df' in globals() and 'test_df' in globals(), \"Missing train/val/test.\"\n",
    "KEY = 'Cow_ID_match'\n",
    "for nm, d in [('train',train_df),('val',val_df),('test',test_df)]:\n",
    "    if KEY not in d.columns: raise KeyError(f\"{nm}_df is missing '{KEY}'\")\n",
    "for d in (train_df, val_df, test_df):\n",
    "    if 'class1' not in d.columns: raise KeyError(\"Column 'class1' (0/1) is required.\")\n",
    "    if 'Temperature' not in d.columns: raise KeyError(\"Column 'Temperature' is required.\")\n",
    "\n",
    "SEED = 42\n",
    "TIME_COLS = ['Day','visit_time','datetime','VisitDate','time']\n",
    "\n",
    "# ---------- Time helpers ------------------------------------------------------\n",
    "def _order_series(df):\n",
    "    \"\"\"\n",
    "    Produce an ordering key for each cow:\n",
    "    - Prefer a time-like column (parsed to datetime where necessary).\n",
    "    - Fallback to a per-cow visit index.\n",
    "    \"\"\"\n",
    "    for c in TIME_COLS:\n",
    "        if c in df.columns:\n",
    "            s = df[c]\n",
    "            if pd.api.types.is_string_dtype(s):\n",
    "                try: s = pd.to_datetime(s, errors='coerce')\n",
    "                except: pass\n",
    "            return s\n",
    "    return df.groupby(KEY).cumcount()\n",
    "\n",
    "def _sort(df):\n",
    "    \"\"\"Sort by cow and temporal/visit order, returning a copy with an internal order column.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['_ord_'] = _order_series(df)\n",
    "    return df.sort_values([KEY,'_ord_']).reset_index(drop=True)\n",
    "\n",
    "def _align(df, s, dtype=float):\n",
    "    \"\"\"Return a Series aligned to df.index with a guaranteed dtype.\"\"\"\n",
    "    return pd.Series(s, index=df.index, dtype=dtype)\n",
    "\n",
    "# ---------- Robust past-only features ----------------------------------------\n",
    "def z_past_strict(df, col):\n",
    "    \"\"\"\n",
    "    Per-cow z-score using *past-only* expanding statistics:\n",
    "    z_t = (x_t − mean_{<t}) / std_{<t}, with minimum periods and winsorisation.\n",
    "    \"\"\"\n",
    "    df = _sort(df.copy())\n",
    "    if col not in df.columns:\n",
    "        out = pd.Series(np.nan, index=df.index, dtype=float)\n",
    "        df.drop(columns=['_ord_'], inplace=True)\n",
    "        return out\n",
    "    x = pd.to_numeric(df[col], errors='coerce')\n",
    "    g = df.groupby(KEY)[x.name]\n",
    "    # Expanding mean/std with minimum periods; shift so only past is used.\n",
    "    m = g.expanding(min_periods=2).mean().reset_index(level=0, drop=True)\n",
    "    s = g.expanding(min_periods=3).std(ddof=1).reset_index(level=0, drop=True)\n",
    "    mu_prev = m.groupby(df[KEY]).shift(1)\n",
    "    sd_prev = s.groupby(df[KEY]).shift(1)\n",
    "    sd_prev = sd_prev.replace(0, np.nan)\n",
    "    z = (x - mu_prev) / sd_prev\n",
    "    # Winsorise z for robustness\n",
    "    z = z.clip(lower=-5, upper=5)\n",
    "    out = _align(df, z, float)\n",
    "    df.drop(columns=['_ord_'], inplace=True)\n",
    "    return out\n",
    "\n",
    "def rolling_median_dev_z(df, col, win=3):\n",
    "    \"\"\"\n",
    "    Deviation from rolling median (per cow), then past-only z-standardisation of the deviation.\n",
    "    \"\"\"\n",
    "    df = _sort(df.copy())\n",
    "    x = pd.to_numeric(df[col], errors='coerce')\n",
    "    med = df.groupby(KEY)[x.name].rolling(win, min_periods=2).median()\n",
    "    med.index = med.index.droplevel(0)\n",
    "    med_prev = med.groupby(df[KEY]).shift(1)\n",
    "    dev = x - med_prev\n",
    "    # z-standardise the deviation using past-only stats\n",
    "    tmp = df.copy(); tmp['__dev__'] = dev\n",
    "    z = z_past_strict(tmp, '__dev__')\n",
    "    df.drop(columns=['_ord_'], inplace=True)\n",
    "    return z\n",
    "\n",
    "def slope_last3_prev(df, col):\n",
    "    \"\"\"\n",
    "    Past-only slope of the last 3 observations (per cow), aligned so that\n",
    "    the slope for time t uses data up to t−1.\n",
    "    \"\"\"\n",
    "    df = _sort(df.copy())\n",
    "    x = pd.to_numeric(df[col], errors='coerce')\n",
    "    out = np.full(len(df), np.nan, dtype=float)\n",
    "    for cow, idx in df.groupby(KEY).groups.items():\n",
    "        vals = x.loc[idx].astype(float).values\n",
    "        sl = np.full_like(vals, np.nan, dtype=float)\n",
    "        for i in range(3, len(vals)+1):\n",
    "            y = vals[i-3:i]; t = np.arange(3)\n",
    "            if np.isfinite(y).sum() >= 2:\n",
    "                t_mean = t.mean(); y_mean = np.nanmean(y)\n",
    "                num = np.nansum((t - t_mean)*(y - y_mean))\n",
    "                den = np.nansum((t - t_mean)**2) + 1e-9\n",
    "                sl[i-1] = num/den\n",
    "        # shift to ensure pure past-only use\n",
    "        sl = np.roll(sl, 1); sl[0] = np.nan\n",
    "        out[idx] = sl\n",
    "    df.drop(columns=['_ord_'], inplace=True)\n",
    "    return _align(df, out, float)\n",
    "\n",
    "def difflag(df, col, k):\n",
    "    \"\"\"Past-only k-lag difference for a numeric column (per cow).\"\"\"\n",
    "    df = _sort(df.copy())\n",
    "    x = pd.to_numeric(df[col], errors='coerce')\n",
    "    prev = df.groupby(KEY)[x.name].shift(k)\n",
    "    d = x - prev\n",
    "    df.drop(columns=['_ord_'], inplace=True)\n",
    "    return _align(df, d, float)\n",
    "\n",
    "def seasonal_feats(df):\n",
    "    \"\"\"\n",
    "    Encode simple seasonality using a cyclic transform:\n",
    "    - If 'Day' exists, use day-of-year; else if 'Months after giving birth' exists, use it mod 12.\n",
    "    Past-only alignment is enforced by shifting by one step.\n",
    "    \"\"\"\n",
    "    df = _sort(df.copy())\n",
    "    if 'Day' in df.columns:\n",
    "        day = pd.to_datetime(df['Day'], errors='coerce')\n",
    "        doy_prev = day.dt.dayofyear.groupby(df[KEY]).shift(1)\n",
    "        ang = 2*np.pi*(doy_prev.fillna(0)/365.25)\n",
    "        sinv, cosv = np.sin(ang), np.cos(ang)\n",
    "    elif 'Months after giving birth' in df.columns:\n",
    "        m_prev = pd.to_numeric(df['Months after giving birth'], errors='coerce').groupby(df[KEY]).shift(1)\n",
    "        ang = 2*np.pi*((m_prev.fillna(0)%12)/12.0)\n",
    "        sinv, cosv = np.sin(ang), np.cos(ang)\n",
    "    else:\n",
    "        sinv, cosv = np.nan, np.nan\n",
    "    out_sin, out_cos = _align(df, sinv, float).rename('season_sin'), _align(df, cosv, float).rename('season_cos')\n",
    "    df.drop(columns=['_ord_'], inplace=True)\n",
    "    return out_sin, out_cos\n",
    "\n",
    "def build_feats(df):\n",
    "    \"\"\"\n",
    "    Construct robust past-only features for Temperature and seasonality.\n",
    "    Add months-after-birth z-score when available.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['Temperature_z']      = z_past_strict(df, 'Temperature')\n",
    "    df['Temp_meddev3_z']     = rolling_median_dev_z(df, 'Temperature', win=3)\n",
    "    df['Temp_slope3']        = slope_last3_prev(df, 'Temperature')\n",
    "    df['Temp_diff1']         = difflag(df, 'Temperature', 1)\n",
    "    df['Temp_diff2']         = difflag(df, 'Temperature', 2)\n",
    "    ssin, scos               = seasonal_feats(df)\n",
    "    df['season_sin'], df['season_cos'] = ssin, scos\n",
    "    if 'Months after giving birth' in df.columns:\n",
    "        df['Months_after_birth_z'] = z_past_strict(df, 'Months after giving birth')\n",
    "    return df\n",
    "\n",
    "# Apply feature construction to each split (no leakage between splits).\n",
    "for nm in ['train_df','val_df','test_df']:\n",
    "    globals()[nm] = build_feats(globals()[nm])\n",
    "\n",
    "# ---------- Target: risk_h1 (pre-event ONLY in pooling) ----------------------\n",
    "def add_risk_h1(df):\n",
    "    \"\"\"\n",
    "    Define next-visit risk at visit level (risk_h1): label_t = class1 at t+1 (shifted),\n",
    "    with missing future set to 0. Sorting ensures past-only alignment.\n",
    "    \"\"\"\n",
    "    df = _sort(df)\n",
    "    df['risk_h1'] = df.groupby(KEY)['class1'].shift(-1).fillna(0).astype(int)\n",
    "    df.drop(columns=['_ord_'], inplace=True)\n",
    "    return df\n",
    "train_df = add_risk_h1(train_df)\n",
    "val_df   = add_risk_h1(val_df)\n",
    "test_df  = add_risk_h1(test_df)\n",
    "YCOL = 'risk_h1'\n",
    "\n",
    "# ---------- Whitelist: keep features that exist and have data in all splits ---\n",
    "cand = ['Temperature_z','Temp_meddev3_z','Temp_slope3','Temp_diff1','Temp_diff2','season_sin','season_cos','Months_after_birth_z']\n",
    "def _ok(c):\n",
    "    return (c in train_df.columns and c in val_df.columns and c in test_df.columns\n",
    "            and train_df[c].notna().sum()>0 and val_df[c].notna().sum()>0 and test_df[c].notna().sum()>0)\n",
    "whitelist = [c for c in cand if _ok(c)]\n",
    "if not whitelist:\n",
    "    raise RuntimeError(\"Empty whitelist: please verify generation of z/diff/slope features.\")\n",
    "print(f\"[v11] whitelist: {whitelist} | Target={YCOL}\")\n",
    "\n",
    "# ---------- Preprocess --------------------------------------------------------\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"sc\",  StandardScaler())\n",
    "    ]), whitelist)\n",
    "], remainder='drop', verbose_feature_names_out=True)\n",
    "pre.fit(train_df[whitelist])\n",
    "\n",
    "def mat(df):\n",
    "    \"\"\"Transform df into (keys, X, y) using the fitted preprocessor.\"\"\"\n",
    "    X = pre.transform(df[whitelist])\n",
    "    y = df[YCOL].astype(int).values\n",
    "    K = df[KEY].astype(str).values\n",
    "    return K, X, y\n",
    "\n",
    "Kv_tr, Xtr, ytr = mat(train_df)\n",
    "Kv_va, Xva, yva = mat(val_df)\n",
    "Kv_te, Xte, yte = mat(test_df)\n",
    "\n",
    "# ---------- Models: LR-EN + HGB ---------------------------------------------\n",
    "pos_rate = max(1e-6, float((ytr==1).mean()))\n",
    "w_pos = 0.5/pos_rate; w_neg = 0.5/(1.0-pos_rate)\n",
    "w_tr  = np.where(ytr==1, w_pos, w_neg)\n",
    "\n",
    "lr = LogisticRegression(max_iter=4000, solver='saga', penalty='elasticnet', l1_ratio=0.35, C=1.0, random_state=SEED)\n",
    "lr.fit(Xtr, ytr, sample_weight=w_tr)\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.15, max_leaf_nodes=31, min_samples_leaf=25,\n",
    "    l2_regularization=0.0, max_depth=None, random_state=SEED\n",
    ")\n",
    "hgb.fit(Xtr, ytr, sample_weight=w_tr)\n",
    "\n",
    "def proba(clf, X):\n",
    "    \"\"\"Return positive-class probabilities (or decision function as a fallback).\"\"\"\n",
    "    return clf.predict_proba(X)[:,1] if hasattr(clf, \"predict_proba\") else clf.decision_function(X)\n",
    "\n",
    "pva_lr,  pte_lr  = proba(lr,  Xva), proba(lr,  Xte)\n",
    "pva_hgb, pte_hgb = proba(hgb, Xva), proba(hgb, Xte)\n",
    "\n",
    "# ---------- Pre-event pooling + hyperparameter tuning on VAL (AUPRC) ---------\n",
    "def pooling_scores(p_visit, keys, tau, r, topk, jitter=0.006, seed=SEED):\n",
    "    \"\"\"\n",
    "    Convert visit-level probabilities into a per-cow score with:\n",
    "    - temperature scaling (tau) in logit space,\n",
    "    - light Gaussian jitter to break ties,\n",
    "    - pre-event exclusion: drop the last visit per cow,\n",
    "    - robust pooling via (power mean + top-k mean)/2 over positive excess above median.\n",
    "    \"\"\"\n",
    "    p = np.clip(p_visit, 1e-9, 1-1e-9)\n",
    "    z = np.log(p/(1-p))/tau\n",
    "    pt = 1/(1+np.exp(-z))\n",
    "    if jitter>0:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        pt = np.clip(pt + rng.normal(0.0, jitter, size=pt.shape), 1e-9, 1-1e-9)\n",
    "    dfp = pd.DataFrame({'k':keys, 'pt':pt})\n",
    "    # pre-event: ignore the last visit per cow\n",
    "    last_idx = pd.DataFrame({'k':keys}).groupby('k').tail(1).index\n",
    "    dfp = dfp[~dfp.index.isin(last_idx)]\n",
    "    med = dfp.groupby('k')['pt'].transform('median')\n",
    "    exc = (dfp['pt'] - med).clip(lower=0)\n",
    "    def pmean(x, rr):\n",
    "        xv = x.values\n",
    "        return (((xv**rr).mean())**(1.0/rr)) if xv.size>0 else np.nan\n",
    "    def topk_mean(x, kk):\n",
    "        xv = np.sort(x.values);\n",
    "        if xv.size==0: return np.nan\n",
    "        kk = min(kk, xv.size);\n",
    "        return float(xv[-kk:].mean())\n",
    "    pm = exc.groupby(dfp['k']).apply(lambda s: pmean(s, r))\n",
    "    tk = exc.groupby(dfp['k']).apply(lambda s: topk_mean(s, topk))\n",
    "    return ((pm + tk)/2.0)\n",
    "\n",
    "def ranknorm(x):\n",
    "    \"\"\"Rank-normalise to [0,1] with ties resolved by argsort order.\"\"\"\n",
    "    r = np.argsort(np.argsort(x))\n",
    "    return r / max(len(x)-1, 1)\n",
    "\n",
    "# Cow-level labels for VAL/TEST (max over visits)\n",
    "def cow_label(df): return df.groupby(KEY)['class1'].max().astype(int)\n",
    "Kva = sorted(set(Kv_va), key=str); yva_cow = cow_label(val_df).reindex(Kva).values\n",
    "Kte = sorted(set(Kv_te), key=str); yte_cow = cow_label(test_df).reindex(Kte).values\n",
    "\n",
    "taus  = [2.0, 2.3, 2.6]\n",
    "rs    = [0.7, 0.8, 0.9]\n",
    "topks = [2, 3, 4]\n",
    "best = None\n",
    "\n",
    "for tau in taus:\n",
    "    for r in rs:\n",
    "        for k in topks:\n",
    "            # Pool for each model\n",
    "            va_lr  = pooling_scores(pva_lr,  Kv_va, tau, r, k).reindex(Kva).fillna(0.0).values\n",
    "            va_hgb = pooling_scores(pva_hgb, Kv_va, tau, r, k).reindex(Kva).fillna(0.0).values\n",
    "            # Robust rank-ensemble\n",
    "            va_ens = (ranknorm(va_lr) + ranknorm(va_hgb))/2.0\n",
    "            try:\n",
    "                ap = average_precision_score(yva_cow, va_ens)\n",
    "            except:\n",
    "                ap = -np.inf\n",
    "            if (best is None) or (ap > best[0]):\n",
    "                best = (ap, tau, r, k, va_lr, va_hgb, va_ens)\n",
    "\n",
    "ap_best, TAU_B, R_B, K_B, va_lr_b, va_hgb_b, va_ens_b = best\n",
    "\n",
    "# Compute on TEST with best hyperparameters\n",
    "te_lr_b  = pooling_scores(pte_lr,  Kv_te, TAU_B, R_B, K_B).reindex(Kte).fillna(0.0).values\n",
    "te_hgb_b = pooling_scores(pte_hgb, Kv_te, TAU_B, R_B, K_B).reindex(Kte).fillna(0.0).values\n",
    "va_ens_b = (ranknorm(va_lr_b) + ranknorm(va_hgb_b))/2.0\n",
    "te_ens_b = (ranknorm(te_lr_b) + ranknorm(te_hgb_b))/2.0\n",
    "\n",
    "# ---------- Platt calibration on VAL (ensemble) ------------------------------\n",
    "from sklearn.linear_model import LogisticRegression as LRCal\n",
    "cal = LRCal(max_iter=1000, random_state=SEED).fit(va_ens_b.reshape(-1,1), yva_cow.astype(int))\n",
    "pva_c = cal.predict_proba(va_ens_b.reshape(-1,1))[:,1]\n",
    "pte_c = cal.predict_proba(te_ens_b.reshape(-1,1))[:,1]\n",
    "\n",
    "# ---------- Metrics ----------------------------------------------------------\n",
    "def metr(name, y, p):\n",
    "    \"\"\"Compute AUROC, AUPRC, and Brier score; clip probabilities for numerical stability.\"\"\"\n",
    "    p = np.clip(p, 1e-9, 1-1e-9)\n",
    "    try: auc = roc_auc_score(y, p)\n",
    "    except: auc = np.nan\n",
    "    ap = average_precision_score(y, p)\n",
    "    br = brier_score_loss(y, p)\n",
    "    return dict(name=name, AUROC=auc, AUPRC=ap, Brier=br, N=len(y))\n",
    "\n",
    "res = pd.DataFrame([\n",
    "    metr(f\"VAL v11 (tau={TAU_B}, r={R_B}, K={K_B})\", yva_cow, pva_c),\n",
    "    metr(f\"TEST v11 (tau={TAU_B}, r={R_B}, K={K_B})\", yte_cow, pte_c),\n",
    "])\n",
    "print(\"\\n=== Summary v11 (robust features + LR⊕HGB + tuned pooling) ===\")\n",
    "print(res[[\"name\",\"AUROC\",\"AUPRC\",\"Brier\",\"N\"]].to_string(index=False))\n",
    "\n",
    "# ---------- Audit ------------------------------------------------------------\n",
    "print(f\"\\n[v11 Audit] whitelist={whitelist}\")\n",
    "print(f\"[v11 Audit] rows (train/val/test): {len(train_df)}/{len(val_df)}/{len(test_df)}\")\n",
    "print(f\"[v11 Audit] pooling*  tau={TAU_B}, r={R_B}, topK={K_B}  (optimised on VAL for AUPRC)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6xnwLnBNXgga",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822,
     "referenced_widgets": [
      "0040813ff0cd45e9813d9579bde12d38",
      "3723580a8e804da5bbd463f9b647ba4c",
      "cfa59ddb74954ca1863713448e5c6069",
      "3de4de61d7624d3e8d15b7b05da8ac41",
      "2c7ba2bcb485475994f5641abe1f414b",
      "82abc872056e42bdb64c71cf0881c2f5",
      "2f758e6b2afb4a8da492c616c60f7849",
      "19c3592d188741ba81ba73107a466521",
      "365d6dee17774d58828e556dde603981",
      "e9b4abf2a12c4ea7a4c1e8d67b07c674",
      "5052d672d6c3413296717ce9a136135c",
      "2bca1133286044e6964ad92352f36d81",
      "464dfddea91e4c688fa0838409865e71",
      "ef4b391c0ef04e6c88743d596bd4ea9f",
      "21a61fb301404629aec2af72b148d9e1",
      "10b33843a5de4f74bef9adf208e069a7",
      "35740b40240140fd911ac1167cf8f426",
      "f60bbe75133d4edd94f7fafcc3d7f671",
      "4bfbebf61f624c0886120b418da4e581",
      "9198c13ea21a443e9cb2c971e14c0b58",
      "d84e9e7c36584819863070d8e8461086",
      "b4eee734d1514ed5bb50de503b902bd9",
      "b3aaa65004734b359201c00b219b3955",
      "b5b229c2fb2f40abacbb86876475ade2",
      "d2b17d81e6ae4c69bd4cad3c5694d842",
      "81cb4030115e4a4085199dd55bfb581f",
      "25e6c579c5ae489398309d656aa32e0f",
      "fcc793eefece42db8f7d821450de948f",
      "8dacc44bd6254ca791179544ee452671",
      "45b129b0e02044be91947fd3d3ebdf61",
      "565605d8a7ff423980374c567a798e4e",
      "ea8eb88d98b04ca98b698c66bf81a4ec",
      "78d39e2b8ecb4f329289929e13a6fe58",
      "7bde952458634ca3affc7b5da336c02c",
      "8b7dab5f3624468eb31794b9ce146522",
      "88ed134358974479b8ebda89c4a57baf",
      "584291e3f7354d6593d90cccdad17f3c",
      "cd612096be194ace89ea66ee30f3733b",
      "843fcb7a63574123ba12bcebe6e958f1",
      "57b7438bba33479dbdd31863139924aa",
      "c0efe8ff73b14d24a7477db5eeb33c0d",
      "73261c3d7323425a964b9e5668bb7d41",
      "754991a906a742e687998ad8c59ff9c5",
      "355d4c84d28f4e20b25cd9ab66a4f4b5",
      "42ab98ff19554203a2d9398a5761bb6e",
      "7fb6e8da29824b6aa385b6135d468527",
      "7b2170e89f244523b5fb33d5fac1b269",
      "bb837636a30e483f87f99585459f229e",
      "177bfa467e824e818308c41f09658ed0",
      "daa698075c5c4ab98d4c8c13ae2ab843",
      "a34ed149057e4bf1956ae348958c6b89",
      "686604bd1b404cdba47c42820744b194",
      "36f5f156ec0b404581893008ff38f0d1",
      "3a569d4d197248979953810bc8336491",
      "d40bf0f96c024829978cf1dd0843cd82"
     ]
    },
    "id": "6xnwLnBNXgga",
    "outputId": "d189936c-3f08-4f3f-c44b-94e5fe09a529"
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Cell 6 — v6.8 (YOLO .txt, GPU/AMP, multimodal-ready, bootstrap & figures/tables)\n",
    "# - Imaging pipeline with robust fallback (images-only) and tabular fusion when available\n",
    "# - Save figures & tables to PROJECT_DIR/figures_and_tables (overwrite guaranteed)\n",
    "# =======================\n",
    "import os, re, glob, time, json, warnings, random, sys\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Torch / Vision\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# ML\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegression as LRCal\n",
    "from sklearn.metrics import (average_precision_score, roc_auc_score, brier_score_loss,\n",
    "                             roc_curve, precision_recall_curve, confusion_matrix)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== CONFIG =====\n",
    "SEED    = 42\n",
    "DEBUG   = True\n",
    "\n",
    "# Fixed PATHS (per your setup)\n",
    "if 'PROJECT_DIR' not in globals():\n",
    "    PROJECT_DIR = \"/content/drive/MyDrive/Mastitis_illness_cow/datasets\"\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"images\")\n",
    "LABEL_DIR = os.path.join(PROJECT_DIR, \"labels\")\n",
    "\n",
    "SAVE_DIR   = \"/content/mastitis_outputs\"  # quick outputs\n",
    "FIGDIR     = os.path.join(PROJECT_DIR, \"figures_and_tables\")  # for the paper\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(FIGDIR, exist_ok=True)\n",
    "\n",
    "# YOLO: which class_id means “mastitis positive”\n",
    "POSITIVE_CLASS_ID = 1         # <-- change if needed (e.g., 0)\n",
    "IMG_EXTS = {\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\"}\n",
    "\n",
    "print(\"[MOUNT] IN_COLAB:\", 'google.colab' in sys.modules)\n",
    "print(\"[PATHS] PROJECT_DIR:\", PROJECT_DIR)\n",
    "print(\"[PATHS] IMAGE_DIR exists:\", os.path.isdir(IMAGE_DIR), \"| LABEL_DIR exists:\", os.path.isdir(LABEL_DIR))\n",
    "\n",
    "# ===== ENV =====\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[ENV] torch={torch.__version__} | torchvision={torchvision.__version__} | device={DEVICE}\", flush=True)\n",
    "\n",
    "# ===== Tabular (optional, for real per-cow fusion) =====\n",
    "tab_ok = ('train_df' in globals()) and ('val_df' in globals()) and ('test_df' in globals())\n",
    "KEY = 'Cow_ID_match'\n",
    "if tab_ok:\n",
    "    for nm, d in [('train',train_df),('val',val_df),('test',test_df)]:\n",
    "        if KEY not in d.columns or 'class1' not in d.columns:\n",
    "            tab_ok = False\n",
    "            print(f\"[WARN] {nm}_df is missing '{KEY}' or 'class1' → using image-only fallback.\", flush=True)\n",
    "            break\n",
    "\n",
    "# ===== 1) Index images =====\n",
    "print(\"[Index] Scanning images…\", flush=True)\n",
    "stem2path = {}\n",
    "for root, dirs, files in os.walk(IMAGE_DIR):\n",
    "    for f in files:\n",
    "        if os.path.splitext(f)[1].lower() in IMG_EXTS:\n",
    "            stem2path[os.path.splitext(f)[0]] = os.path.join(root, f)\n",
    "print(f\"[Index] Indexed images: {len(stem2path)}\")\n",
    "\n",
    "# ===== 2) Read YOLO labels (.txt one per image) =====\n",
    "def parse_yolo_txt(txt_path):\n",
    "    \"\"\"\n",
    "    Return True if at least one line has class_id == POSITIVE_CLASS_ID.\n",
    "    Typical row format: <class_id> <cx> <cy> <w> <h> (normalised)\n",
    "    \"\"\"\n",
    "    pos = False\n",
    "    try:\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = line.split()\n",
    "                try:\n",
    "                    cls = int(float(parts[0]))\n",
    "                    if cls == POSITIVE_CLASS_ID:\n",
    "                        pos = True\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "    except Exception:\n",
    "        pass\n",
    "    return pos\n",
    "\n",
    "txt_files = sorted([p for p in glob.glob(os.path.join(LABEL_DIR, \"*.txt\")) if os.path.isfile(p)])\n",
    "if not txt_files:\n",
    "    raise RuntimeError(f\"No YOLO .txt found in {LABEL_DIR}.\")\n",
    "\n",
    "records = []\n",
    "for p in tqdm(txt_files, desc=\"Parse YOLO labels\", mininterval=0.1):\n",
    "    stem = os.path.splitext(os.path.basename(p))[0]\n",
    "    pos = parse_yolo_txt(p)\n",
    "    records.append((stem, pos))\n",
    "\n",
    "lab_img = pd.DataFrame(records, columns=[\"stem\", \"pos\"])\n",
    "lab_img['class1'] = lab_img['pos'].astype(int)\n",
    "lab_img.drop(columns=['pos'], inplace=True)\n",
    "\n",
    "# resolve image path for stem\n",
    "lab_img['abs_path'] = lab_img['stem'].map(stem2path)\n",
    "lab_img = lab_img[lab_img['abs_path'].notna()].reset_index(drop=True)\n",
    "lab_img['filename'] = lab_img['abs_path'].apply(os.path.basename)\n",
    "print(f\"[Labels] Images with resolved labels: {len(lab_img)}\")\n",
    "if len(lab_img) == 0:\n",
    "    raise RuntimeError(\"No images resolved from .txt files: ensure .txt stems match images/ filenames.\")\n",
    "\n",
    "# ===== 3) Try to extract Cow_ID from filename (customise as needed) =====\n",
    "def extract_cow_from_filename(fname):\n",
    "    \"\"\"\n",
    "    CUSTOMISE this if you know how to map file → cow.\n",
    "    Tried patterns: 'cow123', 'COW_045', 'vacca-12'\n",
    "    \"\"\"\n",
    "    base = os.path.basename(fname)\n",
    "    for pat in [r'cow[_-]?(\\d+)', r'COW[_-]?(\\d+)', r'vacca[_-]?(\\d+)']:\n",
    "        m = re.search(pat, base, re.I)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    return None\n",
    "\n",
    "lab_img[KEY] = lab_img['filename'].apply(extract_cow_from_filename)\n",
    "\n",
    "# ===== 4) Decide split: per-cow (if mappable) or image-level fallback =====\n",
    "use_tab_split = tab_ok and lab_img[KEY].notna().any()\n",
    "if use_tab_split:\n",
    "    cows_tr = set(train_df[KEY].astype(str))\n",
    "    cows_va = set(val_df[KEY].astype(str))\n",
    "    cows_te = set(test_df[KEY].astype(str))\n",
    "    lab_tr = lab_img[lab_img[KEY].isin(cows_tr)].copy()\n",
    "    lab_va = lab_img[lab_img[KEY].isin(cows_va)].copy()\n",
    "    lab_te = lab_img[lab_img[KEY].isin(cows_te)].copy()\n",
    "    print(f\"[Align] images per split (by cow): train={len(lab_tr)} | val={len(lab_va)} | test={len(lab_te)}\", flush=True)\n",
    "    if min(len(lab_tr), len(lab_va), len(lab_te)) == 0:\n",
    "        print(\"[WARN] Few matches with cow_id → falling back to image-level (stratified) split.\", flush=True)\n",
    "        use_tab_split = False\n",
    "\n",
    "if not use_tab_split:\n",
    "    print(\"[Fallback] Image-level split (stratified on class1). No tabular fusion possible.\", flush=True)\n",
    "    df_all = lab_img.copy()\n",
    "    y_all = df_all['class1'].values\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=SEED)\n",
    "    tr_idx, tm_idx = next(sss1.split(np.zeros(len(y_all)), y_all))\n",
    "    df_tr = df_all.iloc[tr_idx].reset_index(drop=True)\n",
    "    df_tm = df_all.iloc[tm_idx].reset_index(drop=True)\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.50, random_state=SEED)\n",
    "    va_idx, te_idx = next(sss2.split(np.zeros(len(df_tm)), df_tm['class1'].values))\n",
    "    lab_tr = df_tr\n",
    "    lab_va = df_tm.iloc[va_idx].reset_index(drop=True)\n",
    "    lab_te = df_tm.iloc[te_idx].reset_index(drop=True)\n",
    "    # synthetic KEY = stem (1 image = 1 “cow”)\n",
    "    for df in (lab_tr, lab_va, lab_te):\n",
    "        df[KEY] = df['stem']\n",
    "\n",
    "print(f\"[IMG rows] train={len(lab_tr)} | val={len(lab_va)} | test={len(lab_te)}\")\n",
    "\n",
    "# ===== 5) Dataset & DataLoader =====\n",
    "# PATCH: no ToTensor (we already read as Tensor). Convert dtype and normalise.\n",
    "img_size = 224\n",
    "tfm = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float32),   # uint8/uint16 → float32 [0,1]\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
    "])\n",
    "\n",
    "class ImgDS(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        img = torchvision.io.read_image(r['abs_path'])  # Tensor CxHxW uint8/uint16\n",
    "        img = tfm(img)                                   # -> float32 normalised\n",
    "        return img, int(r['class1']), str(r[KEY])\n",
    "\n",
    "# SPEED PATCH (GPU)\n",
    "from torch.cuda import amp\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception: pass\n",
    "    print(f\"[GPU] {torch.cuda.get_device_name(0)} | cap={torch.cuda.get_device_capability(0)}\", flush=True)\n",
    "\n",
    "BATCH       = 256    # lower to 192/128 if OOM\n",
    "NUM_WORKERS = 6      # set 0 if you get I/O issues\n",
    "PREFETCH    = 4\n",
    "\n",
    "def make_loader(df, shuffle):\n",
    "    return DataLoader(\n",
    "        ImgDS(df),\n",
    "        batch_size=BATCH,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=(NUM_WORKERS > 0),\n",
    "        prefetch_factor=PREFETCH if NUM_WORKERS > 0 else None\n",
    "    )\n",
    "\n",
    "dl_tr = make_loader(lab_tr, True)\n",
    "dl_va = make_loader(lab_va, False)\n",
    "dl_te = make_loader(lab_te, False)\n",
    "\n",
    "# ===== 6) Backbone + embedding extraction =====\n",
    "backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "feat_dim = backbone.fc.in_features\n",
    "backbone.fc = nn.Identity()\n",
    "backbone.eval().to(DEVICE)\n",
    "for p in backbone.parameters(): p.requires_grad = False\n",
    "print(f\"[Backbone] ResNet18 feat_dim={feat_dim}\", flush=True)\n",
    "\n",
    "use_amp = torch.cuda.is_available()\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(dloader, desc):\n",
    "    Xs, ys, ks = [], [], []\n",
    "    t0 = time.time()\n",
    "    for imgs, y, k in tqdm(dloader, desc=desc, mininterval=0.1, leave=True):\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        if use_amp:\n",
    "            # New autocast API\n",
    "            with torch.amp.autocast(\"cuda\", dtype=torch.float16):\n",
    "                emb = backbone(imgs)\n",
    "            emb = emb.float().detach().cpu().numpy()\n",
    "            torch.cuda.synchronize()\n",
    "        else:\n",
    "            emb = backbone(imgs).detach().cpu().numpy()\n",
    "        Xs.append(emb); ys.append(y.numpy()); ks += list(k)\n",
    "    dt = time.time() - t0\n",
    "    n  = sum(x.shape[0] for x in Xs) if Xs else 0\n",
    "    print(f\"[TIMING] {desc}: {n} img in {dt:.2f}s → {n/max(dt,1e-9):.1f} img/s\", flush=True)\n",
    "    X = np.concatenate(Xs, axis=0) if Xs else np.zeros((0, feat_dim), dtype=np.float32)\n",
    "    y = np.concatenate(ys, axis=0) if ys else np.zeros((0,), dtype=np.int32)\n",
    "    k = np.array(ks, dtype=object)\n",
    "    return X, y, k\n",
    "\n",
    "Xtr_i, ytr_i, Ktr_i = extract_embeddings(dl_tr, \"Emb TR\")\n",
    "Xva_i, yva_i, Kva_i = extract_embeddings(dl_va, \"Emb VA\")\n",
    "Xte_i, yte_i, Kte_i = extract_embeddings(dl_te, \"Emb TE\")\n",
    "print(f\"[Emb] TR={Xtr_i.shape} VA={Xva_i.shape} TE={Xte_i.shape}\", flush=True)\n",
    "\n",
    "# ===== 7) LR on embeddings =====\n",
    "pos_rate = max(1e-6, float((ytr_i==1).mean()))\n",
    "w_pos = 0.5/pos_rate; w_neg = 0.5/(1.0-pos_rate)\n",
    "w_tr  = np.where(ytr_i==1, w_pos, w_neg)\n",
    "\n",
    "clf_i = LogisticRegression(max_iter=3000, solver='lbfgs', C=1.0, n_jobs=-1)\n",
    "clf_i.fit(Xtr_i, ytr_i, sample_weight=w_tr)\n",
    "pva_img_v = clf_i.predict_proba(Xva_i)[:,1]\n",
    "pte_img_v = clf_i.predict_proba(Xte_i)[:,1]\n",
    "\n",
    "# ===== 8) Per-cow pooling when possible, otherwise per-image identity =====\n",
    "def logistic_temp(p, tau):\n",
    "    p = np.clip(p, 1e-9, 1-1e-9); z = np.log(p/(1-p))/tau\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def pre_event_mask(keys):\n",
    "    s = pd.Series(1, index=pd.RangeIndex(len(keys)))\n",
    "    if use_tab_split:\n",
    "        dfk = pd.DataFrame({'k':keys})\n",
    "        last = dfk.groupby('k').tail(1).index\n",
    "        s.loc[last] = 0\n",
    "    return s.astype(bool).values\n",
    "\n",
    "def pooling_scores(p_visit, keys, tau, r, topk, jitter=0.006, seed=SEED):\n",
    "    if not use_tab_split:\n",
    "        return pd.Series(p_visit, index=pd.Index(keys, name='k'))\n",
    "    pt = logistic_temp(p_visit, tau)\n",
    "    if jitter>0:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        pt = np.clip(pt + rng.normal(0.0, jitter, size=pt.shape), 1e-9, 1-1e-9)\n",
    "    dfp = pd.DataFrame({'k':keys, 'pt':pt})\n",
    "    mask = pre_event_mask(keys); dfp = dfp[mask]\n",
    "    if len(dfp)==0: return pd.Series(dtype=float)\n",
    "    med = dfp.groupby('k')['pt'].transform('median')\n",
    "    exc = (dfp['pt'] - med).clip(lower=0)\n",
    "    def pmean(x, rr):\n",
    "        xv = x.values\n",
    "        return (((xv**rr).mean())**(1.0/rr)) if xv.size>0 else np.nan\n",
    "    def topk_mean(x, kk):\n",
    "        xv = np.sort(x.values)\n",
    "        if xv.size==0: return np.nan\n",
    "        kk = min(kk, xv.size)\n",
    "        return float(xv[-kk:].mean())\n",
    "    pm = exc.groupby(dfp['k']).apply(lambda s: pmean(s, r))\n",
    "    tk = exc.groupby(dfp['k']).apply(lambda s: topk_mean(s, topk))\n",
    "    return (pm + tk)/2.0\n",
    "\n",
    "# y per cow (if tab) or per image (fallback)\n",
    "if use_tab_split:\n",
    "    yva_cow = val_df.groupby(KEY)['class1'].max().astype(int)\n",
    "    yte_cow = test_df.groupby(KEY)['class1'].max().astype(int)\n",
    "    taus, rs, topks = [2.0,2.6,3.0], [0.7,0.9], [2,3,4]\n",
    "    best_img = None\n",
    "    keys_va = Kva_i\n",
    "    for (tau, r, k) in tqdm([(t,r,kk) for t in taus for r in rs for kk in topks], desc=\"Tune pooling (IMG)\"):\n",
    "        pva_img_c = pooling_scores(pva_img_v, keys_va, tau, r, k)\n",
    "        pva_img_c = pva_img_c.reindex(yva_cow.index).fillna(0.0).values\n",
    "        ap = average_precision_score(yva_cow.values.astype(int), pva_img_c)\n",
    "        if (best_img is None) or (ap > best_img[0]):\n",
    "            best_img = (ap, tau, r, k, pva_img_c)\n",
    "    ap_img, TAU_I, R_I, K_I, pva_img_c = best_img\n",
    "    pte_img_c = pooling_scores(pte_img_v, Kte_i, TAU_I, R_I, K_I).reindex(yte_cow.index).fillna(0.0).values\n",
    "    print(f\"[Tune IMG] AP(VAL)={ap_img:.4f} tau={TAU_I}, r={R_I}, K={K_I}\", flush=True)\n",
    "else:\n",
    "    yva_cow = pd.Series(yva_i, index=Kva_i)\n",
    "    yte_cow = pd.Series(yte_i, index=Kte_i)\n",
    "    pva_img_c = pd.Series(pva_img_v, index=Kva_i).reindex(yva_cow.index).fillna(0.0).values\n",
    "    pte_img_c = pd.Series(pte_img_v, index=Kte_i).reindex(yte_cow.index).fillna(0.0).values\n",
    "\n",
    "# Platt calibration for images\n",
    "cal_img = LRCal(max_iter=1000, random_state=SEED).fit(pva_img_c.reshape(-1,1), yva_cow.values.astype(int))\n",
    "pva_img_cal = cal_img.predict_proba(pva_img_c.reshape(-1,1))[:,1]\n",
    "pte_img_cal = cal_img.predict_proba(pte_img_c.reshape(-1,1))[:,1]\n",
    "\n",
    "# ===== 9) Fusion with tabular (only if we have cow mapping and pva_c/pte_c) =====\n",
    "tab_ready = use_tab_split and ('pva_c' in globals()) and ('pte_c' in globals())\n",
    "if not tab_ready:\n",
    "    print(\"[Fusion] Images-only (missing cow mapping or pva_c/pte_c).\", flush=True)\n",
    "    pva_tab = np.zeros_like(pva_img_cal); pte_tab = np.zeros_like(pte_img_cal)\n",
    "else:\n",
    "    pva_tab = pd.Series(pva_c, index=yva_cow.index).reindex(yva_cow.index).fillna(0.0).values\n",
    "    pte_tab = pd.Series(pte_c, index=yte_cow.index).reindex(yte_cow.index).fillna(0.0).values\n",
    "\n",
    "def ranknorm(x):\n",
    "    r = np.argsort(np.argsort(x))\n",
    "    return r / max(len(x)-1, 1)\n",
    "\n",
    "weights = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "best = None\n",
    "for w in tqdm(weights, desc=\"Tune fusion weight\", mininterval=0.1, leave=True):\n",
    "    va_f = w*ranknorm(pva_tab) + (1-w)*ranknorm(pva_img_cal)\n",
    "    ap = average_precision_score(yva_cow.values.astype(int), va_f)\n",
    "    if (best is None) or (ap > best[0]):\n",
    "        best = (ap, w, va_f)\n",
    "ap_fuse, W, va_fused = best\n",
    "te_fused = W*ranknorm(pte_tab) + (1-W)*ranknorm(pte_img_cal)\n",
    "\n",
    "cal_f = LRCal(max_iter=1000, random_state=SEED).fit(va_fused.reshape(-1,1), yva_cow.values.astype(int))\n",
    "pva_f = cal_f.predict_proba(va_fused.reshape(-1,1))[:,1]\n",
    "pte_f = cal_f.predict_proba(te_fused.reshape(-1,1))[:,1]\n",
    "\n",
    "# ===== 10) Metrics & utilities =====\n",
    "def metr(name, y, p):\n",
    "    p = np.clip(p, 1e-9, 1-1e-9)\n",
    "    try: auc = roc_auc_score(y, p)\n",
    "    except: auc = np.nan\n",
    "    ap = average_precision_score(y, p); br = brier_score_loss(y, p)\n",
    "    return dict(name=name, AUROC=float(auc) if auc==auc else np.nan, AUPRC=float(ap), Brier=float(br), N=int(len(y)))\n",
    "\n",
    "rows = []\n",
    "rows.append(metr(\"VAL IMG only\",  yva_cow.values, pva_img_cal))\n",
    "rows.append(metr(\"TEST IMG only\", yte_cow.values, pte_img_cal))\n",
    "if tab_ready:\n",
    "    rows.append(metr(\"VAL TAB only\",  yva_cow.values, pva_tab))\n",
    "    rows.append(metr(\"TEST TAB only\", yte_cow.values, pte_tab))\n",
    "rows.append(metr(f\"VAL FUSION (w={W:.2f})\",  yva_cow.values, pva_f))\n",
    "rows.append(metr(f\"TEST FUSION (w={W:.2f})\", yte_cow.values, pte_f))\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "print(\"\\n=== Multimodal Summary ===\", flush=True)\n",
    "print(summary_df[[\"name\",\"AUROC\",\"AUPRC\",\"Brier\",\"N\"]].to_string(index=False), flush=True)\n",
    "\n",
    "# ===== 11) Robustness section: Bootstrap on TEST (AUROC, AUPRC) =====\n",
    "def bootstrap_metrics(y, p, n_boot=200, seed=SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y, dtype=int); p = np.asarray(p, dtype=float)\n",
    "    n = len(y)\n",
    "    aucs, aps = [], []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        yy, pp = y[idx], p[idx]\n",
    "        if len(np.unique(yy)) < 2:\n",
    "            aucs.append(np.nan)\n",
    "        else:\n",
    "            aucs.append(roc_auc_score(yy, pp))\n",
    "        aps.append(average_precision_score(yy, pp))\n",
    "    aucs = np.array(aucs, dtype=float); aps = np.array(aps, dtype=float)\n",
    "    def stat(x):\n",
    "        x = x[np.isfinite(x)]\n",
    "        if x.size == 0:\n",
    "            return dict(mean=np.nan, std=np.nan, ci_lo=np.nan, ci_hi=np.nan)\n",
    "        return dict(mean=float(np.mean(x)),\n",
    "                    std=float(np.std(x, ddof=1) if x.size>1 else 0.0),\n",
    "                    ci_lo=float(np.quantile(x, 0.025)),\n",
    "                    ci_hi=float(np.quantile(x, 0.975)))\n",
    "    return stat(aucs), stat(aps)\n",
    "\n",
    "boot_results = []\n",
    "def add_boot(name, y, p):\n",
    "    auc_s, ap_s = bootstrap_metrics(y, p, n_boot=200)\n",
    "    boot_results.append(dict(model=name,\n",
    "                             AUROC_mean=auc_s['mean'], AUROC_std=auc_s['std'], AUROC_ci_lo=auc_s['ci_lo'], AUROC_ci_hi=auc_s['ci_hi'],\n",
    "                             AUPRC_mean=ap_s['mean'], AUPRC_std=ap_s['std'], AUPRC_ci_lo=ap_s['ci_lo'], AUPRC_ci_hi=ap_s['ci_hi']))\n",
    "\n",
    "add_boot(\"TEST IMG only\", yte_cow.values, pte_img_cal)\n",
    "if tab_ready:\n",
    "    add_boot(\"TEST TAB only\", yte_cow.values, pte_tab)\n",
    "add_boot(f\"TEST FUSION (w={W:.2f})\", yte_cow.values, pte_f)\n",
    "\n",
    "boot_df = pd.DataFrame(boot_results)\n",
    "print(\"\\n=== Bootstrap (TEST) ===\")\n",
    "print(boot_df.to_string(index=False))\n",
    "\n",
    "# ===== 12) Threshold from VAL (max F1) + Confusion Matrix on TEST =====\n",
    "def best_thresh_by_f1(y, p):\n",
    "    prec, rec, thr = precision_recall_curve(y, p)\n",
    "    f1 = np.where((prec+rec) > 0, 2*prec*rec/(prec+rec), 0.0)\n",
    "    ix = int(np.nanargmax(f1))\n",
    "    if ix >= len(thr):\n",
    "        t = 0.5\n",
    "    else:\n",
    "        t = float(thr[ix])\n",
    "    return float(t), float(f1[ix] if ix < len(f1) else 0.0)\n",
    "\n",
    "# choose final score: FUSION (if tab_ready) else IMG only\n",
    "pva_final = (pva_f if tab_ready else pva_img_cal)\n",
    "pte_final = (pte_f if tab_ready else pte_img_cal)\n",
    "th_opt, f1_val = best_thresh_by_f1(yva_cow.values, pva_final)\n",
    "print(f\"\\n[Thresh] Best F1 on VAL: threshold={th_opt:.4f}, F1={f1_val:.4f}\")\n",
    "\n",
    "yte_pred = (pte_final >= th_opt).astype(int)\n",
    "cm = confusion_matrix(yte_cow.values, yte_pred, labels=[0,1])\n",
    "tn, fp, fn, tp = cm.ravel() if cm.size==4 else (cm[0,0], cm[0,1], cm[1,0], cm[1,1])\n",
    "acc = (tp+tn)/np.sum(cm)\n",
    "prec = tp/max(tp+fp, 1)\n",
    "rec  = tp/max(tp+fn, 1)\n",
    "f1_te = 2*prec*rec/max(prec+rec, 1e-9)\n",
    "print(f\"[ConfMat TEST] TP={tp} FP={fp} FN={fn} TN={tn} | Acc={acc:.3f} Prec={prec:.3f} Rec={rec:.3f} F1={f1_te:.3f}\")\n",
    "\n",
    "# ===== 13) Figures & Tables (save to FIGDIR, overwrite) =====\n",
    "def savefig(path):\n",
    "    plt.savefig(path, dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ROC & PR plots for VAL/TEST (final score)\n",
    "def plot_roc_pr(y, p, split_name):\n",
    "    # ROC\n",
    "    if len(np.unique(y)) > 1:\n",
    "        fpr, tpr, _ = roc_curve(y, p)\n",
    "        auc = roc_auc_score(y, p)\n",
    "    else:\n",
    "        fpr, tpr, auc = np.array([0,1]), np.array([0,1]), np.nan\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\" if auc==auc else \"AUC=N/A\")\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {split_name}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    savefig(os.path.join(FIGDIR, f\"roc_{split_name.lower().replace(' ','_')}.png\"))\n",
    "\n",
    "    # PR\n",
    "    prec, rec, _ = precision_recall_curve(y, p)\n",
    "    ap = average_precision_score(y, p)\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {split_name}\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    savefig(os.path.join(FIGDIR, f\"pr_{split_name.lower().replace(' ','_')}.png\"))\n",
    "\n",
    "# Confusion matrix plot for TEST\n",
    "def plot_confmat(cm, split_name=\"TEST\"):\n",
    "    plt.figure()\n",
    "    im = plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(f\"Confusion Matrix — {split_name}\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, ['0','1'])\n",
    "    plt.yticks(tick_marks, ['0','1'])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\", va=\"center\", fontsize=10)\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    savefig(os.path.join(FIGDIR, f\"confusion_matrix_{split_name.lower()}.png\"))\n",
    "\n",
    "# Plots\n",
    "plot_roc_pr(yva_cow.values, pva_final, \"VAL_final\")\n",
    "plot_roc_pr(yte_cow.values, pte_final, \"TEST_final\")\n",
    "plot_confmat(cm, \"TEST\")\n",
    "\n",
    "# Tables (CSV) — overwrite\n",
    "summary_df.to_csv(os.path.join(FIGDIR, \"summary_multimodal.csv\"), index=False)\n",
    "boot_df.to_csv(os.path.join(FIGDIR, \"bootstrap_test_metrics.csv\"), index=False)\n",
    "pd.DataFrame({\n",
    "    \"threshold\": [th_opt],\n",
    "    \"F1_VAL\": [f1_val],\n",
    "    \"Acc_TEST\": [acc],\n",
    "    \"Precision_TEST\": [prec],\n",
    "    \"Recall_TEST\": [rec],\n",
    "    \"F1_TEST\": [f1_te],\n",
    "    \"TP\":[tp], \"FP\":[fp], \"FN\":[fn], \"TN\":[tn]\n",
    "}).to_csv(os.path.join(FIGDIR, \"threshold_confmat_stats.csv\"), index=False)\n",
    "\n",
    "# ===== 14) Robust debug JSON (serialisable) =====\n",
    "def pyify(obj):\n",
    "    import numpy as _np\n",
    "    import torch as _torch\n",
    "    import pandas as _pd\n",
    "    if isinstance(obj, (_np.generic,)):\n",
    "        return obj.item()\n",
    "    if isinstance(obj, _torch.Tensor):\n",
    "        return obj.item() if obj.ndim == 0 else obj.detach().cpu().tolist()\n",
    "    if isinstance(obj, (_pd.Series, _pd.Index)):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: pyify(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [pyify(x) for x in obj]\n",
    "    if isinstance(obj, (np.ndarray,)):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "payload = dict(\n",
    "    device=str(DEVICE),\n",
    "    seed=int(SEED),\n",
    "    counts=dict(train_img=int(len(lab_tr)), val_img=int(len(lab_va)), test_img=int(len(lab_te))),\n",
    "    use_tab_split=bool(use_tab_split),\n",
    "    fusion_weight=float(W),\n",
    "    labels_dir=str(LABEL_DIR),\n",
    "    image_dir=str(IMAGE_DIR),\n",
    "    metrics=rows,\n",
    "    threshold=float(th_opt),\n",
    "    f1_val=float(f1_val),\n",
    "    confmat=dict(TP=int(tp), FP=int(fp), FN=int(fn), TN=int(tn))\n",
    ")\n",
    "with open(os.path.join(SAVE_DIR, \"debug_multimodal.json\"), \"w\") as f:\n",
    "    json.dump(pyify(payload), f, indent=2)\n",
    "\n",
    "print(f\"\\n[OK] Figures and tables saved to: {FIGDIR}\")\n",
    "print(f\"[OK] Quick summaries in: {SAVE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nQLUHTtebdc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQLUHTtebdc0",
    "outputId": "d32c04c1-12cb-4524-9336-3c2681efcbec"
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Cell 6.2 — SIMULATED cow mapping & \"true\" fusion (ablation)\n",
    "# - Generate a synthetic filename→Cow_ID_match mapping consistent with split and class\n",
    "# - Perform per-cow fusion using pva_img_cal/pte_img_cal\n",
    "# - Save figures/tables with suffix *_cowfusion_SIM (overwrite)\n",
    "# =======================\n",
    "import os, json, re, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression as LRCal\n",
    "from sklearn.metrics import (average_precision_score, roc_auc_score,\n",
    "                             precision_recall_curve, confusion_matrix, roc_curve)\n",
    "\n",
    "# --- context requirements\n",
    "need = ['lab_tr','lab_va','lab_te','pva_img_cal','pte_img_cal','Kva_i','Kte_i',\n",
    "        'train_df','val_df','test_df']\n",
    "for v in need:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"[SIM WARN] Missing '{v}'. Run Cell 6 first and ensure tabular DFs are in memory.\")\n",
    "\n",
    "KEY   = 'Cow_ID_match'\n",
    "LABEL_DIR = os.path.join(PROJECT_DIR, \"labels\")\n",
    "FIGDIR    = os.path.join(PROJECT_DIR, \"figures_and_tables\")\n",
    "os.makedirs(LABEL_DIR, exist_ok=True)\n",
    "os.makedirs(FIGDIR, exist_ok=True)\n",
    "\n",
    "print(\"\\n[SIM NOTICE] Generating a SYNTHETIC filename→Cow_ID_match mapping for a sensitivity experiment.\")\n",
    "print(\"             DO NOT USE these numbers as 'true multimodality' in the final paper.\\n\")\n",
    "\n",
    "# --- utilities\n",
    "def cows_posneg(df):\n",
    "    \"\"\"Return lists of positive and negative cows in the tabular split (cow label = max over visits).\"\"\"\n",
    "    g = df.groupby(KEY)['class1'].max().astype(int)\n",
    "    pos = g[g==1].index.astype(str).tolist()\n",
    "    neg = g[g==0].index.astype(str).tolist()\n",
    "    return pos, neg\n",
    "\n",
    "def simulated_map_for_split(img_df, tab_df, seed=42):\n",
    "    \"\"\"\n",
    "    Assign each image to a cow in the *same split* with the *same class*.\n",
    "    Multiple images may map to the same cow (allowed).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pos_cows, neg_cows = cows_posneg(tab_df)\n",
    "    out_rows = []\n",
    "    for _, r in img_df.iterrows():\n",
    "        fname = os.path.basename(r['abs_path'])\n",
    "        y = int(r['class1'])\n",
    "        pool = pos_cows if y==1 else neg_cows\n",
    "        if len(pool)==0:\n",
    "            # Fallback: if the split has no cows of that class, sample from the other set (rare)\n",
    "            pool = (pos_cows+neg_cows) if (pos_cows or neg_cows) else [f\"SIM{rng.integers(100000)}\"]\n",
    "        cow = str(rng.choice(pool))\n",
    "        out_rows.append((fname, cow))\n",
    "    return pd.DataFrame(out_rows, columns=['filename','cow_id_match'])\n",
    "\n",
    "# --- build mapping for the three splits\n",
    "sim_tr = simulated_map_for_split(lab_tr, train_df, seed=42)\n",
    "sim_va = simulated_map_for_split(lab_va, val_df,   seed=43)\n",
    "sim_te = simulated_map_for_split(lab_te, test_df,  seed=44)\n",
    "\n",
    "sim_map = pd.concat([sim_tr, sim_va, sim_te], axis=0, ignore_index=True)\n",
    "sim_map_path_csv  = os.path.join(LABEL_DIR, \"filename_to_cow_SIMULATED.csv\")\n",
    "sim_map_path_json = os.path.join(LABEL_DIR, \"filename_to_cow_SIMULATED.json\")\n",
    "sim_map.to_csv(sim_map_path_csv, index=False)\n",
    "json.dump({r['filename']: str(r['cow_id_match']) for _, r in sim_map.iterrows()},\n",
    "          open(sim_map_path_json, \"w\"), indent=2)\n",
    "print(f\"[SIM] Saved synthetic mapping:\\n      - {sim_map_path_csv}\\n      - {sim_map_path_json}\")\n",
    "\n",
    "# --- apply mapping to image DFs\n",
    "def apply_sim_map(df, sim_map):\n",
    "    df = df.copy()\n",
    "    df['filename'] = df['abs_path'].apply(os.path.basename)\n",
    "    m = sim_map.set_index('filename')['cow_id_match']\n",
    "    df[KEY] = df['filename'].map(m)\n",
    "    return df\n",
    "\n",
    "lab_tr_m = apply_sim_map(lab_tr, sim_map)\n",
    "lab_va_m = apply_sim_map(lab_va, sim_map)\n",
    "lab_te_m = apply_sim_map(lab_te, sim_map)\n",
    "\n",
    "print(f\"[SIM] Images mapped (per cow): train={lab_tr_m[KEY].notna().sum()} | val={lab_va_m[KEY].notna().sum()} | test={lab_te_m[KEY].notna().sum()}\")\n",
    "\n",
    "# --- rebuild Series p(img) indexed by filename (from Cell 6)\n",
    "pva_img_series = pd.Series(pva_img_cal, index=lab_va['abs_path'].apply(os.path.basename))\n",
    "pte_img_series = pd.Series(pte_img_cal, index=lab_te['abs_path'].apply(os.path.basename))\n",
    "\n",
    "# --- per-cow pooling (TopK=2 mean)\n",
    "def pool_by_cow(df_split_m, p_series, K=2):\n",
    "    g = df_split_m.groupby(KEY)['filename'].apply(list)\n",
    "    pooled = {}\n",
    "    for cow, files in g.items():\n",
    "        vals = [p_series.get(f, np.nan) for f in files]\n",
    "        vals = np.array([v for v in vals if np.isfinite(v)], dtype=float)\n",
    "        if vals.size == 0:\n",
    "            pooled[cow] = np.nan\n",
    "        else:\n",
    "            k = min(K, vals.size)\n",
    "            pooled[cow] = float(np.sort(vals)[-k:].mean())\n",
    "    return pd.Series(pooled).sort_index()\n",
    "\n",
    "# target per cow from images (any positive makes the cow positive)\n",
    "def cow_label_from_imgs(df_split_m):\n",
    "    return df_split_m.groupby(KEY)['class1'].max().astype(int).sort_index()\n",
    "\n",
    "yva_cow_img = cow_label_from_imgs(lab_va_m)\n",
    "yte_cow_img = cow_label_from_imgs(lab_te_m)\n",
    "pva_cow_img = pool_by_cow(lab_va_m, pva_img_series, K=2)\n",
    "pte_cow_img = pool_by_cow(lab_te_m, pte_img_series, K=2)\n",
    "\n",
    "# --- Platt calibration on VAL at cow-level\n",
    "cal_cow = LRCal(max_iter=1000, random_state=42).fit(pva_cow_img.values.reshape(-1,1), yva_cow_img.values)\n",
    "pva_cow_cal = cal_cow.predict_proba(pva_cow_img.values.reshape(-1,1))[:,1]\n",
    "pte_cow_cal = cal_cow.predict_proba(pte_cow_img.values.reshape(-1,1))[:,1]\n",
    "\n",
    "# --- align with tabular for true per-cow fusion (if pva_c/pte_c available)\n",
    "tab_ready = ('pva_c' in globals()) and ('pte_c' in globals())\n",
    "if tab_ready:\n",
    "    # pva_c/pte_c must be per-cow probabilities computed in Cell 5\n",
    "    pv_tab = pd.Series(pva_c).copy()\n",
    "    pt_tab = pd.Series(pte_c).copy()\n",
    "    pv_tab = pv_tab.reindex(yva_cow_img.index).fillna(0.0).values\n",
    "    pt_tab = pt_tab.reindex(yte_cow_img.index).fillna(0.0).values\n",
    "else:\n",
    "    pv_tab = np.zeros_like(pva_cow_cal); pt_tab = np.zeros_like(pte_cow_cal)\n",
    "    print(\"[SIM] pva_c/pte_c not present — fusion with tabular channel = 0 (placeholder).\")\n",
    "\n",
    "def ranknorm(x):\n",
    "    r = np.argsort(np.argsort(x))\n",
    "    return r / max(len(x)-1, 1)\n",
    "\n",
    "# tune fusion weight on VAL\n",
    "best = None\n",
    "for w in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
    "    va_f = w*ranknorm(pv_tab) + (1-w)*ranknorm(pva_cow_cal)\n",
    "    ap = average_precision_score(yva_cow_img.values, va_f)\n",
    "    if (best is None) or (ap > best[0]):\n",
    "        best = (ap, w, va_f)\n",
    "_, W_SIM, va_f = best\n",
    "te_f = W_SIM*ranknorm(pt_tab) + (1-W_SIM)*ranknorm(pte_cow_cal)\n",
    "\n",
    "def metr(y, p):\n",
    "    p = np.clip(p, 1e-9, 1-1e-9)\n",
    "    try: auc = roc_auc_score(y, p)\n",
    "    except: auc = np.nan\n",
    "    ap = average_precision_score(y, p)\n",
    "    return auc, ap\n",
    "\n",
    "auc_va_img, ap_va_img = metr(yva_cow_img.values, pva_cow_cal)\n",
    "auc_te_img, ap_te_img = metr(yte_cow_img.values, pte_cow_cal)\n",
    "auc_va_fus, ap_va_fus = metr(yva_cow_img.values, va_f)\n",
    "auc_te_fus, ap_te_fus = metr(yte_cow_img.values, te_f)\n",
    "\n",
    "print(\"\\n=== SIMULATED True Multimodal (per cow) — results FOR ABLATION ONLY ===\")\n",
    "print(f\"VAL IMG(cow):  AUC={auc_va_img:.3f}  AP={ap_va_img:.3f}\")\n",
    "print(f\"TEST IMG(cow): AUC={auc_te_img:.3f}  AP={ap_te_img:.3f}\")\n",
    "print(f\"VAL FUSION_SIM (w={W_SIM:.2f}):  AUC={auc_va_fus:.3f}  AP={ap_va_fus:.3f}\")\n",
    "print(f\"TEST FUSION_SIM (w={W_SIM:.2f}): AUC={auc_te_fus:.3f}  AP={ap_te_fus:.3f}\")\n",
    "\n",
    "# --- threshold from VAL (max F1) + confusion matrix on TEST\n",
    "def best_thresh_by_f1(y, p):\n",
    "    prec, rec, thr = precision_recall_curve(y, p)\n",
    "    f1 = np.where((prec+rec)>0, 2*prec*rec/(prec+rec), 0.0)\n",
    "    ix = int(np.nanargmax(f1))\n",
    "    t  = float(thr[ix]) if ix < len(thr) else 0.5\n",
    "    return t, float(f1[ix] if ix < len(f1) else 0.0)\n",
    "\n",
    "th_opt_sim, f1_val_sim = best_thresh_by_f1(yva_cow_img.values, va_f)\n",
    "yte_pred_sim = (te_f >= th_opt_sim).astype(int)\n",
    "cm_sim = confusion_matrix(yte_cow_img.values, yte_pred_sim, labels=[0,1])\n",
    "tn, fp, fn, tp = cm_sim.ravel() if cm_sim.size==4 else (cm_sim[0,0], cm_sim[0,1], cm_sim[1,0], cm_sim[1,1])\n",
    "\n",
    "print(f\"[SIM ConfMat TEST] TP={tp} FP={fp} FN={fn} TN={tn} | thr={th_opt_sim:.3f}\")\n",
    "\n",
    "# --- figures/tables with suffix _cowfusion_SIM (overwrite)\n",
    "def savefig(path): plt.savefig(path, dpi=200, bbox_inches='tight'); plt.close()\n",
    "\n",
    "def plot_roc_pr(y, p, split):\n",
    "    if len(np.unique(y))>1:\n",
    "        fpr,tpr,_= roc_curve(y,p); auc=roc_auc_score(y,p)\n",
    "    else:\n",
    "        fpr,tpr,auc = np.array([0,1]), np.array([0,1]), np.nan\n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr,label=f\"AUC={auc:.3f}\" if auc==auc else \"AUC=N/A\")\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.title(f\"ROC — {split} (cow-fusion SIM)\")\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "    savefig(os.path.join(FIGDIR, f\"roc_{split.lower()}_cowfusion_SIM.png\"))\n",
    "\n",
    "    prec, rec, _ = precision_recall_curve(y,p); ap = average_precision_score(y,p)\n",
    "    plt.figure()\n",
    "    plt.plot(rec,prec,label=f\"AP={ap:.3f}\")\n",
    "    plt.title(f\"PR — {split} (cow-fusion SIM)\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.legend(loc=\"lower left\")\n",
    "    savefig(os.path.join(FIGDIR, f\"pr_{split.lower()}_cowfusion_SIM.png\"))\n",
    "\n",
    "def plot_confmat(cm, split=\"TEST\"):\n",
    "    plt.figure()\n",
    "    im = plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(f\"Confusion Matrix — {split} (cow-fusion SIM)\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(2)\n",
    "    plt.xticks(ticks, ['0','1']); plt.yticks(ticks, ['0','1'])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\")\n",
    "    plt.ylabel('True'); plt.xlabel('Predicted')\n",
    "    savefig(os.path.join(FIGDIR, f\"confusion_matrix_{split.lower()}_cowfusion_SIM.png\"))\n",
    "\n",
    "# plots\n",
    "plot_roc_pr(yva_cow_img.values, va_f, \"VAL\")\n",
    "plot_roc_pr(yte_cow_img.values, te_f, \"TEST\")\n",
    "plot_confmat(cm_sim, \"TEST\")\n",
    "\n",
    "# csv\n",
    "pd.DataFrame({\n",
    "    \"name\": [\"VAL IMG(cow)\", \"TEST IMG(cow)\", f\"VAL FUSION_SIM (w={W_SIM:.2f})\", f\"TEST FUSION_SIM (w={W_SIM:.2f})\"],\n",
    "    \"AUROC\": [auc_va_img, auc_te_img, auc_va_fus, auc_te_fus],\n",
    "    \"AUPRC\": [ap_va_img,  ap_te_img,  ap_va_fus,  ap_te_fus]\n",
    "}).to_csv(os.path.join(FIGDIR, \"summary_multimodal_cowfusion_SIM.csv\"), index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"threshold_VAL\": [th_opt_sim],\n",
    "    \"F1_VAL\": [f1_val_sim],\n",
    "    \"TP\":[int(tp)], \"FP\":[int(fp)], \"FN\":[int(fn)], \"TN\":[int(tn)]\n",
    "}).to_csv(os.path.join(FIGDIR, \"threshold_confmat_stats_cowfusion_SIM.csv\"), index=False)\n",
    "\n",
    "print(f\"\\n[SIM DONE] Figures & tables saved to {FIGDIR} with suffix *_cowfusion_SIM (overwrite).\")\n",
    "print(\"           Reminder: these results are FOR ABLATION ONLY, not for true multimodal claims.\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0040813ff0cd45e9813d9579bde12d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3723580a8e804da5bbd463f9b647ba4c",
       "IPY_MODEL_cfa59ddb74954ca1863713448e5c6069",
       "IPY_MODEL_3de4de61d7624d3e8d15b7b05da8ac41"
      ],
      "layout": "IPY_MODEL_2c7ba2bcb485475994f5641abe1f414b"
     }
    },
    "10b33843a5de4f74bef9adf208e069a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "177bfa467e824e818308c41f09658ed0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19c3592d188741ba81ba73107a466521": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21a61fb301404629aec2af72b148d9e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d84e9e7c36584819863070d8e8461086",
      "placeholder": "​",
      "style": "IPY_MODEL_b4eee734d1514ed5bb50de503b902bd9",
      "value": " 1/1 [00:04&lt;00:00,  4.16s/it]"
     }
    },
    "25e6c579c5ae489398309d656aa32e0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bca1133286044e6964ad92352f36d81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_464dfddea91e4c688fa0838409865e71",
       "IPY_MODEL_ef4b391c0ef04e6c88743d596bd4ea9f",
       "IPY_MODEL_21a61fb301404629aec2af72b148d9e1"
      ],
      "layout": "IPY_MODEL_10b33843a5de4f74bef9adf208e069a7"
     }
    },
    "2c7ba2bcb485475994f5641abe1f414b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f758e6b2afb4a8da492c616c60f7849": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "355d4c84d28f4e20b25cd9ab66a4f4b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35740b40240140fd911ac1167cf8f426": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "365d6dee17774d58828e556dde603981": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36f5f156ec0b404581893008ff38f0d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3723580a8e804da5bbd463f9b647ba4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82abc872056e42bdb64c71cf0881c2f5",
      "placeholder": "​",
      "style": "IPY_MODEL_2f758e6b2afb4a8da492c616c60f7849",
      "value": "Parse YOLO labels: 100%"
     }
    },
    "3a569d4d197248979953810bc8336491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3de4de61d7624d3e8d15b7b05da8ac41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9b4abf2a12c4ea7a4c1e8d67b07c674",
      "placeholder": "​",
      "style": "IPY_MODEL_5052d672d6c3413296717ce9a136135c",
      "value": " 130/130 [00:00&lt;00:00, 356.89it/s]"
     }
    },
    "42ab98ff19554203a2d9398a5761bb6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7fb6e8da29824b6aa385b6135d468527",
       "IPY_MODEL_7b2170e89f244523b5fb33d5fac1b269",
       "IPY_MODEL_bb837636a30e483f87f99585459f229e"
      ],
      "layout": "IPY_MODEL_177bfa467e824e818308c41f09658ed0"
     }
    },
    "45b129b0e02044be91947fd3d3ebdf61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "464dfddea91e4c688fa0838409865e71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35740b40240140fd911ac1167cf8f426",
      "placeholder": "​",
      "style": "IPY_MODEL_f60bbe75133d4edd94f7fafcc3d7f671",
      "value": "Emb TR: 100%"
     }
    },
    "4bfbebf61f624c0886120b418da4e581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5052d672d6c3413296717ce9a136135c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "565605d8a7ff423980374c567a798e4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "57b7438bba33479dbdd31863139924aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "584291e3f7354d6593d90cccdad17f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_754991a906a742e687998ad8c59ff9c5",
      "placeholder": "​",
      "style": "IPY_MODEL_355d4c84d28f4e20b25cd9ab66a4f4b5",
      "value": " 1/1 [00:01&lt;00:00,  1.17s/it]"
     }
    },
    "686604bd1b404cdba47c42820744b194": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69706d6fb6af4a4dbaa212d8bf12aab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_877c2771634f47ee9d9ff094c31607e4",
      "max": 21355344,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd7c8f7ef97d4d48b96cca2f0c5b1e3e",
      "value": 21355344
     }
    },
    "73261c3d7323425a964b9e5668bb7d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "754991a906a742e687998ad8c59ff9c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "761f8b9a5a60457eaf81e25c56666979": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78d39e2b8ecb4f329289929e13a6fe58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b2170e89f244523b5fb33d5fac1b269": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_686604bd1b404cdba47c42820744b194",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36f5f156ec0b404581893008ff38f0d1",
      "value": 5
     }
    },
    "7bde952458634ca3affc7b5da336c02c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b7dab5f3624468eb31794b9ce146522",
       "IPY_MODEL_88ed134358974479b8ebda89c4a57baf",
       "IPY_MODEL_584291e3f7354d6593d90cccdad17f3c"
      ],
      "layout": "IPY_MODEL_cd612096be194ace89ea66ee30f3733b"
     }
    },
    "7fb6e8da29824b6aa385b6135d468527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daa698075c5c4ab98d4c8c13ae2ab843",
      "placeholder": "​",
      "style": "IPY_MODEL_a34ed149057e4bf1956ae348958c6b89",
      "value": "Tune fusion weight: 100%"
     }
    },
    "81cb4030115e4a4085199dd55bfb581f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea8eb88d98b04ca98b698c66bf81a4ec",
      "placeholder": "​",
      "style": "IPY_MODEL_78d39e2b8ecb4f329289929e13a6fe58",
      "value": " 1/1 [00:00&lt;00:00,  1.59it/s]"
     }
    },
    "81e335e27c414781916fdc0f58f24e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_914cb81fbe384ed4b3d94003879c5e4b",
       "IPY_MODEL_69706d6fb6af4a4dbaa212d8bf12aab9",
       "IPY_MODEL_ff783b51eb2f4dd891f767286e5efab9"
      ],
      "layout": "IPY_MODEL_965ff089fed04c4b9e7daf2ed4b8bb8a"
     }
    },
    "82abc872056e42bdb64c71cf0881c2f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "843fcb7a63574123ba12bcebe6e958f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87088db11a7d4dca93af4f618aa3da60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "877c2771634f47ee9d9ff094c31607e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ed134358974479b8ebda89c4a57baf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0efe8ff73b14d24a7477db5eeb33c0d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73261c3d7323425a964b9e5668bb7d41",
      "value": 1
     }
    },
    "8b7dab5f3624468eb31794b9ce146522": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_843fcb7a63574123ba12bcebe6e958f1",
      "placeholder": "​",
      "style": "IPY_MODEL_57b7438bba33479dbdd31863139924aa",
      "value": "Emb TE: 100%"
     }
    },
    "8dacc44bd6254ca791179544ee452671": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "914cb81fbe384ed4b3d94003879c5e4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_761f8b9a5a60457eaf81e25c56666979",
      "placeholder": "​",
      "style": "IPY_MODEL_f00ed51a7ba2432c836ecde7bcd64c1b",
      "value": "model.safetensors: 100%"
     }
    },
    "9198c13ea21a443e9cb2c971e14c0b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "965ff089fed04c4b9e7daf2ed4b8bb8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a34ed149057e4bf1956ae348958c6b89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3aaa65004734b359201c00b219b3955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5b229c2fb2f40abacbb86876475ade2",
       "IPY_MODEL_d2b17d81e6ae4c69bd4cad3c5694d842",
       "IPY_MODEL_81cb4030115e4a4085199dd55bfb581f"
      ],
      "layout": "IPY_MODEL_25e6c579c5ae489398309d656aa32e0f"
     }
    },
    "b4eee734d1514ed5bb50de503b902bd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5b229c2fb2f40abacbb86876475ade2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcc793eefece42db8f7d821450de948f",
      "placeholder": "​",
      "style": "IPY_MODEL_8dacc44bd6254ca791179544ee452671",
      "value": "Emb VA: 100%"
     }
    },
    "bb837636a30e483f87f99585459f229e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a569d4d197248979953810bc8336491",
      "placeholder": "​",
      "style": "IPY_MODEL_d40bf0f96c024829978cf1dd0843cd82",
      "value": " 5/5 [00:00&lt;00:00, 99.19it/s]"
     }
    },
    "c0efe8ff73b14d24a7477db5eeb33c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caff951dfad746b78078436787ca2bef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd612096be194ace89ea66ee30f3733b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfa59ddb74954ca1863713448e5c6069": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19c3592d188741ba81ba73107a466521",
      "max": 130,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_365d6dee17774d58828e556dde603981",
      "value": 130
     }
    },
    "d2b17d81e6ae4c69bd4cad3c5694d842": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45b129b0e02044be91947fd3d3ebdf61",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_565605d8a7ff423980374c567a798e4e",
      "value": 1
     }
    },
    "d40bf0f96c024829978cf1dd0843cd82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d84e9e7c36584819863070d8e8461086": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa698075c5c4ab98d4c8c13ae2ab843": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9b4abf2a12c4ea7a4c1e8d67b07c674": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea8eb88d98b04ca98b698c66bf81a4ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef4b391c0ef04e6c88743d596bd4ea9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bfbebf61f624c0886120b418da4e581",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9198c13ea21a443e9cb2c971e14c0b58",
      "value": 1
     }
    },
    "f00ed51a7ba2432c836ecde7bcd64c1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f60bbe75133d4edd94f7fafcc3d7f671": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcc793eefece42db8f7d821450de948f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd7c8f7ef97d4d48b96cca2f0c5b1e3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ff783b51eb2f4dd891f767286e5efab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_caff951dfad746b78078436787ca2bef",
      "placeholder": "​",
      "style": "IPY_MODEL_87088db11a7d4dca93af4f618aa3da60",
      "value": " 21.4M/21.4M [00:00&lt;00:00, 177kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
