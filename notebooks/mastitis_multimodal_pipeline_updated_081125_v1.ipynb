{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da4fcc29",
      "metadata": {
        "id": "da4fcc29"
      },
      "source": [
        "\n",
        "# IoT-based Multimodal Pipeline for Early Mastitis Detection\n",
        "This notebook provides a robust, leak-safe and energy-aware pipeline:\n",
        "- **Tabular model** on clinical ground truth (CSV)\n",
        "- **Imaging model** (frozen EfficientNet features + LR) on image labels\n",
        "- **Cross-modal bridge** (tab→image embeddings) enabling fusion even when cohorts are not perfectly aligned\n",
        "- **Fail-safe fusion** with proper clinical evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5175e241",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5175e241",
        "outputId": "b737067b-86a2-4716-9fce-36ab87689dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "IN_COLAB: True\n",
            "BASE_DRIVE: /content/drive/MyDrive\n",
            "PROJECT_ROOT: /content/drive/MyDrive/Mastitis_illness_cow  [OK]\n",
            "DATASETS_DIR: /content/drive/MyDrive/Mastitis_illness_cow/datasets  [OK]\n",
            "IMAGE_DIR: /content/drive/MyDrive/Mastitis_illness_cow/datasets/images  [OK]\n",
            "COCO_JSON_PATH: /content/drive/MyDrive/Mastitis_illness_cow/exports/_annotations.coco.json  [OK]\n",
            "TABULAR_CSV_PATH: /content/drive/MyDrive/Mastitis_illness_cow/datasets/clinical_mastitis_cows_version1.csv  [OK]\n",
            "MAPPING_CSV_PATH (optional): /content/drive/MyDrive/Mastitis_illness_cow/datasets/image_to_cow_map.csv  [OK]\n",
            "LABEL_DIR (legacy, unused with COCO): /content/drive/MyDrive/Mastitis_illness_cow/labels  [MISSING]\n"
          ]
        }
      ],
      "source": [
        "# ===== 1) Configuration & Paths =====\n",
        "# Goal: centralise environment detection (Colab vs local), pick robust paths to data (images/COCO/tabular),\n",
        "# and define runtime knobs (seeds, batch size, GPU toggle). This avoids path drift and makes runs reproducible.\n",
        "\n",
        "import os, random, json, re, glob, math, shutil, time, warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Detect whether we are in Google Colab ----------------------------------\n",
        "# Why: On Colab, data usually lives in Google Drive; locally, we use the current working directory.\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Mount Google Drive once. If already mounted, this is a no-op.\n",
        "    try:\n",
        "        drive.mount('/content/drive', force_remount=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "    BASE_DRIVE = Path(\"/content/drive/MyDrive\")\n",
        "else:\n",
        "    # Fallback: run relative to the current working directory.\n",
        "    BASE_DRIVE = Path(os.getcwd())\n",
        "\n",
        "# --- Helper to choose the first existing path from a list --------------------\n",
        "# Why: Users may keep data in slightly different locations; we accept multiple “candidates” and pick the first that exists.\n",
        "def first_existing(paths):\n",
        "    for p in paths:\n",
        "        p = Path(p)\n",
        "        if p.exists():\n",
        "            return p\n",
        "    return Path(\"\")\n",
        "\n",
        "# --- Project roots & dataset containers --------------------------------------\n",
        "# Why: Normalise the notion of \"project home\" and \"datasets\" so downstream code can be path-agnostic.\n",
        "PROJECT_ROOT_CANDIDATES = [\n",
        "    BASE_DRIVE / \"Mastitis_illness_cow\",\n",
        "    BASE_DRIVE / \"mastitis_illness_cow\",\n",
        "    Path(\"/mnt/data/Mastitis_illness_cow\"),\n",
        "    Path(os.getcwd()) / \"Mastitis_illness_cow\",\n",
        "]\n",
        "PROJECT_ROOT = first_existing(PROJECT_ROOT_CANDIDATES) or PROJECT_ROOT_CANDIDATES[0]\n",
        "\n",
        "DATASETS_DIR = first_existing([\n",
        "    PROJECT_ROOT / \"datasets\",   # your primary layout\n",
        "    PROJECT_ROOT / \"data\",\n",
        "    Path(\"/mnt/data\")\n",
        "]) or (PROJECT_ROOT / \"datasets\")\n",
        "\n",
        "# --- Canonical paths for images, COCO annotations, and tabular CSV ----------\n",
        "# Why: We avoid hard failures here; we only warn. Hard assertions will happen in the loading cell.\n",
        "IMAGE_DIR = first_existing([\n",
        "    DATASETS_DIR / \"images\",                # e.g., /.../datasets/images  (typical)\n",
        "    PROJECT_ROOT / \"images\",\n",
        "])\n",
        "COCO_JSON_PATH = first_existing([\n",
        "    PROJECT_ROOT / \"exports\" / \"_annotations.coco.json\",  # e.g., /.../exports/_annotations.coco.json\n",
        "    DATASETS_DIR / \"_annotations.coco.json\",\n",
        "    Path(\"/mnt/data/_annotations.coco.json\"),\n",
        "])\n",
        "TABULAR_CSV_PATH = first_existing([\n",
        "    DATASETS_DIR / \"clinical_mastitis_cows_version1.csv\", # e.g., /.../datasets/clinical_mastitis_cows_version1.csv\n",
        "    Path(\"/mnt/data/clinical_mastitis_cows_version1.csv\"),\n",
        "])\n",
        "# Optional explicit mapping file: filename -> Cow_ID (useful when image folders do not encode cow IDs)\n",
        "MAPPING_CSV_PATH = first_existing([\n",
        "    DATASETS_DIR / \"image_to_cow_map.csv\",\n",
        "])\n",
        "\n",
        "# Legacy label dir (unused with COCO; we keep it printed for visibility when migrating notebooks)\n",
        "LABEL_DIR = PROJECT_ROOT / \"labels\"\n",
        "\n",
        "# --- Runtime knobs: GPU, batch size, seeds -----------------------------------\n",
        "USE_GPU_FOR_IMAGE_MODEL = True\n",
        "BATCH_SIZE_IMAGE = 32\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "def seed_all_torch(seed=42):\n",
        "    \"\"\"\n",
        "    Set PyTorch seeds and deterministic flags if torch is available.\n",
        "    Rationale: helps reproducibility even on CuDNN-enabled setups.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import torch\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception:\n",
        "        # Torch not installed or GPU not present; silently ignore.\n",
        "        pass\n",
        "\n",
        "seed_all_torch(SEED)\n",
        "\n",
        "# --- Human-friendly path diagnostics (no hard stop here) ---------------------\n",
        "def exists_str(p: Path):\n",
        "    return f\"{str(p)}  [{'OK' if p and p.exists() else 'MISSING'}]\"\n",
        "\n",
        "print(\"IN_COLAB:\", IN_COLAB)\n",
        "print(\"BASE_DRIVE:\", BASE_DRIVE)\n",
        "print(\"PROJECT_ROOT:\", exists_str(PROJECT_ROOT))\n",
        "print(\"DATASETS_DIR:\", exists_str(DATASETS_DIR))\n",
        "print(\"IMAGE_DIR:\", exists_str(IMAGE_DIR))\n",
        "print(\"COCO_JSON_PATH:\", exists_str(COCO_JSON_PATH))\n",
        "print(\"TABULAR_CSV_PATH:\", exists_str(TABULAR_CSV_PATH))\n",
        "print(\"MAPPING_CSV_PATH (optional):\", exists_str(MAPPING_CSV_PATH))\n",
        "print(\"LABEL_DIR (legacy, unused with COCO):\", exists_str(LABEL_DIR))\n",
        "\n",
        "# Gentle warnings to catch misconfigurations early (we assert later in the load cell).\n",
        "if not IMAGE_DIR or not IMAGE_DIR.exists():\n",
        "    warnings.warn(\"IMAGE_DIR not found. Example: /content/drive/MyDrive/Mastitis_illness_cow/datasets/images\")\n",
        "if not COCO_JSON_PATH or not COCO_JSON_PATH.exists():\n",
        "    warnings.warn(\"COCO JSON not found. Expected: '.../exports/_annotations.coco.json'.\")\n",
        "if not TABULAR_CSV_PATH or not TABULAR_CSV_PATH.exists():\n",
        "    warnings.warn(\"Tabular CSV not found. Expected: '.../datasets/clinical_mastitis_cows_version1.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "105b4370",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "105b4370",
        "outputId": "b922d754-b1e4-40c9-f8ef-78502a173978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tabular] shape: (6600, 18)\n",
            "[Tabular] Columns: ['Cow_ID', 'Day', 'Breed', 'Months after giving birth', 'Previous_Mastits_status', 'IUFL', 'EUFL', 'IUFR', 'EUFR', 'IURL', 'EURL', 'IURR', 'EURR', 'Temperature', 'Hardness', 'Pain', 'Milk_visibility', 'class1']\n",
            "[CowID] unique: 1100\n",
            "[Target] positives: 1110 | negatives: 5490\n",
            "[TRY] RISK_NEXT@3visits | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_NEXT@5visits | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_NEXT@7visits | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_NEXT@10visits | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_NEXT@14visits | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_NEXT@21visits | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_NEXT@30visits | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_WITHIN@3days | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_WITHIN@5days | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_WITHIN@7days | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_WITHIN@10days | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_WITHIN@14days | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_WITHIN@21days | positive visits=0 | positive cows=0\n",
            "[TRY] RISK_WITHIN@30days | positive visits=0 | positive cows=0\n",
            "[FALLBACK] PROXIMITY@3vis | positive visits=185 | positive cows=185\n",
            "[CHOSEN] PROXIMITY_visits param=3 | visits pos=185 | cows pos=185 | N=6600\n",
            "[Split] Train cows: 660 | Val cows: 220 | Test cows: 220\n",
            "[READY] TASK_MODE='PROXIMITY_visits' | label='risk_next' | hyper=3\n"
          ]
        }
      ],
      "source": [
        "# ===== 2) ADAPTIVE TASK: RISK_NEXT (visits) → RISK_WITHIN (days) → fallback PROXIMITY =====\n",
        "# Goal: derive a robust visit-level target ('risk_next') for early diagnosis modeling.\n",
        "# Why adaptive? On small, noisy, or irregular time series, a single definition may be too sparse or too dense.\n",
        "# Strategy:\n",
        "#   (1) Try a visit-based lookahead: \"positive if any of the next K visits is positive\".\n",
        "#   (2) If that’s too sparse, try a time-based window: \"positive if an onset occurs within H days\".\n",
        "#   (3) If both fail thresholds, fall back to a proximity proxy (mark last K visits before first onset, including onset).\n",
        "# We also enforce leak-safe splits by cow so the same animal never leaks across train/val/test.\n",
        "\n",
        "import os, re, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Normalise cow IDs to a canonical form ('cow{N}') ------------------------\n",
        "# Rationale: imaging/fusion later expect consistent identifiers. This absorbs 'Cow_01', 'COW-003', 'cow12' → 'cow1'/'cow3'/'cow12'.\n",
        "def normalize_cow_id(x) -> str:\n",
        "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
        "        return \"\"\n",
        "    s = str(x).strip().lower()\n",
        "    m = re.search(r\"cow[_\\-]?(\\d+)\", s)\n",
        "    if m:\n",
        "        return f\"cow{int(m.group(1))}\"\n",
        "    # If no 'cow' token present, map bare digits to cowN as a fallback\n",
        "    m2 = re.search(r\"\\b(\\d{1,6})\\b\", s)\n",
        "    if m2:\n",
        "        return f\"cow{int(m2.group(1))}\"\n",
        "    return s\n",
        "\n",
        "# --- Ensure binary label semantics (0/1) -------------------------------------\n",
        "# Rationale: table labels may be {0,1}, {True,False}, or strings like 'yes'/'no'.\n",
        "def ensure_binary(arr, pos_values=(1, \"1\", True, \"true\", \"yes\", \"y\")):\n",
        "    y = pd.to_numeric(arr, errors=\"coerce\")\n",
        "    if y.isna().all():\n",
        "        # Map strings to binary if numerics fail entirely\n",
        "        y = arr.astype(str).str.lower().isin({str(v).lower() for v in pos_values}).astype(int)\n",
        "    else:\n",
        "        y = (y.fillna(0).astype(float) > 0).astype(int)\n",
        "    return y\n",
        "\n",
        "# --- Task aggressiveness thresholds ------------------------------------------\n",
        "# Why: We prefer a target with enough positives to be learnable but not trivial.\n",
        "K_LIST   = [3, 5, 7, 10, 14, 21, 30]   # lookahead in number of future visits\n",
        "H_LIST   = [3, 5, 7, 10, 14, 21, 30]   # lookahead horizon in days\n",
        "MIN_POS_VISITS = 50                    # minimum positive visits required\n",
        "MIN_POS_COWS   = 30                    # minimum cows with ≥1 positive visit\n",
        "\n",
        "# --- Load the tabular dataset as configured in Cell 1 ------------------------\n",
        "assert 'TABULAR_CSV_PATH' in globals(), \"TABULAR_CSV_PATH is not defined (check Cell 1).\"\n",
        "TABULAR_CSV_PATH = Path(TABULAR_CSV_PATH)\n",
        "if not TABULAR_CSV_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Tabular CSV not found at: {TABULAR_CSV_PATH}\")\n",
        "\n",
        "tab = pd.read_csv(TABULAR_CSV_PATH)\n",
        "print(\"[Tabular] shape:\", tab.shape)\n",
        "print(\"[Tabular] Columns:\", list(tab.columns))\n",
        "\n",
        "# --- Auto-detect key columns (ID, time, label) --------------------------------\n",
        "# Why: supports light schema drift while keeping the notebook reusable.\n",
        "COW_ID_COL = next((c for c in [\"Cow_ID\",\"cow_id\",\"CowID\",\"animal_id\",\"Animal_ID\",\"subject_id\",\"id\",\"ID\"] if c in tab.columns), None)\n",
        "TIME_COL   = next((c for c in [\"Day\",\"day\",\"time\",\"Time\",\"Days\",\"days\"] if c in tab.columns), None)\n",
        "RAW_TARGET = next((c for c in [\"class1\",\"Class1\",\"Label\",\"label\",\"mastitis\",\"status\",\"target\",\"class\",\"disease\",\"outcome\",\"y\"] if c in tab.columns), None)\n",
        "if COW_ID_COL is None: raise KeyError(\"Cow ID column not found. Expected one of: Cow_ID, cow_id, CowID, animal_id, ...\")\n",
        "if TIME_COL   is None: raise KeyError(\"Time column not found (e.g., 'Day').\")\n",
        "if RAW_TARGET is None: raise KeyError(\"Binary target column not found (e.g., 'class1').\")\n",
        "\n",
        "# --- Normalise identifiers and coerce types ----------------------------------\n",
        "tab = tab.copy()\n",
        "tab[\"Cow_ID_match\"] = tab[COW_ID_COL].apply(normalize_cow_id)  # canonical cow id\n",
        "KEY = \"Cow_ID_match\"\n",
        "\n",
        "tab[TIME_COL]   = pd.to_numeric(tab[TIME_COL], errors=\"coerce\")\n",
        "tab[RAW_TARGET] = ensure_binary(tab[RAW_TARGET])\n",
        "tab = tab[tab[KEY] != \"\"].copy().sort_values([KEY, TIME_COL]).reset_index(drop=True)\n",
        "\n",
        "print(\"[CowID] unique:\", tab[KEY].nunique())\n",
        "print(\"[Target] positives:\", int(tab[RAW_TARGET].sum()), \"| negatives:\", int((1 - tab[RAW_TARGET]).sum()))\n",
        "\n",
        "# --- Label builders: three options with complementary assumptions ------------\n",
        "def build_risk_nextK_visits(df, K=3, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET):\n",
        "    \"\"\"\n",
        "    Visit-based risk: mark a visit as 1 if any of the next K visits is positive.\n",
        "    We exclude visits that are already positive at time t (set to -1 and later filtered out).\n",
        "    Why: aligns with clinical “what happens next” framing for discrete schedules.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for cow, g in df.groupby(key, sort=False):\n",
        "        g = g.sort_values(tcol, na_position=\"last\").reset_index(drop=True)\n",
        "        y = g[ycol].to_numpy(dtype=int)\n",
        "        n = len(g)\n",
        "        rn = np.full(n, -1, dtype=int)\n",
        "        for t in range(n):\n",
        "            if y[t] == 1:\n",
        "                rn[t] = -1          # exclude current-onset visits from inputs\n",
        "            else:\n",
        "                t2 = min(n-1, t + K)\n",
        "                rn[t] = int((y[t+1:t2+1] == 1).any()) if t < n-1 else 0\n",
        "        g2 = g.copy(); g2[\"risk_next\"] = rn\n",
        "        out.append(g2)\n",
        "    out = pd.concat(out, ignore_index=True)\n",
        "    out = out.query(\"risk_next != -1\").copy()\n",
        "    out[\"risk_next\"] = out[\"risk_next\"].astype(int)\n",
        "    return out\n",
        "\n",
        "def build_risk_withinH_days(df, H=7, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET):\n",
        "    \"\"\"\n",
        "    Time-based risk: mark a visit as 1 if a positive event occurs within H days after this visit.\n",
        "    We exclude visits already positive at time t.\n",
        "    Why: respects irregular sampling in days rather than visit counts.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for cow, g in df.groupby(key, sort=False):\n",
        "        g = g.sort_values(tcol, na_position=\"last\").reset_index(drop=True)\n",
        "        y = g[ycol].to_numpy(dtype=int)\n",
        "        tvals = g[tcol].to_numpy(dtype=float)\n",
        "        n = len(g)\n",
        "        rn = np.zeros(n, dtype=int)\n",
        "        for t in range(n):\n",
        "            if y[t] == 1:\n",
        "                rn[t] = -1\n",
        "            else:\n",
        "                future_idx = np.where((tvals > tvals[t]) & (tvals - tvals[t] <= H))[0]\n",
        "                rn[t] = int(any(y[j] == 1 for j in future_idx))\n",
        "        g2 = g.copy(); g2[\"risk_next\"] = rn\n",
        "        out.append(g2)\n",
        "    out = pd.concat(out, ignore_index=True)\n",
        "    out = out.query(\"risk_next != -1\").copy()\n",
        "    out[\"risk_next\"] = out[\"risk_next\"].astype(int)\n",
        "    return out\n",
        "\n",
        "def build_proximity_visit_level(df, K=3, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET):\n",
        "    \"\"\"\n",
        "    Proximity proxy: mark as 1 the last K visits before the first onset, including the onset itself.\n",
        "    Why: if genuine forecasting windows are too sparse, this yields a learnable pre-onset signal.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for cow, g in df.groupby(key, sort=False):\n",
        "        g = g.sort_values(tcol, na_position=\"last\").reset_index(drop=True)\n",
        "        y = g[ycol].to_numpy(dtype=int)\n",
        "        n = len(g)\n",
        "        rn = np.zeros(n, dtype=int)\n",
        "        pos = np.where(y == 1)[0]\n",
        "        if len(pos) > 0:\n",
        "            i0 = int(pos[0])                # first onset index\n",
        "            j0 = max(0, i0 - (K - 1))       # include K-1 visits before onset\n",
        "            rn[j0:i0+1] = 1\n",
        "        g2 = g.copy(); g2[\"risk_next\"] = rn\n",
        "        out.append(g2)\n",
        "    out = pd.concat(out, ignore_index=True)\n",
        "    out[\"risk_next\"] = out[\"risk_next\"].astype(int)\n",
        "    return out\n",
        "\n",
        "# --- Adaptive selection: try visit-based, then time-based, else proximity ----\n",
        "chosen = None\n",
        "\n",
        "# (1) Next-K visits\n",
        "for K in K_LIST:\n",
        "    cand = build_risk_nextK_visits(tab, K=K, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET)\n",
        "    pos_v = int((cand[\"risk_next\"] == 1).sum())\n",
        "    pos_c = int(cand.groupby(KEY)[\"risk_next\"].max().sum())\n",
        "    print(f\"[TRY] RISK_NEXT@{K}visits | positive visits={pos_v} | positive cows={pos_c}\")\n",
        "    if pos_v >= MIN_POS_VISITS and pos_c >= MIN_POS_COWS:\n",
        "        chosen = (\"RISK_NEXT_visits\", K, cand); break\n",
        "\n",
        "# (2) Within-H days\n",
        "if chosen is None:\n",
        "    for H in H_LIST:\n",
        "        cand = build_risk_withinH_days(tab, H=H, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET)\n",
        "        pos_v = int((cand[\"risk_next\"] == 1).sum())\n",
        "        pos_c = int(cand.groupby(KEY)[\"risk_next\"].max().sum())\n",
        "        print(f\"[TRY] RISK_WITHIN@{H}days | positive visits={pos_v} | positive cows={pos_c}\")\n",
        "        if pos_v >= MIN_POS_VISITS and pos_c >= MIN_POS_COWS:\n",
        "            chosen = (\"RISK_WITHIN_days\", H, cand); break\n",
        "\n",
        "# (3) Fallback: proximity around onset\n",
        "if chosen is None:\n",
        "    K_fallback = 3\n",
        "    cand = build_proximity_visit_level(tab, K=K_fallback, key=KEY, tcol=TIME_COL, ycol=RAW_TARGET)\n",
        "    pos_v = int((cand[\"risk_next\"] == 1).sum())\n",
        "    pos_c = int(cand.groupby(KEY)[\"risk_next\"].max().sum())\n",
        "    print(f\"[FALLBACK] PROXIMITY@{K_fallback}vis | positive visits={pos_v} | positive cows={pos_c}\")\n",
        "    chosen = (\"PROXIMITY_visits\", K_fallback, cand)\n",
        "\n",
        "TASK_MODE, HYPER, df_risk = chosen\n",
        "print(f\"[CHOSEN] {TASK_MODE} param={HYPER} | visits pos={int((df_risk['risk_next']==1).sum())} \"\n",
        "      f\"| cows pos={int(df_risk.groupby(KEY)['risk_next'].max().sum())} | N={len(df_risk)}\")\n",
        "\n",
        "# --- Leak-safe split by cow: no animal appears in multiple splits ------------\n",
        "# Why: prevents identity leakage; ensures generalisation across animals rather than across visits from the same cow.\n",
        "cow_any = df_risk.groupby(KEY)[\"risk_next\"].max().astype(int)\n",
        "all_cows = np.array(sorted(cow_any.index.astype(str)))\n",
        "y_cows   = cow_any.reindex(all_cows).values\n",
        "\n",
        "if len(np.unique(y_cows)) < 2:\n",
        "    # If stratification is impossible (single class across cows), use plain split.\n",
        "    print(\"[WARN] Single-class across cows. Falling back to non-stratified split.\")\n",
        "    tr_c, te_c = train_test_split(all_cows, test_size=0.20, random_state=42)\n",
        "else:\n",
        "    tr_c, te_c = train_test_split(all_cows, test_size=0.20, stratify=y_cows, random_state=42)\n",
        "\n",
        "mask_tv = np.isin(all_cows, tr_c)\n",
        "tv_cows = all_cows[mask_tv]\n",
        "tv_y    = cow_any.reindex(tv_cows).values\n",
        "\n",
        "if len(np.unique(tv_y)) < 2:\n",
        "    tr_cows, val_cows = train_test_split(tv_cows, test_size=0.25, random_state=42)\n",
        "else:\n",
        "    tr_cows, val_cows = train_test_split(tv_cows, test_size=0.25, stratify=tv_y, random_state=42)\n",
        "\n",
        "print(f\"[Split] Train cows: {len(tr_cows)} | Val cows: {len(val_cows)} | Test cows: {len(te_c)}\")\n",
        "print(f\"[READY] TASK_MODE='{TASK_MODE}' | label='risk_next' | hyper={HYPER}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 2.5) Visit-level feature engineering (leak-safe) & cow-aligned splits =====\n",
        "# Goal: build leakage-safe visit-level features with cows strictly disjoint across splits.\n",
        "# Why: ensures fair generalisation (no identity leakage) and stable training.\n",
        "# Design notes:\n",
        "#   • We derive features *within each split* only (no cross-split stats).\n",
        "#   • We keep a single, clean key (KEY) and a single, integer target (YCOL).\n",
        "#   • We handle both \"Day\" and custom time columns via TIME_COL from Cell 2.\n",
        "#   • We drop degenerate (all-NaN / zero-variance) features based on TRAIN only.\n",
        "#   • We optionally keep only the K most recent visits per cow to focus on near-term risk.\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---------- Preconditions & context ------------------------------------------\n",
        "assert 'tab' in globals(), \"Run Cell 2 first: the DataFrame 'tab' is missing.\"\n",
        "assert 'TIME_COL' in globals() and isinstance(TIME_COL, str), \"TIME_COL must be defined in Cell 2.\"\n",
        "KEY = \"Cow_ID_match\"\n",
        "\n",
        "# Target detection with graceful fallback\n",
        "YCOL_CANDIDATES = [\"risk_next\", \"early\", \"class1\", \"Label\", \"label\"]\n",
        "YCOL = next((c for c in YCOL_CANDIDATES if c in tab.columns), None)\n",
        "if YCOL is None:\n",
        "    raise KeyError(f\"No target column found in 'tab'. Expected one of: {YCOL_CANDIDATES}\")\n",
        "if KEY not in tab.columns:\n",
        "    raise KeyError(f\"Key '{KEY}' missing in 'tab'; please verify Cell 2.\")\n",
        "\n",
        "# ---------- Robust utilities: ensure a single key/target ---------------------\n",
        "def coerce_and_dedup_target(df: pd.DataFrame, ycol: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Ensure a single integer target column ycol exists in df.\n",
        "    Rationale: merged frames or accidental duplicates can create multiple same-named columns.\n",
        "    Strategy:\n",
        "      - If missing → create zeros.\n",
        "      - If one    → numeric cast + fillna(0) + int.\n",
        "      - If many   → numeric-cast then row-wise max (OR-like).\n",
        "    \"\"\"\n",
        "    cols = [c for c in df.columns if c == ycol]\n",
        "    if len(cols) == 0:\n",
        "        df[ycol] = 0\n",
        "        return df\n",
        "    if len(cols) == 1:\n",
        "        df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\").fillna(0).astype(int)\n",
        "        return df\n",
        "    comb = df[cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0).max(axis=1).astype(int)\n",
        "    df = df.drop(columns=cols, errors=\"ignore\")\n",
        "    df[ycol] = comb\n",
        "    return df\n",
        "\n",
        "def coerce_and_dedup_key(df: pd.DataFrame, key: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Ensure a single clean key column exists in df.\n",
        "    Why: downstream joins/splits assume a unique cow ID; duplicates can appear after merges.\n",
        "    Strategy:\n",
        "      - If one column → cast to str.\n",
        "      - If multiple   → take first non-NaN per row (backfill across duplicates) and keep that.\n",
        "    \"\"\"\n",
        "    cols = [c for c in df.columns if c == key]\n",
        "    if len(cols) == 0:\n",
        "        raise KeyError(f\"Key '{key}' absent after preprocessing.\")\n",
        "    if len(cols) == 1:\n",
        "        df[key] = df[key].astype(str)\n",
        "        return df\n",
        "    tmp = (df[cols].astype(str).replace({\"nan\": np.nan, \"None\": np.nan}))\n",
        "    comb = tmp.bfill(axis=1).iloc[:, 0].astype(str)\n",
        "    df = df.drop(columns=cols, errors=\"ignore\")\n",
        "    df[key] = comb\n",
        "    return df\n",
        "\n",
        "# Apply initial de-duplication on 'tab'\n",
        "tab = coerce_and_dedup_key(tab, KEY)\n",
        "tab = coerce_and_dedup_target(tab, YCOL)\n",
        "\n",
        "# ---------- Ensure we have cow-based splits; rebuild if missing --------------\n",
        "# Why: keep cows disjoint across train/val/test; this avoids identity leakage.\n",
        "if not all(k in globals() for k in [\"tr_cows\", \"val_cows\", \"test_cows\"]):\n",
        "    print(\"[2.5 Fallback] Rebuilding cow-based splits…\")\n",
        "    cow_y = tab.groupby(KEY)[YCOL].max().astype(int)\n",
        "    all_cows = np.array(sorted(cow_y.index.astype(str)))\n",
        "    if cow_y.nunique() < 2:\n",
        "        # No stratification possible; still enforce disjointness.\n",
        "        tr_all, te_all = train_test_split(all_cows, test_size=0.20, random_state=42, shuffle=True)\n",
        "    else:\n",
        "        tr_all, te_all = train_test_split(\n",
        "            all_cows, test_size=0.20,\n",
        "            stratify=cow_y.reindex(all_cows).values, random_state=42\n",
        "        )\n",
        "    tv_labels = cow_y.reindex(tr_all).values\n",
        "    if len(np.unique(tv_labels)) < 2:\n",
        "        tr_cows, val_cows = train_test_split(tr_all, test_size=0.25, random_state=42, shuffle=True)\n",
        "    else:\n",
        "        tr_cows, val_cows = train_test_split(\n",
        "            tr_all, test_size=0.25, stratify=tv_labels, random_state=42\n",
        "        )\n",
        "    test_cows = te_all\n",
        "    print(f\"[2.5 Fallback] Train cows: {len(tr_cows)} | Val cows: {len(val_cows)} | Test cows: {len(test_cows)}\")\n",
        "\n",
        "# ---------- Visit-ordered base copy ------------------------------------------\n",
        "# We preserve visit order per cow using TIME_COL when present; otherwise we synthesise a visit index.\n",
        "base = tab.copy()\n",
        "if TIME_COL in base.columns:\n",
        "    base = base.sort_values([KEY, TIME_COL]).reset_index(drop=True)\n",
        "else:\n",
        "    base = (\n",
        "        base.sort_values([KEY])\n",
        "            .assign(_visit_idx = base.groupby(KEY).cumcount())\n",
        "            .sort_values([KEY, \"_visit_idx\"])\n",
        "            .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "# ---------- Select numeric columns for feature engineering -------------------\n",
        "# Exclusions: key, target, and known non-numeric metadata. Extend as needed for your schema.\n",
        "exclude_cols = {KEY, YCOL, \"Cow_ID_norm\", \"onset_day\", \"Breed\", \"Previous_Mastits_status\"}\n",
        "num_cols_all = (\n",
        "    base.drop(columns=[c for c in exclude_cols if c in base.columns], errors=\"ignore\")\n",
        "        .select_dtypes(include=[np.number])\n",
        "        .columns.tolist()\n",
        ")\n",
        "if len(num_cols_all) == 0:\n",
        "    raise RuntimeError(\"No numeric columns available for feature engineering. Verify input schema and exclusions.\")\n",
        "\n",
        "# ---------- Helper utilities -------------------------------------------------\n",
        "def split_by_cows(df, cows):\n",
        "    \"\"\"Return only rows whose cow id is in the provided list. Keeps splits leak-safe by construction.\"\"\"\n",
        "    return df[df[KEY].astype(str).isin(set(map(str, cows)))].reset_index(drop=True)\n",
        "\n",
        "def add_time_features(df: pd.DataFrame, num_cols) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build per-cow temporal features (leak-safe) computed *within each split*:\n",
        "      • lag1 for each numeric variable (captures short-term trend),\n",
        "      • rolling means over 3 and 5 visits (local smoothing),\n",
        "      • first differences on raw and rolling means (change signals),\n",
        "      • per-cow expanding z-score (normalises by each cow’s evolving baseline).\n",
        "    Missing values from shifts/rolling are set to 0 for robustness.\n",
        "    \"\"\"\n",
        "    d = df.copy()\n",
        "    d = coerce_and_dedup_key(d, KEY)\n",
        "\n",
        "    # Visit order: prefer TIME_COL if present, else synthetic index.\n",
        "    if TIME_COL in d.columns:\n",
        "        d = d.sort_values([KEY, TIME_COL]).reset_index(drop=True)\n",
        "    else:\n",
        "        if \"_visit_idx\" not in d.columns:\n",
        "            d[\"_visit_idx\"] = d.groupby(KEY).cumcount()\n",
        "        d = d.sort_values([KEY, \"_visit_idx\"]).reset_index(drop=True)\n",
        "\n",
        "    for c in num_cols:\n",
        "        grp = d.groupby(KEY)[c]\n",
        "\n",
        "        # lag-1\n",
        "        d[f\"{c}_lag1\"] = grp.shift(1)\n",
        "\n",
        "        # rolling means (3, 5)\n",
        "        r3 = grp.rolling(3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        r5 = grp.rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        d[f\"{c}_r3_mean\"] = r3\n",
        "        d[f\"{c}_r5_mean\"] = r5\n",
        "\n",
        "        # first differences (raw + rolling)\n",
        "        d[f\"{c}_d1\"]    = grp.diff(1)\n",
        "        d[f\"{c}_r3_d1\"] = d[f\"{c}_r3_mean\"].groupby(d[KEY]).diff(1)\n",
        "        d[f\"{c}_r5_d1\"] = d[f\"{c}_r5_mean\"].groupby(d[KEY]).diff(1)\n",
        "\n",
        "        # expanding z-score per cow (adaptive baseline over time)\n",
        "        exp_mean = grp.expanding().mean().reset_index(level=0, drop=True)\n",
        "        exp_std  = grp.expanding().std().reset_index(level=0, drop=True).replace(0, np.nan)\n",
        "        z = (d[c] - exp_mean) / exp_std\n",
        "        d[f\"{c}_z_cow\"] = z.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # New feature columns (not in original df)\n",
        "    fe_cols = [c for c in d.columns if c not in df.columns]\n",
        "    d[fe_cols] = d[fe_cols].fillna(0)\n",
        "\n",
        "    # Final hygiene: ensure a single clean key.\n",
        "    d = coerce_and_dedup_key(d, KEY)\n",
        "    return d\n",
        "\n",
        "def take_last_k(df, k=6):\n",
        "    \"\"\"\n",
        "    Keep only the last k visits per cow (focus on recent history).\n",
        "    If TIME_COL is absent, use a synthetic visit index to define recency.\n",
        "    \"\"\"\n",
        "    d = coerce_and_dedup_key(df.copy(), KEY)\n",
        "    if TIME_COL in d.columns:\n",
        "        d[\"_rank_last\"] = d.groupby(KEY)[TIME_COL].rank(method=\"first\", ascending=False)\n",
        "    else:\n",
        "        if \"_visit_idx\" not in d.columns:\n",
        "            d[\"_visit_idx\"] = d.groupby(KEY).cumcount()\n",
        "        d[\"_rank_last\"] = d.groupby(KEY)[\"_visit_idx\"].rank(method=\"first\", ascending=False)\n",
        "    out = d[d[\"_rank_last\"] <= k].drop(columns=[\"_rank_last\"])\n",
        "    return coerce_and_dedup_key(out.reset_index(drop=True), KEY)\n",
        "\n",
        "def drop_degenerate(train_df, val_df, test_df, key, ycol):\n",
        "    \"\"\"\n",
        "    Drop degenerate features using TRAIN statistics only:\n",
        "      • columns all-NaN on TRAIN,\n",
        "      • zero-variance columns on TRAIN.\n",
        "    Then align VAL/TEST to the kept set. Preserve key/target/time/index helpers.\n",
        "    \"\"\"\n",
        "    # Ensure exactly one key/target column each.\n",
        "    train_df = coerce_and_dedup_key(coerce_and_dedup_target(train_df, ycol), key)\n",
        "    val_df   = coerce_and_dedup_key(coerce_and_dedup_target(val_df,   ycol), key)\n",
        "    test_df  = coerce_and_dedup_key(coerce_and_dedup_target(test_df,  ycol), key)\n",
        "\n",
        "    keep = []\n",
        "    for c in train_df.columns:\n",
        "        if c in {key, ycol, TIME_COL, \"_visit_idx\", \"Cow_ID_norm\"}:\n",
        "            keep.append(c); continue\n",
        "        if str(train_df[c].dtype).startswith((\"float\",\"int\")):\n",
        "            col = train_df[c]\n",
        "            if col.isna().all():\n",
        "                continue\n",
        "            if col.nunique(dropna=True) <= 1:\n",
        "                continue\n",
        "            keep.append(c)\n",
        "    tr2 = train_df[[k for k in keep if k in train_df.columns] + [key, ycol]].copy()\n",
        "    va2 = val_df[[k for k in keep if k in val_df.columns] + [key, ycol]].copy()\n",
        "    te2 = test_df[[k for k in keep if k in test_df.columns] + [key, ycol]].copy()\n",
        "\n",
        "    # Final hygiene\n",
        "    tr2 = coerce_and_dedup_key(coerce_and_dedup_target(tr2, ycol), key)\n",
        "    va2 = coerce_and_dedup_key(coerce_and_dedup_target(va2, ycol), key)\n",
        "    te2 = coerce_and_dedup_key(coerce_and_dedup_target(te2, ycol), key)\n",
        "\n",
        "    dropped = sorted(list(set(train_df.columns) - set(tr2.columns)))\n",
        "    return tr2, va2, te2, dropped\n",
        "\n",
        "def safe_target_series(df: pd.DataFrame, ycol: str) -> pd.Series:\n",
        "    \"\"\"Return a single integer Series for the target, consolidating multi-columns if needed.\"\"\"\n",
        "    obj = df[ycol]\n",
        "    if isinstance(obj, pd.DataFrame):\n",
        "        y = obj.apply(pd.to_numeric, errors=\"coerce\").fillna(0).max(axis=1)\n",
        "    else:\n",
        "        y = pd.to_numeric(obj, errors=\"coerce\").fillna(0)\n",
        "    return y.astype(int)\n",
        "\n",
        "def count_pos_visits(df, ycol):\n",
        "    \"\"\"Number of visits labelled positive (1).\"\"\"\n",
        "    y = safe_target_series(df, ycol)\n",
        "    return int((y == 1).sum())\n",
        "\n",
        "def count_pos_cows(df, key, ycol):\n",
        "    \"\"\"Number of cows with at least one positive visit (max over visits per cow).\"\"\"\n",
        "    df = coerce_and_dedup_key(df.copy(), key)\n",
        "    y = safe_target_series(df, ycol)\n",
        "    per_cow = df.assign(__y=y).groupby(key)[\"__y\"].max()\n",
        "    return int(per_cow.sum())\n",
        "\n",
        "# ---------- Split-specific (no-leak) feature engineering ---------------------\n",
        "# Why: compute temporal stats (lags/rolling/expanding) separately per split to avoid leakage.\n",
        "train_raw = split_by_cows(base, tr_cows)\n",
        "val_raw   = split_by_cows(base, val_cows)\n",
        "test_raw  = split_by_cows(base, test_cows)\n",
        "\n",
        "# De-duplicate key/target BEFORE feature engineering (stability).\n",
        "train_raw = coerce_and_dedup_key(coerce_and_dedup_target(train_raw, YCOL), KEY)\n",
        "val_raw   = coerce_and_dedup_key(coerce_and_dedup_target(val_raw,   YCOL), KEY)\n",
        "test_raw  = coerce_and_dedup_key(coerce_and_dedup_target(test_raw,  YCOL), KEY)\n",
        "\n",
        "train_fe = add_time_features(train_raw, num_cols_all)\n",
        "val_fe   = add_time_features(val_raw,   num_cols_all)\n",
        "test_fe  = add_time_features(test_raw,  num_cols_all)\n",
        "\n",
        "# ---------- Optional: keep only the last K visits per cow --------------------\n",
        "V_LAST = 6  # tune as needed\n",
        "train_sel = take_last_k(train_fe, V_LAST)\n",
        "val_sel   = take_last_k(val_fe,   V_LAST)\n",
        "test_sel  = take_last_k(test_fe,  V_LAST)\n",
        "\n",
        "# De-duplicate key/target AGAIN (post FE/filters)\n",
        "train_sel = coerce_and_dedup_key(coerce_and_dedup_target(train_sel, YCOL), KEY)\n",
        "val_sel   = coerce_and_dedup_key(coerce_and_dedup_target(val_sel,   YCOL), KEY)\n",
        "test_sel  = coerce_and_dedup_key(coerce_and_dedup_target(test_sel,  YCOL), KEY)\n",
        "\n",
        "# ---------- Drop degenerate features (train-driven) --------------------------\n",
        "train_df, val_df, test_df, dropped_cols = drop_degenerate(train_sel, val_sel, test_sel, KEY, YCOL)\n",
        "\n",
        "# ---------- Diagnostics -------------------------------------------------------\n",
        "print(f\"[FE-visit] rows — TRAIN {train_df.shape} | VAL {val_df.shape} | TEST {test_df.shape}\")\n",
        "print(f\"[FE-visit] visits+ ({YCOL}) — TR {count_pos_visits(train_df,YCOL)} | VA {count_pos_visits(val_df,YCOL)} | TE {count_pos_visits(test_df,YCOL)}\")\n",
        "print(f\"[FE-visit] cows+ (max-per-cow) — TR {count_pos_cows(train_df,KEY,YCOL)} | VA {count_pos_cows(val_df,KEY,YCOL)} | TE {count_pos_cows(test_df,KEY,YCOL)}\")\n",
        "feat_cnt = len([c for c in train_df.columns if c not in {KEY, YCOL, TIME_COL, '_visit_idx', 'Cow_ID_norm'}])\n",
        "print(f\"[READY] KEY='{KEY}' | YCOL='{YCOL}' | TIME_COL='{TIME_COL}' | Num features={feat_cnt}\")\n",
        "if dropped_cols:\n",
        "    print(f\"[NOTE] Dropped degenerate columns: {dropped_cols[:10]}{' ...' if len(dropped_cols)>10 else ''}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiMFt20wcEjE",
        "outputId": "bcb36e49-7981-49ce-81fb-5e7b3084a387"
      },
      "id": "RiMFt20wcEjE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.5 Fallback] Rebuilding cow-based splits…\n",
            "[2.5 Fallback] Train cows: 660 | Val cows: 220 | Test cows: 220\n",
            "[FE-visit] rows — TRAIN (3960, 99) | VAL (1320, 99) | TEST (1320, 99)\n",
            "[FE-visit] visits+ (class1) — TR 666 | VA 222 | TE 222\n",
            "[FE-visit] cows+ (max-per-cow) — TR 111 | VA 37 | TE 37\n",
            "[READY] KEY='Cow_ID_match' | YCOL='class1' | TIME_COL='Day' | Num features=96\n",
            "[NOTE] Dropped degenerate columns: ['Breed', 'Cow_ID', 'Hardness_d1', 'Hardness_r3_d1', 'Hardness_r5_d1', 'Hardness_z_cow', 'Milk_visibility_d1', 'Milk_visibility_r3_d1', 'Milk_visibility_r5_d1', 'Milk_visibility_z_cow'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "61255a13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "61255a13",
        "outputId": "62ea3607-b440-4653-9a41-87b675341985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Config] IMAGE_DIR: /content/drive/MyDrive/Mastitis_illness_cow/datasets/images\n",
            "[Config] COCO_JSON_PATH: /content/drive/MyDrive/Mastitis_illness_cow/exports/_annotations.coco.json\n",
            "[Config] MAPPING_CSV_PATH: /content/drive/MyDrive/Mastitis_illness_cow/datasets/image_to_cow_map.csv\n",
            "[Config] USE_MAPPING_CSV: True\n",
            "[COCO] images=130 | annotations=185 | categories=6\n",
            "[Mapping] Using mapping CSV: /content/drive/MyDrive/Mastitis_illness_cow/datasets/image_to_cow_map.csv\n",
            "[Images] df_images shape: (130, 9)\n",
            "[Images] with cow-id (_cid_) present: 130 / 130\n",
            "[Images] with cow-level label (y_img): 0 / 130\n",
            "\n",
            "[Debug] Example rows with cow-level label:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [file_name, path, _cid_, y_img, y_img_coco]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec3fed49-2c99-4982-a99f-415418c2a663\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>path</th>\n",
              "      <th>_cid_</th>\n",
              "      <th>y_img</th>\n",
              "      <th>y_img_coco</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec3fed49-2c99-4982-a99f-415418c2a663')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec3fed49-2c99-4982-a99f-415418c2a663 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec3fed49-2c99-4982-a99f-415418c2a663');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Debug] Example rows missing cow-level label:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                           file_name  \\\n",
              "0  FLIR0179_jpg.rf.7b1370df26ea8498381f67453133af...   \n",
              "1  FLIR0227_jpg.rf.845a66986fb6d4d9648aa314ced09e...   \n",
              "2  FLIR1445_jpg.rf.045fbc0881e974ff438962ed621fac...   \n",
              "3  FLIR1867_jpg.rf.efa16aea0933b52816d3df8e3c6f03...   \n",
              "4  FLIR1695_jpg.rf.8265732ed9ecf71b800da75ac6e20d...   \n",
              "5  FLIR0843_jpg.rf.11aa52a9b9c110de0f267c09a1c2d6...   \n",
              "6  FLIR1509_jpg.rf.0c7f6501cb7be8160df19e17973aa0...   \n",
              "7  FLIR0983_jpg.rf.e5f677846f89da4b40af8dd12e19e7...   \n",
              "8  FLIR1833_jpg.rf.c071bcf03f96633dcb00121c8028e8...   \n",
              "9  FLIR1647_jpg.rf.0eede5710a1a7b5f5adff4ee6dc4d5...   \n",
              "\n",
              "                                                path _cid_  y_img  y_img_coco  \n",
              "0  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "1  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "2  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "3  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "4  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "5  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "6  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "7  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "8  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  \n",
              "9  /content/drive/MyDrive/Mastitis_illness_cow/da...          NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91bdd3ae-ff03-4878-8b2e-a5836a79258f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>path</th>\n",
              "      <th>_cid_</th>\n",
              "      <th>y_img</th>\n",
              "      <th>y_img_coco</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FLIR0179_jpg.rf.7b1370df26ea8498381f67453133af...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FLIR0227_jpg.rf.845a66986fb6d4d9648aa314ced09e...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FLIR1445_jpg.rf.045fbc0881e974ff438962ed621fac...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FLIR1867_jpg.rf.efa16aea0933b52816d3df8e3c6f03...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FLIR1695_jpg.rf.8265732ed9ecf71b800da75ac6e20d...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FLIR0843_jpg.rf.11aa52a9b9c110de0f267c09a1c2d6...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FLIR1509_jpg.rf.0c7f6501cb7be8160df19e17973aa0...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>FLIR0983_jpg.rf.e5f677846f89da4b40af8dd12e19e7...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>FLIR1833_jpg.rf.c071bcf03f96633dcb00121c8028e8...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>FLIR1647_jpg.rf.0eede5710a1a7b5f5adff4ee6dc4d5...</td>\n",
              "      <td>/content/drive/MyDrive/Mastitis_illness_cow/da...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91bdd3ae-ff03-4878-8b2e-a5836a79258f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91bdd3ae-ff03-4878-8b2e-a5836a79258f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91bdd3ae-ff03-4878-8b2e-a5836a79258f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-481d34f7-dc9a-46c5-b4ef-769de8771fbe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-481d34f7-dc9a-46c5-b4ef-769de8771fbe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-481d34f7-dc9a-46c5-b4ef-769de8771fbe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#   \\u2022 For imaging-only experiments without cow labels, set USE_COCO_AS_IMAGING_LABELS=True\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"FLIR1833_jpg.rf.c071bcf03f96633dcb00121c8028e8b1.jpg\",\n          \"FLIR0227_jpg.rf.845a66986fb6d4d9648aa314ced09ea1.jpg\",\n          \"FLIR0843_jpg.rf.11aa52a9b9c110de0f267c09a1c2d68f.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"/content/drive/MyDrive/Mastitis_illness_cow/datasets/images/FLIR1833_jpg.rf.c071bcf03f96633dcb00121c8028e8b1.jpg\",\n          \"/content/drive/MyDrive/Mastitis_illness_cow/datasets/images/FLIR0227_jpg.rf.845a66986fb6d4d9648aa314ced09ea1.jpg\",\n          \"/content/drive/MyDrive/Mastitis_illness_cow/datasets/images/FLIR0843_jpg.rf.11aa52a9b9c110de0f267c09a1c2d68f.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_cid_\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_img\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_img_coco\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overlap] cows in images: 1 | in df_risk: 1100 | intersection: 0\n"
          ]
        }
      ],
      "source": [
        "# ===== 3) Image Index Builder (COCO-based) — robust cow-id alignment =====\n",
        "# Goal: build `df_images` from a COCO JSON, resolve absolute file paths under IMAGE_DIR,\n",
        "# and align each image to a cow-level label coming from the VISIT-LEVEL TARGET (df_risk from Cell 2).\n",
        "# Why this way:\n",
        "#   • Old YOLO TXT labels are not trusted (hashed/unusable).\n",
        "#   • COCO defines canonical `images`/`annotations`/`categories` for indexing.\n",
        "#   • Supervision should follow the ADAPTIVE TARGET built in Cell 2 (df_risk → risk_next),\n",
        "#     aggregated to cow-level with a max-over-visits per cow.\n",
        "#   • If cow-id cannot be inferred from path, we can optionally use an explicit CSV map: `file_name,Cow_ID`.\n",
        "\n",
        "import json, re, os, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Preconditions from Cells 1–2 --------------------------------------------\n",
        "assert 'IMAGE_DIR' in globals() and isinstance(IMAGE_DIR, Path), \"IMAGE_DIR must come from Cell 1.\"\n",
        "assert 'COCO_JSON_PATH' in globals() and isinstance(COCO_JSON_PATH, Path), \"COCO_JSON_PATH must come from Cell 1.\"\n",
        "assert 'df_risk' in globals(), \"Run Cell 2 first: 'df_risk' (visit-level target) is required.\"\n",
        "assert 'KEY' in globals(), \"Run Cell 2 first: KEY (cow id col in df_risk) must be defined.\"\n",
        "assert COCO_JSON_PATH.exists(), f\"COCO JSON not found: {COCO_JSON_PATH}\"\n",
        "assert IMAGE_DIR.exists(), f\"IMAGE_DIR not found: {IMAGE_DIR}\"\n",
        "\n",
        "# --- Config knobs -------------------------------------------------------------\n",
        "# Use mapping only if it's a real file (not empty, not a directory)\n",
        "USE_MAPPING_CSV = (\n",
        "    'MAPPING_CSV_PATH' in globals()\n",
        "    and MAPPING_CSV_PATH\n",
        "    and isinstance(MAPPING_CSV_PATH, Path)\n",
        "    and MAPPING_CSV_PATH.is_file()\n",
        ")\n",
        "\n",
        "# Optional: imaging-only labels from COCO categories (NOT used for fusion).\n",
        "USE_COCO_AS_IMAGING_LABELS = False\n",
        "POSITIVE_CATEGORIES = {\"mastitis\", \"lesion\", \"inflammation\"}  # adapt to your COCO taxonomy\n",
        "\n",
        "print(\"[Config] IMAGE_DIR:\", IMAGE_DIR)\n",
        "print(\"[Config] COCO_JSON_PATH:\", COCO_JSON_PATH)\n",
        "print(\"[Config] MAPPING_CSV_PATH:\", (MAPPING_CSV_PATH if USE_MAPPING_CSV else \"None/Not a file\"))\n",
        "print(\"[Config] USE_MAPPING_CSV:\", USE_MAPPING_CSV)\n",
        "\n",
        "# --- Helpers -----------------------------------------------------------------\n",
        "def normalize_cow_id(x) -> str:\n",
        "    \"\"\"Map 'Cow_01'/'COW-003'/3 → 'cow1'/'cow3'. If only digits exist, still map to 'cowN'.\"\"\"\n",
        "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
        "        return \"\"\n",
        "    s = str(x).strip().lower()\n",
        "    m = re.search(r\"cow[_\\-]?(\\d+)\", s)\n",
        "    if m:\n",
        "        return f\"cow{int(m.group(1))}\"\n",
        "    m2 = re.search(r\"\\b(\\d{1,6})\\b\", s)\n",
        "    if m2:\n",
        "        return f\"cow{int(m2.group(1))}\"\n",
        "    return s\n",
        "\n",
        "def find_image_path(root: Path, fn: str) -> str:\n",
        "    \"\"\"\n",
        "    Resolve a COCO `file_name` to an absolute path under IMAGE_DIR (robust to subfolders).\n",
        "    1) root/fn if exists; 2) search by basename anywhere under root.\n",
        "    \"\"\"\n",
        "    p = root / fn\n",
        "    if p.exists():\n",
        "        return str(p)\n",
        "    hits = list(root.rglob(Path(fn).name))\n",
        "    return str(hits[0]) if hits else \"\"\n",
        "\n",
        "def extract_cow_id_from_path(p: str) -> str:\n",
        "    \"\"\"\n",
        "    Heuristic cow-id inference from the path:\n",
        "      • Look for tokens like 'cow3', 'cow_003', 'Cow-12' in any folder part.\n",
        "      • Fallback: use a 1–6 digit cluster in the filename and map to 'cowN'.\n",
        "    Prefer an explicit mapping CSV when folders are flat.\n",
        "    \"\"\"\n",
        "    path = Path(p)\n",
        "    for part in path.parts[::-1]:\n",
        "        m = re.search(r\"\\b(cow[_\\-]?\\d{1,6})\\b\", part.lower())\n",
        "        if m:\n",
        "            return normalize_cow_id(m.group(1))\n",
        "    base = path.stem\n",
        "    m2 = re.search(r\"(\\d{1,6})\", base)\n",
        "    return normalize_cow_id(m2.group(1)) if m2 else \"\"\n",
        "\n",
        "# --- Load COCO ---------------------------------------------------------------\n",
        "with open(COCO_JSON_PATH, \"r\") as f:\n",
        "    coco = json.load(f)\n",
        "\n",
        "coco_images = pd.DataFrame(coco.get(\"images\", []))\n",
        "coco_cats   = pd.DataFrame(coco.get(\"categories\", []))\n",
        "coco_ann    = pd.DataFrame(coco.get(\"annotations\", []))\n",
        "print(f\"[COCO] images={len(coco_images)} | annotations={len(coco_ann)} | categories={len(coco_cats)}\")\n",
        "\n",
        "# Resolve absolute paths + basic fields\n",
        "coco_images = coco_images.copy()\n",
        "coco_images[\"path\"] = coco_images[\"file_name\"].apply(lambda fn: find_image_path(IMAGE_DIR, fn))\n",
        "coco_images[\"path_exists\"] = coco_images[\"path\"].apply(lambda p: bool(p) and Path(p).exists())\n",
        "coco_images[\"stem\"] = coco_images[\"file_name\"].apply(lambda fn: Path(fn).stem)\n",
        "\n",
        "missing = coco_images[~coco_images[\"path_exists\"]]\n",
        "if len(missing) > 0:\n",
        "    print(f\"[WARN] {len(missing)} images from COCO were not found under IMAGE_DIR. Showing first 5:\")\n",
        "    display(missing.head(5)[[\"id\",\"file_name\",\"path\"]])\n",
        "\n",
        "# --- Optional explicit mapping: filename -> Cow_ID ---------------------------\n",
        "if USE_MAPPING_CSV:\n",
        "    print(f\"[Mapping] Using mapping CSV: {MAPPING_CSV_PATH}\")\n",
        "    mp = pd.read_csv(MAPPING_CSV_PATH)\n",
        "    assert {\"file_name\",\"Cow_ID\"}.issubset(mp.columns), \\\n",
        "        \"Mapping CSV must have columns: file_name,Cow_ID\"\n",
        "    mp[\"Cow_ID\"] = mp[\"Cow_ID\"].apply(normalize_cow_id)\n",
        "    coco_images = coco_images.merge(mp[[\"file_name\",\"Cow_ID\"]], on=\"file_name\", how=\"left\")\n",
        "    coco_images.rename(columns={\"Cow_ID\": \"_cid_\"}, inplace=True)\n",
        "else:\n",
        "    print(\"[Mapping] No valid mapping CSV file detected (skipping).\")\n",
        "    coco_images[\"_cid_\"] = coco_images[\"path\"].apply(extract_cow_id_from_path)\n",
        "\n",
        "# --- Cow-level label from df_risk (Cell 2) -----------------------------------\n",
        "# Use the ADAPTIVE VISIT-LEVEL TARGET 'risk_next' aggregated per cow to get a stable y_img.\n",
        "df_risk_norm = df_risk.copy()\n",
        "df_risk_norm[\"_cid_\"] = df_risk_norm[KEY].apply(normalize_cow_id)\n",
        "y_per_cow = (\n",
        "    df_risk_norm.groupby(\"_cid_\")[\"risk_next\"]\n",
        "    .apply(lambda s: int(pd.to_numeric(s, errors=\"coerce\").fillna(0).max()))\n",
        "    .rename(\"y_img\")\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "df_images = (\n",
        "    coco_images[[\"id\",\"file_name\",\"path\",\"path_exists\",\"stem\",\"_cid_\"]]\n",
        "    .merge(y_per_cow, on=\"_cid_\", how=\"left\")\n",
        ")\n",
        "\n",
        "# --- Optional: imaging-only labels from COCO categories ----------------------\n",
        "if USE_COCO_AS_IMAGING_LABELS and not coco_cats.empty and not coco_ann.empty:\n",
        "    cat_map = {int(row[\"id\"]): str(row.get(\"name\",\"\")).lower() for _, row in coco_cats.iterrows()}\n",
        "    ann = coco_ann.copy()\n",
        "    ann[\"cat_name\"] = ann[\"category_id\"].map(cat_map)\n",
        "    ann[\"is_pos\"] = ann[\"cat_name\"].isin({c.lower() for c in POSITIVE_CATEGORIES})\n",
        "    pos_by_img = ann.groupby(\"image_id\")[\"is_pos\"].max().reset_index()\n",
        "    pos_by_img.rename(columns={\"is_pos\":\"y_img_coco\"}, inplace=True)\n",
        "    df_images = df_images.merge(pos_by_img, left_on=\"id\", right_on=\"image_id\", how=\"left\")\n",
        "    df_images.drop(columns=[\"image_id\"], inplace=True)\n",
        "    df_images[\"y_img_coco\"] = df_images[\"y_img_coco\"].fillna(False).astype(int)\n",
        "else:\n",
        "    df_images[\"y_img_coco\"] = np.nan  # not used\n",
        "\n",
        "# --- Final hygiene & diagnostics ---------------------------------------------\n",
        "df_images[\"y_img_present\"] = df_images[\"y_img\"].notna().astype(int)\n",
        "df_images = df_images[df_images[\"path_exists\"]].reset_index(drop=True)\n",
        "\n",
        "print(f\"[Images] df_images shape: {df_images.shape}\")\n",
        "print(f\"[Images] with cow-id (_cid_) present: {df_images['_cid_'].notna().sum()} / {len(df_images)}\")\n",
        "print(f\"[Images] with cow-level label (y_img): {int(df_images['y_img_present'].sum())} / {len(df_images)}\")\n",
        "\n",
        "dbg_cols = [\"file_name\",\"path\",\"_cid_\",\"y_img\",\"y_img_coco\"]\n",
        "print(\"\\n[Debug] Example rows with cow-level label:\")\n",
        "display(df_images[df_images[\"y_img_present\"] == 1][dbg_cols].head(10))\n",
        "print(\"\\n[Debug] Example rows missing cow-level label:\")\n",
        "display(df_images[df_images[\"y_img_present\"] == 0][dbg_cols].head(10))\n",
        "\n",
        "# Overlap with df_risk cows (sanity)\n",
        "img_cows = set(df_images[\"_cid_\"].dropna().astype(str).unique())\n",
        "risk_cows = set(df_risk_norm[\"_cid_\"].dropna().astype(str).unique())\n",
        "print(f\"[Overlap] cows in images: {len(img_cows)} | in df_risk: {len(risk_cows)} | intersection: {len(img_cows & risk_cows)}\")\n",
        "\n",
        "# Guidance:\n",
        "#   • If many images lack y_img: check KEY/normalisation consistency and whether those cows exist in df_risk.\n",
        "#   • If folders are flat (no 'cowX'), provide MAPPING_CSV_PATH (filename→Cow_ID) to avoid heuristic errors.\n",
        "#   • For imaging-only experiments without cow labels, set USE_COCO_AS_IMAGING_LABELS=True.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7c47ef33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c47ef33",
        "outputId": "ed300c5a-d1f7-43ca-e8be-4d0426c714e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Imaging] No supervised images (y_img present). Skipping image model.\n"
          ]
        }
      ],
      "source": [
        "# ===== 4) Imaging model — EfficientNet frozen + Augment + TTA + cow-stratified split =====\n",
        "# Purpose:\n",
        "#   Train an image-only branch consistent with the clinical target (y_img) derived from df_risk.\n",
        "#   We: (1) keep only images with y_img present, (2) split cows (not images) into TR/VAL/TEST,\n",
        "#   (3) use a frozen EfficientNet as feature extractor, (4) add Augment, Oversampling (optional), and TTA,\n",
        "#   (5) report image-level metrics and cow-level aggregated probabilities.\n",
        "#\n",
        "# Inputs expected from previous cells:\n",
        "#   • df_images with columns: ['path','_cid_','y_img', ...]\n",
        "#   • df_images['y_img'] must be 0/1 (or NaN for unknown -> dropped here).\n",
        "#\n",
        "# Notes:\n",
        "#   • No identity leakage: cows are disjoint across splits.\n",
        "#   • Late-fusion later will use the cow-level outputs built here.\n",
        "\n",
        "import os, math, numpy as np, pandas as pd\n",
        "import torch, torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from PIL import Image\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# ------------------- Config -------------------\n",
        "SEED = 42\n",
        "rng = np.random.RandomState(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "IMG_SIZE = 224\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PIN_MEM = torch.cuda.is_available()\n",
        "\n",
        "# Image split configuration (by cow)\n",
        "IMG_TRAIN_FRAC = 0.60\n",
        "IMG_VAL_FRAC   = 0.20   # remainder → TEST\n",
        "K_VIEWS_TRAIN  = 5      # augmentation views per TRAIN image\n",
        "USE_OVERSAMPLING = True # oversample minority class on TRAIN\n",
        "TTA_N_VIEWS    = 8      # TTA views for VAL/TEST (0 disables TTA)\n",
        "BATCH_TRAIN    = 32\n",
        "BATCH_EVAL     = 64\n",
        "NUM_WORKERS    = 2\n",
        "\n",
        "# ------------------- Preconditions & filtering -------------------\n",
        "assert 'df_images' in globals() and len(df_images) > 0, \"df_images not available. Run Cell 3.\"\n",
        "assert {'path','_cid_','y_img'}.issubset(df_images.columns), \"df_images must have path, _cid_, y_img.\"\n",
        "\n",
        "# Keep only supervised images (have cow label)\n",
        "dfi_all = df_images.copy()\n",
        "dfi_all = dfi_all[dfi_all['y_img'].notna()].reset_index(drop=True)\n",
        "\n",
        "# Normalise cow id (safety)\n",
        "import re\n",
        "def normalize_cow_id(x):\n",
        "    if x is None or (isinstance(x, float) and pd.isna(x)): return \"\"\n",
        "    s = str(x).strip().lower()\n",
        "    m = re.search(r\"cow[_\\-]?(\\d+)\", s)\n",
        "    if m: return f\"cow{int(m.group(1))}\"\n",
        "    m2 = re.search(r\"\\b(\\d{1,6})\\b\", s)\n",
        "    if m2: return f\"cow{int(m2.group(1))}\"\n",
        "    return s\n",
        "\n",
        "dfi_all[\"_cid_\"] = dfi_all[\"_cid_\"].apply(normalize_cow_id)\n",
        "dfi_all[\"y_img\"] = pd.to_numeric(dfi_all[\"y_img\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "if dfi_all.empty:\n",
        "    print(\"[Imaging] No supervised images (y_img present). Skipping image model.\")\n",
        "else:\n",
        "    # ------------------- Transforms -------------------\n",
        "    train_tf = T.Compose([\n",
        "        T.RandomResizedCrop(IMG_SIZE, scale=(0.90, 1.00), ratio=(0.98, 1.02)),\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        T.RandomAffine(degrees=7, translate=(0.03, 0.03), scale=(0.98, 1.02)),\n",
        "        T.GaussianBlur(kernel_size=3, sigma=(0.1, 0.8)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    eval_tf = T.Compose([\n",
        "        T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "    # ------------------- Backbone (frozen EfficientNet) -------------------\n",
        "    try:\n",
        "        import timm\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Please install timm in this environment: pip install timm\") from e\n",
        "\n",
        "    class EffNetFeats(nn.Module):\n",
        "        \"\"\"Frozen EfficientNet feature extractor: outputs GAP features (no classifier head).\"\"\"\n",
        "        def __init__(self, model_name=\"efficientnet_b0\"):\n",
        "            super().__init__()\n",
        "            self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool=\"avg\")\n",
        "            for p in self.backbone.parameters(): p.requires_grad = False\n",
        "        def forward(self, x): return self.backbone(x)\n",
        "\n",
        "    feat_net = EffNetFeats(\"efficientnet_b0\").to(device).eval()\n",
        "    FEAT_DIM = feat_net.backbone.num_features\n",
        "\n",
        "    # ------------------- Dataset -------------------\n",
        "    class ImageDatasetK(Dataset):\n",
        "        \"\"\"\n",
        "        Dataset that exposes K augmented views per image.\n",
        "        Labels are repeated accordingly; transform controls augmentation.\n",
        "        \"\"\"\n",
        "        def __init__(self, df_rows: pd.DataFrame, transform, k_views=1):\n",
        "            self.paths  = df_rows[\"path\"].tolist()\n",
        "            self.labels = df_rows[\"y_img\"].astype(int).tolist()\n",
        "            self.tf = transform\n",
        "            self.k = max(1, int(k_views))\n",
        "        def __len__(self): return len(self.paths) * self.k\n",
        "        def __getitem__(self, idx):\n",
        "            i = idx % len(self.paths)\n",
        "            im = Image.open(self.paths[i]).convert(\"RGB\")\n",
        "            return self.tf(im), self.labels[i]\n",
        "\n",
        "    def extract_features(dloader):\n",
        "        \"\"\"Run frozen backbone to obtain features; return (X, y).\"\"\"\n",
        "        X, y = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dloader:\n",
        "                xb = xb.to(device)\n",
        "                feats = feat_net(xb).cpu().numpy()\n",
        "                X.append(feats); y.append(np.array(yb))\n",
        "        X = np.vstack(X) if len(X) else np.zeros((0, FEAT_DIM))\n",
        "        y = np.concatenate(y) if len(y) else np.array([])\n",
        "        return X, y\n",
        "\n",
        "    # ------------------- Cow-stratified split (image-only branch) -------------------\n",
        "    cows = dfi_all.groupby(\"_cid_\")[\"y_img\"].max().reset_index()\n",
        "    y_cow = cows[\"y_img\"].astype(int).values\n",
        "    C     = cows[\"_cid_\"].astype(str).values\n",
        "\n",
        "    # TRAIN vs (VAL+TEST)\n",
        "    if len(np.unique(y_cow)) < 2 or len(cows) < 5:\n",
        "        # Too few cows or single-class — fall back to simple split (still cow-based)\n",
        "        perm = rng.permutation(len(C))\n",
        "        n_tr = int(math.ceil(IMG_TRAIN_FRAC * len(C)))\n",
        "        n_va = int(math.ceil(IMG_VAL_FRAC   * len(C)))\n",
        "        tr_idx = perm[:n_tr]\n",
        "        va_idx = perm[n_tr:n_tr+n_va]\n",
        "        te_idx = perm[n_tr+n_va:]\n",
        "    else:\n",
        "        sss1 = StratifiedShuffleSplit(n_splits=1, test_size=(1.0-IMG_TRAIN_FRAC), random_state=SEED)\n",
        "        tr_idx, tmp_idx = next(sss1.split(C, y_cow))\n",
        "        C_tmp, y_tmp = C[tmp_idx], y_cow[tmp_idx]\n",
        "        test_frac_rel = (1.0 - IMG_TRAIN_FRAC - IMG_VAL_FRAC) / (1.0 - IMG_TRAIN_FRAC)\n",
        "        if len(np.unique(y_tmp)) < 2 or len(C_tmp) < 3:\n",
        "            # small/degenerate tmp: simple split\n",
        "            perm2 = rng.permutation(len(C_tmp))\n",
        "            cut = int(math.ceil((1.0 - test_frac_rel) * len(C_tmp)))\n",
        "            va_idx_rel, te_idx_rel = perm2[:cut], perm2[cut:]\n",
        "        else:\n",
        "            sss2 = StratifiedShuffleSplit(n_splits=1, test_size=test_frac_rel, random_state=SEED)\n",
        "            va_idx_rel, te_idx_rel = next(sss2.split(C_tmp, y_tmp))\n",
        "        # remap to original indices\n",
        "        tr_idx = tr_idx\n",
        "        va_idx = tmp_idx[va_idx_rel]\n",
        "        te_idx = tmp_idx[te_idx_rel]\n",
        "\n",
        "    C_tr, C_va, C_te = C[tr_idx], C[va_idx], C[te_idx]\n",
        "    tr_img = dfi_all[dfi_all[\"_cid_\"].isin(set(C_tr))].reset_index(drop=True)\n",
        "    va_img = dfi_all[dfi_all[\"_cid_\"].isin(set(C_va))].reset_index(drop=True)\n",
        "    te_img = dfi_all[dfi_all[\"_cid_\"].isin(set(C_te))].reset_index(drop=True)\n",
        "\n",
        "    print(f\"[Imaging|Split] COWS — TRAIN: {len(C_tr)} | VAL: {len(C_va)} | TEST: {len(C_te)}\")\n",
        "    print(f\"[Imaging|Split] IMAGES — TRAIN: {len(tr_img)} | VAL: {len(va_img)} | TEST: {len(te_img)}\")\n",
        "    if len(np.unique(y_cow))>=2:\n",
        "        print(f\"[Imaging|Class balance @cow] TRAIN pos={int((cows.iloc[tr_idx]['y_img']==1).sum())}/{len(tr_idx)} \"\n",
        "              f\"| VAL pos={int((cows.iloc[va_idx]['y_img']==1).sum())}/{len(va_idx)} \"\n",
        "              f\"| TEST pos={int((cows.iloc[te_idx]['y_img']==1).sum())}/{len(te_idx)}\")\n",
        "\n",
        "    # ------------------- Datasets & Samplers -------------------\n",
        "    train_ds = ImageDatasetK(tr_img, transform=train_tf, k_views=K_VIEWS_TRAIN)\n",
        "    val_ds   = ImageDatasetK(va_img, transform=eval_tf,   k_views=1)\n",
        "    test_ds  = ImageDatasetK(te_img, transform=eval_tf,   k_views=1)\n",
        "\n",
        "    # Oversampling on TRAIN (image-level, replicated across K views)\n",
        "    y_train_base = tr_img[\"y_img\"].astype(int).values\n",
        "    class_counts = np.bincount(y_train_base) if y_train_base.size else np.array([0,0])\n",
        "    sampler = None\n",
        "    if USE_OVERSAMPLING and class_counts.size==2 and class_counts.min()>0:\n",
        "        class_weights = 1.0 / class_counts\n",
        "        sample_weights = np.array([class_weights[y_train_base[i % len(y_train_base)]] for i in range(len(train_ds))])\n",
        "        sampler = WeightedRandomSampler(weights=torch.from_numpy(sample_weights).float(),\n",
        "                                        num_samples=len(train_ds), replacement=True)\n",
        "\n",
        "    tr_dl = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=(sampler is None),\n",
        "                       sampler=sampler, num_workers=NUM_WORKERS, pin_memory=PIN_MEM)\n",
        "    va_dl = DataLoader(val_ds,   batch_size=BATCH_EVAL,  shuffle=False,\n",
        "                       num_workers=NUM_WORKERS, pin_memory=PIN_MEM)\n",
        "    te_dl = DataLoader(test_ds,  batch_size=BATCH_EVAL,  shuffle=False,\n",
        "                       num_workers=NUM_WORKERS, pin_memory=PIN_MEM) if len(te_img)>0 else None\n",
        "\n",
        "    print(f\"[Imaging|Train loader] items={len(train_ds)}  (base_imgs={len(tr_img)} × K_VIEWS={K_VIEWS_TRAIN})\"\n",
        "          + (f\"  | oversampling=ON\" if sampler is not None else \"  | oversampling=OFF\"))\n",
        "\n",
        "    # ------------------- Feature Extraction -------------------\n",
        "    def extract_all(dl):\n",
        "        X, y = extract_features(dl); return X, y\n",
        "    Xtr, ytr = extract_all(tr_dl)\n",
        "    Xva, yva = extract_all(va_dl)\n",
        "    if te_dl is not None:\n",
        "        Xte, yte = extract_all(te_dl)\n",
        "    else:\n",
        "        Xte, yte = np.zeros((0, Xtr.shape[1])) if Xtr.size else np.array([]), np.array([])\n",
        "\n",
        "    # ------------------- Simple classifier on top of features -------------------\n",
        "    def feature_mixup(X, y, alpha=0.4, n_new=None, rng=rng):\n",
        "        \"\"\"Label-preserving interpolation in embedding space to regularise the linear head.\"\"\"\n",
        "        if X.shape[0] < 2: return X, y\n",
        "        if n_new is None: n_new = X.shape[0] // 2\n",
        "        i1 = rng.randint(0, X.shape[0], n_new); i2 = rng.randint(0, X.shape[0], n_new)\n",
        "        lam = rng.beta(alpha, alpha, size=n_new)[:, None]\n",
        "        Xn = lam*X[i1] + (1-lam)*X[i2]\n",
        "        yn = ((lam[:, 0]*y[i1] + (1-lam[:, 0])*y[i2]) >= 0.5).astype(int)\n",
        "        return np.vstack([X, Xn]), np.concatenate([y, yn])\n",
        "\n",
        "    if Xtr.shape[0] > 0 and len(np.unique(ytr)) >= 2:\n",
        "        Xtr_aug, ytr_aug = feature_mixup(Xtr, ytr, alpha=0.4, n_new=Xtr.shape[0]//2)\n",
        "        clf = LogisticRegression(max_iter=4000, class_weight='balanced', solver='lbfgs', n_jobs=None)\n",
        "        clf.fit(Xtr_aug, ytr_aug)\n",
        "\n",
        "        # --- Predictions with TTA ---\n",
        "        def predict_with_tta(paths, clf, n_views=TTA_N_VIEWS):\n",
        "            if n_views <= 0:\n",
        "                ds = ImageDatasetK(pd.DataFrame({\"path\": paths, \"y_img\": [0]*len(paths)}), eval_tf, k_views=1)\n",
        "                dl = DataLoader(ds, batch_size=BATCH_EVAL, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEM)\n",
        "                X,_ = extract_features(dl)\n",
        "                return clf.predict_proba(X)[:, 1]\n",
        "            # mild jitter, averaged\n",
        "            aug_eval = T.Compose([\n",
        "                T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "                T.RandomHorizontalFlip(p=0.5),\n",
        "                T.RandomAffine(degrees=3, translate=(0.01, 0.01), scale=(0.995, 1.005)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "            ])\n",
        "            all_probs = []\n",
        "            for _ in range(n_views):\n",
        "                ds = ImageDatasetK(pd.DataFrame({\"path\": paths, \"y_img\": [0]*len(paths)}), aug_eval, k_views=1)\n",
        "                dl = DataLoader(ds, batch_size=BATCH_EVAL, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEM)\n",
        "                X,_ = extract_features(dl)\n",
        "                all_probs.append(clf.predict_proba(X)[:, 1])\n",
        "            return np.mean(np.vstack(all_probs), axis=0)\n",
        "\n",
        "        p_val_img  = predict_with_tta(va_img['path'].tolist(), clf, n_views=TTA_N_VIEWS)\n",
        "        p_test_img = predict_with_tta(te_img['path'].tolist(), clf, n_views=TTA_N_VIEWS) if len(te_img)>0 else np.array([])\n",
        "\n",
        "        # Image-level metrics\n",
        "        if len(np.unique(yva)) == 2:\n",
        "            print(f\"[Imaging] VAL image-level — AUROC={roc_auc_score(yva, p_val_img):.4f} | \"\n",
        "                  f\"AUPRC={average_precision_score(yva, p_val_img):.4f} | N={len(yva)}\")\n",
        "        if len(yte)>0 and len(np.unique(yte)) == 2:\n",
        "            print(f\"[Imaging] TEST image-level — AUROC={roc_auc_score(yte, p_test_img):.4f} | \"\n",
        "                  f\"AUPRC={average_precision_score(yte, p_test_img):.4f} | N={len(yte)}\")\n",
        "    else:\n",
        "        print(\"[Imaging][WARN] Not enough training images or only one class in training. Skipping classifier.\")\n",
        "        p_val_img = np.array([]); p_test_img = np.array([])\n",
        "\n",
        "    # ------------------- Per-cow aggregation -------------------\n",
        "    def agg_per_cow(df_rows: pd.DataFrame, probs: np.ndarray, cow_col: str, target_col=\"y_img\") -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Aggregate image-level probabilities to cow-level by mean; cow label is max over images.\n",
        "        Returns [cow_id, y, p_img, n] where p_img is mean per cow and n is image count.\n",
        "        \"\"\"\n",
        "        if probs.size == 0 or len(df_rows) == 0:\n",
        "            return pd.DataFrame(columns=[cow_col, \"y\", \"p_img\", \"n\"])\n",
        "        tmp = df_rows.copy(); tmp[\"proba\"] = probs\n",
        "        return tmp.groupby(cow_col).agg(y=(target_col,\"max\"), p_img=(\"proba\",\"mean\"), n=(\"proba\",\"count\")).reset_index()\n",
        "\n",
        "    val_img_cow  = agg_per_cow(va_img, p_val_img,  cow_col=\"_cid_\", target_col=\"y_img\")\n",
        "    test_img_cow = agg_per_cow(te_img, p_test_img, cow_col=\"_cid_\", target_col=\"y_img\") if len(te_img)>0 else pd.DataFrame(columns=[\"_cid_\",\"y\",\"p_img\",\"n\"])\n",
        "\n",
        "    print(f\"[Imaging] Output per-cow — VAL cows: {len(val_img_cow)} | TEST cows: {len(test_img_cow)}\")\n",
        "    # These will be used in the fusion cell (we'll join on cow id '_cid_').\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell 5 — Tabular-only v3.1 (leak-safe, visit→cow pooling + calibration)\n",
        "# Purpose\n",
        "#   • Train a robust tabular baseline on visit-level features and aggregate to cow-level.\n",
        "#   • No imaging prerequisites. If imaging exists later, fusion can reuse pva_c/pte_c and yva_cow/yte_cow.\n",
        "# Guarantees\n",
        "#   • No leakage: cows are disjoint across train/val/test (from Cell 2.5).\n",
        "#   • Outputs aligned series: pva_c / pte_c keyed by yva_cow.index / yte_cow.index.\n",
        "# =======================\n",
        "\n",
        "import numpy as np, pandas as pd, warnings\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ---------- 0) Preconditions (tabular only) ----------\n",
        "req = [\"train_df\",\"val_df\",\"test_df\",\"KEY\",\"YCOL\"]\n",
        "missing = [k for k in req if k not in globals()]\n",
        "if missing:\n",
        "    raise AssertionError(f\"Prerequisites missing for tabular model: {missing}. \"\n",
        "                         f\"Run Cell 2 and 2.5 first to build train_df/val_df/test_df, KEY, YCOL.\")\n",
        "\n",
        "# Short aliases\n",
        "tr, va, te = train_df.copy(), val_df.copy(), test_df.copy()\n",
        "KEY_ = KEY\n",
        "Y_   = YCOL\n",
        "\n",
        "# Sanity: ensure key/target present and clean types\n",
        "for nm, d in [(\"train\",tr),(\"val\",va),(\"test\",te)]:\n",
        "    if KEY_ not in d.columns:\n",
        "        raise KeyError(f\"{nm}_df is missing '{KEY_}'\")\n",
        "    if Y_ not in d.columns:\n",
        "        raise KeyError(f\"{nm}_df is missing target '{Y_}'\")\n",
        "    d[KEY_] = d[KEY_].astype(str)\n",
        "    d[Y_]   = pd.to_numeric(d[Y_], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# ---------- 1) Feature whitelist (strict numeric, no time/meta) ----------\n",
        "# Avoid obvious leakers/meta columns; keep only numeric predictors.\n",
        "EXCLUDE = {KEY_, Y_, \"Cow_ID_norm\", \"risk_next\", \"risk_h1\", \"onset_day\",\n",
        "           \"Day\", \"_visit_idx\", \"visit_time\", \"datetime\", \"VisitDate\"}\n",
        "num_cols = (\n",
        "    tr.drop(columns=[c for c in EXCLUDE if c in tr.columns], errors=\"ignore\")\n",
        "      .select_dtypes(include=[np.number]).columns.tolist()\n",
        ")\n",
        "if not num_cols:\n",
        "    raise RuntimeError(\"No numeric features available after exclusions. \"\n",
        "                       \"Check Cell 2.5 feature engineering output.\")\n",
        "\n",
        "# ---------- 2) Preprocess pipeline ----------\n",
        "pre = ColumnTransformer([\n",
        "    (\"num\", Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"sc\",  StandardScaler()),\n",
        "    ]), num_cols)\n",
        "], remainder=\"drop\", verbose_feature_names_out=False)\n",
        "\n",
        "pre.fit(tr[num_cols])\n",
        "\n",
        "def mat(df):\n",
        "    X = pre.transform(df[num_cols])\n",
        "    y = df[Y_].astype(int).values\n",
        "    k = df[KEY_].astype(str).values\n",
        "    return k, X, y\n",
        "\n",
        "Ktr, Xtr, ytr = mat(tr)\n",
        "Kva, Xva, yva = mat(va)\n",
        "Kte, Xte, yte = mat(te)\n",
        "\n",
        "# ---------- 3) Two strong visit-level models: LR(EN) + HGB ----------\n",
        "pos_rate = max(1e-6, float((ytr == 1).mean()))\n",
        "w_pos = 0.5/pos_rate; w_neg = 0.5/(1.0 - pos_rate)\n",
        "w_tr  = np.where(ytr == 1, w_pos, w_neg)\n",
        "\n",
        "lr = LogisticRegression(\n",
        "    max_iter=4000, solver=\"saga\", penalty=\"elasticnet\",\n",
        "    l1_ratio=0.35, C=1.0, random_state=42, n_jobs=-1\n",
        ")\n",
        "hgb = HistGradientBoostingClassifier(\n",
        "    learning_rate=0.15, max_leaf_nodes=31, min_samples_leaf=25,\n",
        "    l2_regularization=0.0, max_depth=None, random_state=42\n",
        ")\n",
        "\n",
        "# Fit\n",
        "lr.fit(Xtr, ytr, sample_weight=w_tr)\n",
        "hgb.fit(Xtr, ytr, sample_weight=w_tr)\n",
        "\n",
        "def proba(clf, X):\n",
        "    return clf.predict_proba(X)[:,1] if hasattr(clf, \"predict_proba\") else clf.decision_function(X)\n",
        "\n",
        "pva_lr,  pte_lr  = proba(lr,  Xva), proba(lr,  Xte)\n",
        "pva_hgb, pte_hgb = proba(hgb, Xva), proba(hgb, Xte)\n",
        "\n",
        "# ---------- 4) Visit→cow pooling (pre-event masking + robust pooling) ----------\n",
        "def logistic_temp(p, tau=2.3):\n",
        "    p = np.clip(p, 1e-9, 1-1e-9)\n",
        "    z = np.log(p/(1-p))/tau\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "def pool_visits(keys, probs, tau=2.3, r=0.8, topk=3, jitter=0.006, seed=42, pre_event=True):\n",
        "    \"\"\"\n",
        "    Convert visit-level probabilities to cow-level score.\n",
        "    Steps:\n",
        "      • temperature scaling in logit space,\n",
        "      • small Gaussian jitter to break ties,\n",
        "      • optional pre-event exclusion (drop last visit per cow),\n",
        "      • robust pooling over 'excess over cow median' with power-mean and top-k mean.\n",
        "    Returns a pd.Series indexed by cow key.\n",
        "    \"\"\"\n",
        "    pt = logistic_temp(np.asarray(probs, float), tau=tau)\n",
        "    if jitter and jitter > 0:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        pt = np.clip(pt + rng.normal(0.0, jitter, size=pt.shape), 1e-9, 1-1e-9)\n",
        "    dfp = pd.DataFrame({\"k\": keys, \"pt\": pt})\n",
        "\n",
        "    if pre_event:\n",
        "        last_idx = dfp.groupby(\"k\").tail(1).index\n",
        "        dfp = dfp.drop(index=last_idx)\n",
        "\n",
        "    if len(dfp) == 0:\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    med = dfp.groupby(\"k\")[\"pt\"].transform(\"median\")\n",
        "    exc = (dfp[\"pt\"] - med).clip(lower=0)\n",
        "\n",
        "    def pmean(x, rr):\n",
        "        v = x.values\n",
        "        return (((v**rr).mean())**(1.0/rr)) if v.size > 0 else np.nan\n",
        "    def topk_mean(x, kk):\n",
        "        v = np.sort(x.values)\n",
        "        if v.size == 0: return np.nan\n",
        "        kk = min(kk, v.size)\n",
        "        return float(v[-kk:].mean())\n",
        "\n",
        "    pm = exc.groupby(dfp[\"k\"]).apply(lambda s: pmean(s, r))\n",
        "    tk = exc.groupby(dfp[\"k\"]).apply(lambda s: topk_mean(s, topk))\n",
        "    return (pm + tk) / 2.0\n",
        "\n",
        "def ranknorm(x):\n",
        "    r = np.argsort(np.argsort(x))\n",
        "    return r / max(len(x)-1, 1)\n",
        "\n",
        "# Cow-level labels (max over visits)\n",
        "yva_cow = va.groupby(KEY_)[Y_].max().astype(int)\n",
        "yte_cow = te.groupby(KEY_)[Y_].max().astype(int)\n",
        "\n",
        "# Small grid search for pooling hyperparams on VAL AUPRC\n",
        "taus  = [2.0, 2.3, 2.6]\n",
        "rs    = [0.7, 0.8, 0.9]\n",
        "topks = [2, 3, 4]\n",
        "best = None\n",
        "for tau in taus:\n",
        "    for r in rs:\n",
        "        for k in topks:\n",
        "            va_lr_c  = pool_visits(Kva, pva_lr,  tau=tau, r=r, topk=k).reindex(yva_cow.index).fillna(0.0).values\n",
        "            va_hgb_c = pool_visits(Kva, pva_hgb, tau=tau, r=r, topk=k).reindex(yva_cow.index).fillna(0.0).values\n",
        "            va_ens   = (ranknorm(va_lr_c) + ranknorm(va_hgb_c))/2.0\n",
        "            ap = average_precision_score(yva_cow.values, va_ens)\n",
        "            if (best is None) or (ap > best[0]):\n",
        "                best = (ap, tau, r, k, va_lr_c, va_hgb_c, va_ens)\n",
        "\n",
        "ap_best, TAU_B, R_B, K_B, va_lr_b, va_hgb_b, va_ens_b = best\n",
        "\n",
        "# Apply best pooling on TEST\n",
        "te_lr_b  = pool_visits(Kte, pte_lr,  tau=TAU_B, r=R_B, topk=K_B).reindex(yte_cow.index).fillna(0.0).values\n",
        "te_hgb_b = pool_visits(Kte, pte_hgb, tau=TAU_B, r=R_B, topk=K_B).reindex(yte_cow.index).fillna(0.0).values\n",
        "te_ens_b = (ranknorm(te_lr_b) + ranknorm(te_hgb_b))/2.0\n",
        "\n",
        "# ---------- 5) Platt calibration on VAL (cow-level ensemble) ----------\n",
        "from sklearn.linear_model import LogisticRegression as LRCal\n",
        "cal = LRCal(max_iter=1000, random_state=42).fit(va_ens_b.reshape(-1,1), yva_cow.values.astype(int))\n",
        "pva_c = cal.predict_proba(va_ens_b.reshape(-1,1))[:,1]\n",
        "pte_c = cal.predict_proba(te_ens_b.reshape(-1,1))[:,1]\n",
        "\n",
        "# ---------- 6) Metrics ----------\n",
        "def metr(name, y, p):\n",
        "    p = np.clip(p, 1e-9, 1-1e-9)\n",
        "    try: auc = roc_auc_score(y, p)\n",
        "    except: auc = np.nan\n",
        "    ap = average_precision_score(y, p)\n",
        "    br = brier_score_loss(y, p)\n",
        "    return dict(name=name, AUROC=float(auc) if auc==auc else np.nan, AUPRC=float(ap), Brier=float(br), N=int(len(y)))\n",
        "\n",
        "tab_summary = pd.DataFrame([\n",
        "    metr(\"VAL TAB only\",  yva_cow.values, pva_c),\n",
        "    metr(\"TEST TAB only\", yte_cow.values, pte_c),\n",
        "])\n",
        "print(\"\\n=== Tabular-only Summary (cow-level) ===\")\n",
        "print(tab_summary[[\"name\",\"AUROC\",\"AUPRC\",\"Brier\",\"N\"]].to_string(index=False))\n",
        "\n",
        "# ---------- 7) Publish aligned globals for fusion (Cell 6) ----------\n",
        "# These globals are consumed by the fusion cell; they are guaranteed aligned to yva_cow/yte_cow indices.\n",
        "globals()[\"pva_c\"]   = pva_c\n",
        "globals()[\"pte_c\"]   = pte_c\n",
        "globals()[\"yva_cow\"] = yva_cow  # pd.Series indexed by cow key\n",
        "globals()[\"yte_cow\"] = yte_cow  # pd.Series indexed by cow key\n",
        "\n",
        "print(\"\\n[READY] Exported for fusion: pva_c / pte_c aligned to yva_cow / yte_cow.\")\n",
        "print(f\"[Pooling*] Best on VAL — AP={ap_best:.4f} | tau={TAU_B}, r={R_B}, topK={K_B}\")\n",
        "print(f\"[Info] Features used ({len(num_cols)}): {num_cols[:12]}{' ...' if len(num_cols)>12 else ''}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz0cKRBN3mMo",
        "outputId": "7361c3c1-0413-4198-c407-543755896d66"
      },
      "id": "Yz0cKRBN3mMo",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Tabular-only Summary (cow-level) ===\n",
            "         name    AUROC    AUPRC    Brier   N\n",
            " VAL TAB only 0.741323 0.474406 0.125696 220\n",
            "TEST TAB only 0.838502 0.645940 0.116652 220\n",
            "\n",
            "[READY] Exported for fusion: pva_c / pte_c aligned to yva_cow / yte_cow.\n",
            "[Pooling*] Best on VAL — AP=0.1116 | tau=2.6, r=0.9, topK=2\n",
            "[Info] Features used (96): ['Months after giving birth', 'Previous_Mastits_status', 'IUFL', 'EUFL', 'IUFR', 'EUFR', 'IURL', 'EURL', 'IURR', 'EURR', 'Temperature', 'Hardness'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell 6 — Hybrid imaging pipeline (COCO + YOLO labels) with auto-fallbacks\n",
        "# What this does:\n",
        "# - Reads labels from COCO JSON and (optionally) YOLO .txt.\n",
        "# - Picks the label source with highest coverage.\n",
        "# - Tries true cow-aligned splits for multimodal fusion; if coverage is too small or train is single-class,\n",
        "#   it auto-falls back to image-level stratified splits (the recipe that previously performed well).\n",
        "# - Uses ResNet18 embeddings + Logistic Regression, with calibration and fusion when tabular cow scores exist.\n",
        "### THIS IS OUR ORIGINAL SINGLE SMALL TEST. WE REPLACE IT WITH A SUBJECT-GROUPED REPEATED CV TECHNIQUE RESTRICTED TO THE COWS THAT HAVE TERMAL IMAGES TO DRAW STASTICALLY ROBUST CONCLUSION AFTER WISE REVIEW FROM PEERING.\n",
        "# =======================\n",
        "import os, re, json, glob, time, warnings, random, sys\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Torch / Vision\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# ML\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegression as LRCal\n",
        "from sklearn.metrics import (average_precision_score, roc_auc_score, brier_score_loss,\n",
        "                             roc_curve, precision_recall_curve, confusion_matrix)\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ===== 0) Configuration & environment =====\n",
        "SEED    = 42\n",
        "DEBUG   = True\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# Paths (from previous cells)\n",
        "if 'PROJECT_DIR' not in globals():\n",
        "    PROJECT_DIR = \"/content/drive/MyDrive/Mastitis_illness_cow/datasets\"\n",
        "IMAGE_DIR = os.path.join(PROJECT_DIR, \"images\")\n",
        "LABEL_DIR = os.path.join(PROJECT_DIR, \"labels\")  # for YOLO .txt fallback\n",
        "COCO_JSON_PATH = os.path.join(os.path.dirname(PROJECT_DIR), \"exports\", \"_annotations.coco.json\")\n",
        "\n",
        "SAVE_DIR   = \"/content/mastitis_outputs\"\n",
        "FIGDIR     = os.path.join(PROJECT_DIR, \"figures_and_tables\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(FIGDIR, exist_ok=True)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"[MOUNT] IN_COLAB:\", 'google.colab' in sys.modules)\n",
        "print(\"[PATHS] PROJECT_DIR:\", PROJECT_DIR)\n",
        "print(\"[PATHS] IMAGE_DIR exists:\", os.path.isdir(IMAGE_DIR), \"| LABEL_DIR exists:\", os.path.isdir(LABEL_DIR))\n",
        "print(\"[PATHS] COCO_JSON_PATH:\", COCO_JSON_PATH, \"| exists:\", os.path.isfile(COCO_JSON_PATH))\n",
        "print(f\"[ENV] torch={torch.__version__} | torchvision={torchvision.__version__} | device={DEVICE}\", flush=True)\n",
        "\n",
        "IMG_EXTS = {\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\"}\n",
        "\n",
        "# ===== 1) Index images once =====\n",
        "stem2path = {}\n",
        "for root, _, files in os.walk(IMAGE_DIR):\n",
        "    for f in files:\n",
        "        if os.path.splitext(f)[1].lower() in IMG_EXTS:\n",
        "            stem2path[os.path.splitext(f)[0]] = os.path.join(root, f)\n",
        "print(f\"[Index] Indexed images: {len(stem2path)}\")\n",
        "\n",
        "# ===== 2) Build two candidate label tables: (A) COCO, (B) YOLO .txt =====\n",
        "def resolve_path_by_filename(file_name):\n",
        "    # try exact file_name inside IMAGE_DIR (and subfolders)\n",
        "    direct = os.path.join(IMAGE_DIR, file_name)\n",
        "    if os.path.isfile(direct): return direct\n",
        "    cand = glob.glob(os.path.join(IMAGE_DIR, \"**\", file_name), recursive=True)\n",
        "    return cand[0] if cand else None\n",
        "\n",
        "# --- (A) COCO reader ---\n",
        "def read_coco_table(coco_json_path):\n",
        "    if not os.path.isfile(coco_json_path): return None\n",
        "    with open(coco_json_path, \"r\") as f:\n",
        "        coco = json.load(f)\n",
        "    imgs = pd.DataFrame(coco.get(\"images\", []))\n",
        "    anns = pd.DataFrame(coco.get(\"annotations\", []))\n",
        "    cats = pd.DataFrame(coco.get(\"categories\", []))\n",
        "    if imgs.empty: return None\n",
        "\n",
        "    # Decide positive categories\n",
        "    positive_ids = set()\n",
        "    if \"name\" in cats.columns:\n",
        "        mask = cats[\"name\"].str.lower().str.contains(r\"(mastitis|lesion|injury|infect|abnormal|heat|inflammation)\", na=False)\n",
        "        if mask.any():\n",
        "            positive_ids = set(cats.loc[mask, \"id\"].tolist())\n",
        "    if not positive_ids:\n",
        "        print(\"[COCO][WARN] No explicit positive names found. Falling back to category_id==1.\")\n",
        "        positive_ids = {1}\n",
        "\n",
        "    # image_id -> class1\n",
        "    img_id_to_pos = anns.groupby(\"image_id\")[\"category_id\"].apply(\n",
        "        lambda s: int(any(cid in positive_ids for cid in s))\n",
        "    ).reindex(imgs[\"id\"]).fillna(0).astype(int)\n",
        "\n",
        "    # Make table\n",
        "    tbl = imgs[[\"file_name\"]].copy()\n",
        "    tbl[\"abs_path\"] = tbl[\"file_name\"].apply(resolve_path_by_filename)\n",
        "    tbl[\"class1\"]   = img_id_to_pos.values\n",
        "    tbl[\"stem\"]     = tbl[\"file_name\"].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
        "    # Drop unresolved\n",
        "    tbl = tbl[tbl[\"abs_path\"].notna()].reset_index(drop=True)\n",
        "    return tbl\n",
        "\n",
        "# --- (B) YOLO .txt reader ---\n",
        "def parse_yolo_txt(txt_path, positive_id=1):\n",
        "    \"\"\"\n",
        "    Returns 1 if any line has class_id == positive_id; else 0.\n",
        "    \"\"\"\n",
        "    pos = False\n",
        "    try:\n",
        "        with open(txt_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line: continue\n",
        "                parts = line.split()\n",
        "                try:\n",
        "                    cls = int(float(parts[0]))\n",
        "                    if cls == positive_id:\n",
        "                        pos = True; break\n",
        "                except Exception:\n",
        "                    continue\n",
        "    except Exception:\n",
        "        pass\n",
        "    return int(pos)\n",
        "\n",
        "def read_yolo_table(label_dir):\n",
        "    if not os.path.isdir(label_dir): return None\n",
        "    txts = sorted([p for p in glob.glob(os.path.join(label_dir, \"*.txt\")) if os.path.isfile(p)])\n",
        "    if not txts: return None\n",
        "    recs = []\n",
        "    for p in tqdm(txts, desc=\"Parse YOLO labels\", mininterval=0.1):\n",
        "        stem = os.path.splitext(os.path.basename(p))[0]\n",
        "        y = parse_yolo_txt(p, positive_id=1)  # adjust if your positive class differs\n",
        "        abs_path = stem2path.get(stem, None)\n",
        "        if abs_path is not None:\n",
        "            recs.append((stem, abs_path, y))\n",
        "    if not recs: return None\n",
        "    df = pd.DataFrame(recs, columns=[\"stem\",\"abs_path\",\"class1\"])\n",
        "    df[\"file_name\"] = df[\"abs_path\"].apply(os.path.basename)\n",
        "    return df\n",
        "\n",
        "# Build both candidates\n",
        "coco_tbl = read_coco_table(COCO_JSON_PATH)\n",
        "yolo_tbl = read_yolo_table(LABEL_DIR)\n",
        "\n",
        "n_coco = 0 if coco_tbl is None else len(coco_tbl)\n",
        "n_yolo = 0 if yolo_tbl is None else len(yolo_tbl)\n",
        "print(f\"[Labels] COCO resolved: {n_coco} | YOLO-txt resolved: {n_yolo}\")\n",
        "\n",
        "# Pick the best coverage\n",
        "if n_coco == 0 and n_yolo == 0:\n",
        "    raise RuntimeError(\"No labels found: both COCO and YOLO are empty/unresolved.\")\n",
        "if n_coco >= n_yolo:\n",
        "    lab_img = coco_tbl[[\"file_name\",\"abs_path\",\"class1\",\"stem\"]].copy()\n",
        "    source = \"COCO\"\n",
        "else:\n",
        "    lab_img = yolo_tbl[[\"file_name\",\"abs_path\",\"class1\",\"stem\"]].copy()\n",
        "    source = \"YOLO\"\n",
        "print(f\"[Labels] Using source: {source} | rows={len(lab_img)}\")\n",
        "\n",
        "# ===== 3) Infer cow IDs; prefer FLIR#### or first 3–6 digits (consistent with earlier cells) =====\n",
        "def infer_cow_from_stem(stem):\n",
        "    m = re.search(r'FLIR[_-]?(\\d{3,6})', stem, re.I)\n",
        "    if not m:\n",
        "        st_no_rf = stem.split(\".rf\")[0]\n",
        "        m = re.search(r'(\\d{3,6})', st_no_rf)\n",
        "    return f\"cow{m.group(1)}\" if m else None\n",
        "\n",
        "lab_img[\"_cid_\"] = lab_img[\"stem\"].apply(infer_cow_from_stem)\n",
        "\n",
        "# ===== 4) Split strategy: try cow-aligned multimodal; if too small or single-class → image-level fallback =====\n",
        "tab_ready_input = (\"train_df\" in globals()) and (\"val_df\" in globals()) and (\"test_df\" in globals())\n",
        "KEY = \"Cow_ID_match\" if tab_ready_input and (\"Cow_ID_match\" in train_df.columns) else None\n",
        "\n",
        "use_tab_split = False\n",
        "MIN_TRAIN_COWS = 8  # threshold to avoid pathological tiny cow-aligned splits\n",
        "\n",
        "if tab_ready_input and KEY is not None and lab_img[\"_cid_\"].notna().any():\n",
        "    cows_tr = set(train_df[KEY].astype(str))\n",
        "    cows_va = set(val_df[KEY].astype(str))\n",
        "    cows_te = set(test_df[KEY].astype(str))\n",
        "    tr_mask = lab_img[\"_cid_\"].astype(str).isin(cows_tr)\n",
        "    va_mask = lab_img[\"_cid_\"].astype(str).isin(cows_va)\n",
        "    te_mask = lab_img[\"_cid_\"].astype(str).isin(cows_te)\n",
        "    lab_tr = lab_img[tr_mask].copy()\n",
        "    lab_va = lab_img[va_mask].copy()\n",
        "    lab_te = lab_img[te_mask].copy()\n",
        "\n",
        "    # Cow count in TRAIN\n",
        "    n_train_cows = lab_tr[\"_cid_\"].nunique()\n",
        "    # Class check in TRAIN\n",
        "    train_has_two = (len(np.unique(lab_tr[\"class1\"].astype(int))) >= 2)\n",
        "\n",
        "    if n_train_cows >= MIN_TRAIN_COWS and train_has_two:\n",
        "        use_tab_split = True\n",
        "        print(f\"[Align] images per split (by cow): train={len(lab_tr)} | val={len(lab_va)} | test={len(lab_te)}  | cows(TR)={n_train_cows}\")\n",
        "    else:\n",
        "        print(f\"[Align][WARN] Insufficient cow coverage or single-class in TRAIN (cows={n_train_cows}, two_classes={train_has_two}).\")\n",
        "        use_tab_split = False\n",
        "\n",
        "if not use_tab_split:\n",
        "    # Image-level stratified split (replicates the “good” previous behaviour)\n",
        "    df_all = lab_img.copy()\n",
        "    y_all = df_all[\"class1\"].astype(int).values\n",
        "    if len(np.unique(y_all)) < 2:\n",
        "        # degenerate case: make a tiny jittered split and keep constant predictor later\n",
        "        print(\"[Split][WARN] Global labels are single-class. Proceeding; classifier will fallback to constant prior.\")\n",
        "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=SEED) if len(np.unique(y_all))>=2 else None\n",
        "    if sss1 is not None:\n",
        "        tr_idx, tm_idx = next(sss1.split(np.zeros(len(y_all)), y_all))\n",
        "        df_tr = df_all.iloc[tr_idx].reset_index(drop=True)\n",
        "        df_tm = df_all.iloc[tm_idx].reset_index(drop=True)\n",
        "        sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.50, random_state=SEED)\n",
        "        va_idx, te_idx = next(sss2.split(np.zeros(len(df_tm)), df_tm[\"class1\"].astype(int).values))\n",
        "        lab_tr = df_tr\n",
        "        lab_va = df_tm.iloc[va_idx].reset_index(drop=True)\n",
        "        lab_te = df_tm.iloc[te_idx].reset_index(drop=True)\n",
        "    else:\n",
        "        # no stratification possible → simple 60/20/20\n",
        "        n = len(df_all); n_tr = int(0.6*n); n_va = int(0.2*n)\n",
        "        lab_tr = df_all.iloc[:n_tr].reset_index(drop=True)\n",
        "        lab_va = df_all.iloc[n_tr:n_tr+n_va].reset_index(drop=True)\n",
        "        lab_te = df_all.iloc[n_tr+n_va:].reset_index(drop=True)\n",
        "\n",
        "    # Synthesize cow key = one image per “cow” (so metrics run)\n",
        "    for df_ in (lab_tr, lab_va, lab_te):\n",
        "        df_[\"_cid_\"] = df_[\"stem\"]\n",
        "\n",
        "print(f\"[IMG rows] train={len(lab_tr)} | val={len(lab_va)} | test={len(lab_te)}\")\n",
        "\n",
        "# Safety: if TRAIN is single-class after all this, we won't try to fit LR (we’ll output constant probabilities).\n",
        "def _both_classes(df):\n",
        "    y = df[\"class1\"].astype(int).values\n",
        "    return len(np.unique(y)) >= 2\n",
        "\n",
        "# ===== 5) Datasets, dataloaders, backbone, embeddings =====\n",
        "img_size = 224\n",
        "tfm = transforms.Compose([\n",
        "    transforms.ConvertImageDtype(torch.float32),\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
        "])\n",
        "\n",
        "class ImgDS(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        img = torchvision.io.read_image(r[\"abs_path\"])\n",
        "        img = tfm(img)\n",
        "        return img, int(r[\"class1\"]), str(r[\"_cid_\"])\n",
        "\n",
        "BATCH, NUM_WORKERS, PREFETCH = 256, 6, 4\n",
        "def make_loader(df, shuffle):\n",
        "    return DataLoader(\n",
        "        ImgDS(df), batch_size=BATCH, shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS, pin_memory=True,\n",
        "        persistent_workers=(NUM_WORKERS > 0),\n",
        "        prefetch_factor=PREFETCH if NUM_WORKERS > 0 else None\n",
        "    )\n",
        "\n",
        "dl_tr = make_loader(lab_tr, True)\n",
        "dl_va = make_loader(lab_va, False)\n",
        "dl_te = make_loader(lab_te, False)\n",
        "\n",
        "backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "feat_dim = backbone.fc.in_features\n",
        "backbone.fc = nn.Identity()\n",
        "for p in backbone.parameters(): p.requires_grad = False\n",
        "backbone.eval().to(DEVICE)\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    try: torch.set_float32_matmul_precision(\"high\")\n",
        "    except Exception: pass\n",
        "    print(f\"[GPU] {torch.cuda.get_device_name(0)} | cap={torch.cuda.get_device_capability(0)}\", flush=True)\n",
        "\n",
        "use_amp = torch.cuda.is_available()\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_embeddings(dloader, desc):\n",
        "    Xs, ys, ks = [], [], []\n",
        "    t0 = time.time()\n",
        "    for imgs, y, k in tqdm(dloader, desc=desc, mininterval=0.1, leave=True):\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        if use_amp:\n",
        "            with torch.amp.autocast(\"cuda\", dtype=torch.float16):\n",
        "                emb = backbone(imgs)\n",
        "            emb = emb.float().detach().cpu().numpy()\n",
        "            torch.cuda.synchronize()\n",
        "        else:\n",
        "            emb = backbone(imgs).detach().cpu().numpy()\n",
        "        Xs.append(emb); ys.append(y.numpy()); ks += list(k)\n",
        "    dt = time.time() - t0\n",
        "    n  = sum(x.shape[0] for x in Xs) if Xs else 0\n",
        "    print(f\"[TIMING] {desc}: {n} img in {dt:.2f}s → {n/max(dt,1e-9):.1f} img/s\", flush=True)\n",
        "    X = np.concatenate(Xs, axis=0) if Xs else np.zeros((0, feat_dim), dtype=np.float32)\n",
        "    y = np.concatenate(ys, axis=0) if ys else np.zeros((0,), dtype=np.int32)\n",
        "    k = np.array(ks, dtype=object)\n",
        "    return X, y, k\n",
        "\n",
        "Xtr_i, ytr_i, Ktr_i = extract_embeddings(dl_tr, \"Emb TR\")\n",
        "Xva_i, yva_i, Kva_i = extract_embeddings(dl_va, \"Emb VA\")\n",
        "Xte_i, yte_i, Kte_i = extract_embeddings(dl_te, \"Emb TE\")\n",
        "print(f\"[Emb] TR={Xtr_i.shape} VA={Xva_i.shape} TE={Xte_i.shape}\", flush=True)\n",
        "\n",
        "# ===== 6) Image classifier with single-class fallback =====\n",
        "train_has_two = (len(np.unique(ytr_i)) >= 2)\n",
        "if not train_has_two:\n",
        "    print(\"[ClassSafety][Fallback] TRAIN embeddings are single-class → using constant-probability predictor.\")\n",
        "    prior_val = float((yva_i == 1).mean()) if yva_i.size else 0.5\n",
        "    pva_img_v = np.full_like(yva_i, prior_val, dtype=float)\n",
        "    pte_img_v = np.full_like(yte_i, prior_val, dtype=float)\n",
        "else:\n",
        "    pos_rate = max(1e-6, float((ytr_i == 1).mean()))\n",
        "    w_pos = 0.5 / pos_rate; w_neg = 0.5 / (1.0 - pos_rate)\n",
        "    w_tr  = np.where(ytr_i == 1, w_pos, w_neg)\n",
        "    clf_i = LogisticRegression(max_iter=3000, solver='lbfgs', C=1.0, n_jobs=-1)\n",
        "    clf_i.fit(Xtr_i, ytr_i, sample_weight=w_tr)\n",
        "    pva_img_v = clf_i.predict_proba(Xva_i)[:, 1]\n",
        "    pte_img_v = clf_i.predict_proba(Xte_i)[:, 1]\n",
        "\n",
        "# ===== 7) Pooling to cow-level (only when cow-aligned); otherwise identity per image =====\n",
        "def logistic_temp(p, tau):\n",
        "    p = np.clip(p, 1e-9, 1-1e-9); z = np.log(p/(1-p))/tau\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "def pre_event_mask(keys):\n",
        "    if use_tab_split:\n",
        "        dfk = pd.DataFrame({'k': keys})\n",
        "        last = dfk.groupby('k').tail(1).index\n",
        "        mask = pd.Series(True, index=pd.RangeIndex(len(keys)))\n",
        "        mask.loc[last] = False\n",
        "        return mask.values\n",
        "    return np.ones(len(keys), dtype=bool)\n",
        "\n",
        "def pooling_scores(p_visit, keys, tau, r, topk, jitter=0.006, seed=SEED):\n",
        "    if not use_tab_split:\n",
        "        return pd.Series(p_visit, index=pd.Index(keys, name='k'))\n",
        "    pt = logistic_temp(p_visit, tau)\n",
        "    if jitter > 0:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        pt = np.clip(pt + rng.normal(0.0, jitter, size=pt.shape), 1e-9, 1-1e-9)\n",
        "    dfp = pd.DataFrame({'k': keys, 'pt': pt})\n",
        "    dfp = dfp[pre_event_mask(keys)]\n",
        "    if len(dfp) == 0: return pd.Series(dtype=float)\n",
        "    med = dfp.groupby('k')['pt'].transform('median')\n",
        "    exc = (dfp['pt'] - med).clip(lower=0)\n",
        "    def pmean(x, rr):\n",
        "        xv = x.values\n",
        "        return (((xv**rr).mean())**(1.0/rr)) if xv.size>0 else np.nan\n",
        "    def topk_mean(x, kk):\n",
        "        xv = np.sort(x.values)\n",
        "        if xv.size == 0: return np.nan\n",
        "        kk = min(kk, xv.size)\n",
        "        return float(xv[-kk:].mean())\n",
        "    pm = exc.groupby(dfp['k']).apply(lambda s: pmean(s, r))\n",
        "    tk = exc.groupby(dfp['k']).apply(lambda s: topk_mean(s, topk))\n",
        "    return (pm + tk) / 2.0\n",
        "\n",
        "if use_tab_split:\n",
        "    yva_cow = val_df.groupby(\"Cow_ID_match\")['class1'].max().astype(int)\n",
        "    yte_cow = test_df.groupby(\"Cow_ID_match\")['class1'].max().astype(int)\n",
        "    taus, rs, topks = [2.0, 2.6, 3.0], [0.7, 0.9], [2, 3, 4]\n",
        "    best_img = None\n",
        "    for tau in taus:\n",
        "        for r in rs:\n",
        "            for k in topks:\n",
        "                pva_img_c = pooling_scores(pva_img_v, Kva_i, tau, r, k).reindex(yva_cow.index).fillna(0.0).values\n",
        "                ap = average_precision_score(yva_cow.values.astype(int), pva_img_c)\n",
        "                if (best_img is None) or (ap > best_img[0]):\n",
        "                    best_img = (ap, tau, r, k, pva_img_c)\n",
        "    ap_img, TAU_I, R_I, K_I, pva_img_c = best_img\n",
        "    pte_img_c = pooling_scores(pte_img_v, Kte_i, TAU_I, R_I, K_I).reindex(yte_cow.index).fillna(0.0).values\n",
        "    print(f\"[Tune IMG] AP(VAL)={ap_img:.4f} tau={TAU_I}, r={R_I}, K={K_I}\", flush=True)\n",
        "else:\n",
        "    yva_cow = pd.Series(yva_i, index=Kva_i)  # per-image labels\n",
        "    yte_cow = pd.Series(yte_i, index=Kte_i)\n",
        "    pva_img_c = pd.Series(pva_img_v, index=Kva_i).reindex(yva_cow.index).fillna(0.0).values\n",
        "    pte_img_c = pd.Series(pte_img_v, index=Kte_i).reindex(yte_cow.index).fillna(0.0).values\n",
        "\n",
        "# Calibration (Platt) on VAL\n",
        "cal_img = LRCal(max_iter=1000, random_state=SEED).fit(pva_img_c.reshape(-1,1), yva_cow.values.astype(int))\n",
        "pva_img_cal = cal_img.predict_proba(pva_img_c.reshape(-1,1))[:,1]\n",
        "pte_img_cal = cal_img.predict_proba(pte_img_c.reshape(-1,1))[:,1]\n",
        "\n",
        "# ===== 8) Fusion with tabular (needs pva_c/pte_c from Cell 5) =====\n",
        "tab_ready_scores = (use_tab_split and (\"pva_c\" in globals()) and (\"pte_c\" in globals()))\n",
        "if not tab_ready_scores:\n",
        "    print(\"[Fusion] Images-only (no tabular per-cow scores available or no cow alignment).\", flush=True)\n",
        "    pva_tab = np.zeros_like(pva_img_cal); pte_tab = np.zeros_like(pte_img_cal)\n",
        "else:\n",
        "    pva_tab = pd.Series(pva_c, index=yva_cow.index).reindex(yva_cow.index).fillna(0.0).values\n",
        "    pte_tab = pd.Series(pte_c, index=yte_cow.index).reindex(yte_cow.index).fillna(0.0).values\n",
        "\n",
        "def ranknorm(x):\n",
        "    r = np.argsort(np.argsort(x))\n",
        "    return r / max(len(x)-1, 1)\n",
        "\n",
        "weights = [0.0, 0.25, 0.5, 0.75, 1.0]   # weight on TAB (w), 1-w on IMG\n",
        "best = None\n",
        "for w in weights:\n",
        "    va_f = w*ranknorm(pva_tab) + (1-w)*ranknorm(pva_img_cal)\n",
        "    ap = average_precision_score(yva_cow.values.astype(int), va_f)\n",
        "    if (best is None) or (ap > best[0]):\n",
        "        best = (ap, w, va_f)\n",
        "ap_fuse, W, va_fused = best\n",
        "te_fused = W*ranknorm(pte_tab) + (1-W)*ranknorm(pte_img_cal)\n",
        "\n",
        "cal_f = LRCal(max_iter=1000, random_state=SEED).fit(va_fused.reshape(-1,1), yva_cow.values.astype(int))\n",
        "pva_f = cal_f.predict_proba(va_fused.reshape(-1,1))[:,1]\n",
        "pte_f = cal_f.predict_proba(te_fused.reshape(-1,1))[:,1]\n",
        "\n",
        "# ===== 9) Metrics, bootstrap, threshold, figures =====\n",
        "def metr(name, y, p):\n",
        "    p = np.clip(p, 1e-9, 1-1e-9)\n",
        "    try: auc = roc_auc_score(y, p)\n",
        "    except: auc = np.nan\n",
        "    ap = average_precision_score(y, p); br = brier_score_loss(y, p)\n",
        "    return dict(name=name, AUROC=float(auc) if auc==auc else np.nan, AUPRC=float(ap), Brier=float(br), N=int(len(y)))\n",
        "\n",
        "rows = []\n",
        "rows.append(metr(\"VAL IMG only\",  yva_cow.values, pva_img_cal))\n",
        "rows.append(metr(\"TEST IMG only\", yte_cow.values, pte_img_cal))\n",
        "if tab_ready_scores:\n",
        "    rows.append(metr(\"VAL TAB only\",  yva_cow.values, pva_tab))\n",
        "    rows.append(metr(\"TEST TAB only\", yte_cow.values, pte_tab))\n",
        "rows.append(metr(f\"VAL FUSION (w={W:.2f})\",  yva_cow.values, pva_f))\n",
        "rows.append(metr(f\"TEST FUSION (w={W:.2f})\", yte_cow.values, pte_f))\n",
        "\n",
        "summary_df = pd.DataFrame(rows)\n",
        "print(\"\\n=== Multimodal Summary ===\", flush=True)\n",
        "print(summary_df[[\"name\",\"AUROC\",\"AUPRC\",\"Brier\",\"N\"]].to_string(index=False), flush=True)\n",
        "\n",
        "def bootstrap_metrics(y, p, n_boot=200, seed=SEED):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    y = np.asarray(y, dtype=int); p = np.asarray(p, dtype=float)\n",
        "    n = len(y)\n",
        "    aucs, aps = [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        yy, pp = y[idx], p[idx]\n",
        "        if len(np.unique(yy)) < 2: aucs.append(np.nan)\n",
        "        else: aucs.append(roc_auc_score(yy, pp))\n",
        "        aps.append(average_precision_score(yy, pp))\n",
        "    aucs, aps = np.array(aucs, dtype=float), np.array(aps, dtype=float)\n",
        "    def stat(x):\n",
        "        x = x[np.isfinite(x)]\n",
        "        if x.size == 0:\n",
        "            return dict(mean=np.nan, std=np.nan, ci_lo=np.nan, ci_hi=np.nan)\n",
        "        return dict(mean=float(np.mean(x)),\n",
        "                    std=float(np.std(x, ddof=1) if x.size>1 else 0.0),\n",
        "                    ci_lo=float(np.quantile(x, 0.025)),\n",
        "                    ci_hi=float(np.quantile(x, 0.975)))\n",
        "    return stat(aucs), stat(aps)\n",
        "\n",
        "boot_results = []\n",
        "def add_boot(name, y, p):\n",
        "    auc_s, ap_s = bootstrap_metrics(y, p, n_boot=200)\n",
        "    boot_results.append(dict(model=name,\n",
        "                             AUROC_mean=auc_s['mean'], AUROC_std=auc_s['std'], AUROC_ci_lo=auc_s['ci_lo'], AUROC_ci_hi=auc_s['ci_hi'],\n",
        "                             AUPRC_mean=ap_s['mean'], AUPRC_std=ap_s['std'], AUPRC_ci_lo=ap_s['ci_lo'], AUPRC_ci_hi=ap_s['ci_hi']))\n",
        "\n",
        "add_boot(\"TEST IMG only\", yte_cow.values, pte_img_cal)\n",
        "if tab_ready_scores:\n",
        "    add_boot(\"TEST TAB only\", yte_cow.values, pte_tab)\n",
        "add_boot(f\"TEST FUSION (w={W:.2f})\", yte_cow.values, pte_f)\n",
        "\n",
        "boot_df = pd.DataFrame(boot_results)\n",
        "print(\"\\n=== Bootstrap (TEST) ===\")\n",
        "print(boot_df.to_string(index=False))\n",
        "\n",
        "def best_thresh_by_f1(y, p):\n",
        "    prec, rec, thr = precision_recall_curve(y, p)\n",
        "    f1 = np.where((prec+rec) > 0, 2*prec*rec/(prec+rec), 0.0)\n",
        "    ix = int(np.nanargmax(f1))\n",
        "    t = float(thr[ix]) if ix < len(thr) else 0.5\n",
        "    return t, float(f1[ix] if ix < len(f1) else 0.0)\n",
        "\n",
        "pva_final = (pva_f if tab_ready_scores else pva_img_cal)\n",
        "pte_final = (pte_f if tab_ready_scores else pte_img_cal)\n",
        "th_opt, f1_val = best_thresh_by_f1(yva_cow.values, pva_final)\n",
        "print(f\"\\n[Thresh] Best F1 on VAL: threshold={th_opt:.4f}, F1={f1_val:.4f}\")\n",
        "\n",
        "yte_pred = (pte_final >= th_opt).astype(int)\n",
        "cm = confusion_matrix(yte_cow.values, yte_pred, labels=[0,1])\n",
        "tn, fp, fn, tp = cm.ravel() if cm.size==4 else (cm[0,0], cm[0,1], cm[1,0], cm[1,1])\n",
        "acc = (tp+tn)/np.sum(cm)\n",
        "prec = tp/max(tp+fp, 1)\n",
        "rec  = tp/max(tp+fn, 1)\n",
        "f1_te = 2*prec*rec/max(prec+rec, 1e-9)\n",
        "print(f\"[ConfMat TEST] TP={tp} FP={fp} FN={fn} TN={tn} | Acc={acc:.3f} Prec={prec:.3f} Rec={rec:.3f} F1={f1_te:.3f}\")\n",
        "\n",
        "# ===== 10) Figures & CSVs =====\n",
        "def savefig(path):\n",
        "    plt.savefig(path, dpi=200, bbox_inches='tight'); plt.close()\n",
        "\n",
        "def plot_roc_pr(y, p, split_name):\n",
        "    if len(np.unique(y)) > 1:\n",
        "        fpr, tpr, _ = roc_curve(y, p); auc = roc_auc_score(y, p)\n",
        "    else:\n",
        "        fpr, tpr, auc = np.array([0,1]), np.array([0,1]), np.nan\n",
        "    # ROC\n",
        "    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\" if auc==auc else \"AUC=N/A\")\n",
        "    plt.plot([0,1],[0,1],'--'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {split_name}\")\n",
        "    plt.legend(loc=\"lower right\"); savefig(os.path.join(FIGDIR, f\"roc_{split_name.lower().replace(' ','_')}.png\"))\n",
        "    # PR\n",
        "    precs, recs, _ = precision_recall_curve(y, p); ap = average_precision_score(y, p)\n",
        "    plt.figure(); plt.plot(recs, precs, label=f\"AP={ap:.3f}\")\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {split_name}\")\n",
        "    plt.legend(loc=\"lower left\"); savefig(os.path.join(FIGDIR, f\"pr_{split_name.lower().replace(' ','_')}.png\"))\n",
        "\n",
        "def plot_confmat(cm, split_name=\"TEST\"):\n",
        "    plt.figure(); im = plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(f\"Confusion Matrix — {split_name}\")\n",
        "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "    ticks = np.arange(2); plt.xticks(ticks, ['0','1']); plt.yticks(ticks, ['0','1'])\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\", fontsize=10)\n",
        "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
        "    savefig(os.path.join(FIGDIR, f\"confusion_matrix_{split_name.lower()}.png\"))\n",
        "\n",
        "plot_roc_pr(yva_cow.values, pva_final, \"VAL_final\")\n",
        "plot_roc_pr(yte_cow.values, pte_final, \"TEST_final\")\n",
        "plot_confmat(cm, \"TEST\")\n",
        "\n",
        "summary_df.to_csv(os.path.join(FIGDIR, \"summary_multimodal.csv\"), index=False)\n",
        "boot_df.to_csv(os.path.join(FIGDIR, \"bootstrap_test_metrics.csv\"), index=False)\n",
        "pd.DataFrame({\n",
        "    \"threshold\": [th_opt],\n",
        "    \"F1_VAL\": [f1_val],\n",
        "    \"Acc_TEST\": [acc],\n",
        "    \"Precision_TEST\": [prec],\n",
        "    \"Recall_TEST\": [rec],\n",
        "    \"F1_TEST\": [f1_te],\n",
        "    \"TP\":[tp], \"FP\":[fp], \"FN\":[fn], \"TN\":[tn]\n",
        "}).to_csv(os.path.join(FIGDIR, \"threshold_confmat_stats.csv\"), index=False)\n",
        "\n",
        "# Debug payload (for reproducibility)\n",
        "def pyify(obj):\n",
        "    import numpy as _np, torch as _torch, pandas as _pd\n",
        "    if isinstance(obj, (_np.generic,)): return obj.item()\n",
        "    if isinstance(obj, _torch.Tensor):  return obj.item() if obj.ndim == 0 else obj.detach().cpu().tolist()\n",
        "    if isinstance(obj, (_pd.Series, _pd.Index)): return obj.tolist()\n",
        "    if isinstance(obj, dict):  return {k: pyify(v) for k, v in obj.items()}\n",
        "    if isinstance(obj, (list, tuple)): return [pyify(x) for x in obj]\n",
        "    if isinstance(obj, (np.ndarray,)): return obj.tolist()\n",
        "    return obj\n",
        "\n",
        "payload = dict(\n",
        "    device=str(DEVICE),\n",
        "    seed=int(SEED),\n",
        "    source=str(source),\n",
        "    counts=dict(train_img=int(len(lab_tr)), val_img=int(len(lab_va)), test_img=int(len(lab_te))),\n",
        "    use_tab_split=bool(use_tab_split),\n",
        "    fusion_weight=float(W),\n",
        "    coco_json=str(COCO_JSON_PATH),\n",
        "    image_dir=str(IMAGE_DIR),\n",
        "    label_dir=str(LABEL_DIR),\n",
        "    metrics=rows,\n",
        "    threshold=float(th_opt),\n",
        "    f1_val=float(f1_val),\n",
        "    confmat=dict(TP=int(tp), FP=int(fp), FN=int(fn), TN=int(tn))\n",
        ")\n",
        "with open(os.path.join(SAVE_DIR, \"debug_multimodal.json\"), \"w\") as f:\n",
        "    json.dump(pyify(payload), f, indent=2)\n",
        "\n",
        "print(f\"\\n[OK] Figures and tables saved to: {FIGDIR}\")\n",
        "print(f\"[OK] Quick summaries in: {SAVE_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788,
          "referenced_widgets": [
            "48c332fdd75849e4ae73a82d87bdfa56",
            "16ff3847811746dfaf5f19d22a15d85a",
            "4541a4aa5d434905897ee26c5513caaf",
            "cb7ff0fb84094d2a8a5b2fe1162c7beb",
            "9201331d59c74636b13ccb9782252b3a",
            "8da2569d16124583830c32a3989ff285",
            "d8d2e5e99572406db34741735e51ee0b",
            "c18ef2080bbd488baed4485d8eee1891",
            "e5435c36dcfc429fae4c63e4ebd9db66",
            "521c41f6749d4e6abcb9f638f9f8da09",
            "229f3112dd264b398dd2c2e3215c19c3",
            "4c39040796a34a268e69adbbf02108a8",
            "239c642f43104e6ca670491276fda626",
            "43becd1cddc1429d8d9932b9c17a6434",
            "ff4480803c5545bf9b620a9995d3e4b2",
            "eb50c150cb364943815a5d9bfc3da2b0",
            "fce6232d00bb4e179233578d6e158c9b",
            "0237a153a2614f1883b8c5cdbe1500c8",
            "4737a3e65be94e33a2b912cfb5a90423",
            "ee9671ba9b7f432991ec0ea0a939ed4f",
            "96209a2c9209408dbce4315faaa5dfab",
            "0a37e33be3f94614b8efcf66d0045177",
            "5679757fc4e1424aaa941c479c79307d",
            "f60e8965a2fe4edc9a78f4fb74dd9279",
            "54d3892f2d0746de82ef203aa97fbf5d",
            "f374477d0e9c424f9c69a2ac73e5f0f8",
            "5d4e16e725b743a2b971d16dc41dabbd",
            "5bd5aba3e54c4befb6bf1d3713314497",
            "3f4f60067148454496d2ba7dddf0c160",
            "70f7efd2a87141fb8e63315325ad7901",
            "24a1f376075d4906871ce05f1510f558",
            "766005da7a804a6fb573695914632481",
            "dd3b3aebb6494fa4a5e232d0bb134ec7",
            "68ab30e6d00f4d30b637116b8fe1d83f",
            "abfb9e9ab1364758a338d10cef0f548f",
            "1edb69ab9e954690899eddadc8f24b65",
            "11f919e642e94060bb6afcd7059c36a9",
            "e38b73c45f9045d3a7b8d1e2528a947f",
            "b0643f64cac8405298ef8cebfe97fc95",
            "9b850bac628c45a4a0858323cf4668fa",
            "795f4048465542ba87e1ed6f5d1e1357",
            "481bdc833aaf499eb2b4cb8860964b5d",
            "b5d982fe8fc94dda99cff7f4746a004d",
            "1bbc389bff8f4726822f7dbc1a5dad40"
          ]
        },
        "id": "6xnwLnBNXgga",
        "outputId": "2b806de4-959d-4b17-f1eb-5016dcce2946"
      },
      "id": "6xnwLnBNXgga",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MOUNT] IN_COLAB: True\n",
            "[PATHS] PROJECT_DIR: /content/drive/MyDrive/Mastitis_illness_cow/datasets\n",
            "[PATHS] IMAGE_DIR exists: True | LABEL_DIR exists: True\n",
            "[PATHS] COCO_JSON_PATH: /content/drive/MyDrive/Mastitis_illness_cow/exports/_annotations.coco.json | exists: True\n",
            "[ENV] torch=2.8.0+cu126 | torchvision=0.23.0+cu126 | device=cuda\n",
            "[Index] Indexed images: 130\n",
            "[COCO][WARN] No explicit positive names found. Falling back to category_id==1.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parse YOLO labels:   0%|          | 0/130 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48c332fdd75849e4ae73a82d87bdfa56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Labels] COCO resolved: 130 | YOLO-txt resolved: 130\n",
            "[Labels] Using source: COCO | rows=130\n",
            "[Align][WARN] Insufficient cow coverage or single-class in TRAIN (cows=1, two_classes=False).\n",
            "[IMG rows] train=91 | val=19 | test=20\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 193MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GPU] NVIDIA L4 | cap=(8, 9)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Emb TR:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c39040796a34a268e69adbbf02108a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TIMING] Emb TR: 91 img in 41.85s → 2.2 img/s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Emb VA:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5679757fc4e1424aaa941c479c79307d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TIMING] Emb VA: 19 img in 8.88s → 2.1 img/s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Emb TE:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68ab30e6d00f4d30b637116b8fe1d83f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TIMING] Emb TE: 20 img in 9.46s → 2.1 img/s\n",
            "[Emb] TR=(91, 512) VA=(19, 512) TE=(20, 512)\n",
            "[Fusion] Images-only (no tabular per-cow scores available or no cow alignment).\n",
            "\n",
            "=== Multimodal Summary ===\n",
            "                name    AUROC    AUPRC    Brier  N\n",
            "        VAL IMG only 0.877778 0.881734 0.192763 19\n",
            "       TEST IMG only 0.909091 0.879497 0.183106 20\n",
            " VAL FUSION (w=0.25) 0.883333 0.898589 0.213339 19\n",
            "TEST FUSION (w=0.25) 0.878788 0.797470 0.206480 20\n",
            "\n",
            "=== Bootstrap (TEST) ===\n",
            "               model  AUROC_mean  AUROC_std  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_std  AUPRC_ci_lo  AUPRC_ci_hi\n",
            "       TEST IMG only    0.912019   0.066956     0.729069          1.0    0.890407   0.090993     0.666071          1.0\n",
            "TEST FUSION (w=0.25)    0.879138   0.081333     0.699396          1.0    0.816387   0.121691     0.571401          1.0\n",
            "\n",
            "[Thresh] Best F1 on VAL: threshold=0.4475, F1=0.8235\n",
            "[ConfMat TEST] TP=8 FP=2 FN=1 TN=9 | Acc=0.850 Prec=0.800 Rec=0.889 F1=0.842\n",
            "\n",
            "[OK] Figures and tables saved to: /content/drive/MyDrive/Mastitis_illness_cow/datasets/figures_and_tables\n",
            "[OK] Quick summaries in: /content/mastitis_outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6B) Multimodal Fusion (images ⊕ tabular) — robust cow alignment, tuning on VAL, calibration, CIs =====\n",
        "# Goal: restore image–tabular fusion cleanly. We (a) align cows on VAL/TEST, (b) tune fusion weight on VAL AUPRC,\n",
        "# (c) calibrate on VAL, (d) report AUROC/AUPRC/Brier + bootstrap 95% CIs on TEST.\n",
        "# Safe even if tabular scores are missing: it falls back to images-only with a clear log.\n",
        "\n",
        "import numpy as np, pandas as pd, warnings\n",
        "from sklearn.linear_model import LogisticRegression as LRCal\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "SEED = 42\n",
        "rng  = np.random.default_rng(SEED)\n",
        "\n",
        "# ---- Expectations (robust): we try to consume what's already available from previous cells ----\n",
        "# From imaging branch (cell 6): per-cow probabilities (or per-image collapsed to cow) on VAL/TEST.\n",
        "# Expected names (any of these):\n",
        "_img_val_candidates  = ['pva_img_c', 'p_val_img_cow', 'pva_img_cal']\n",
        "_img_test_candidates = ['pte_img_c', 'p_test_img_cow', 'pte_img_cal']\n",
        "\n",
        "# From tabular branch (cell 5): per-cow probabilities on VAL/TEST (already calibrated)\n",
        "_tab_val_candidates  = ['pva_c', 'p_val_tab_cow', 'pva_tab']\n",
        "_tab_test_candidates = ['pte_c', 'p_test_tab_cow', 'pte_tab']\n",
        "\n",
        "# Cow-level targets and indices\n",
        "# If we had a tabular split earlier, prefer it (true cow labels). Else derive from imaging split.\n",
        "def _first_existing(names):\n",
        "    for n in names:\n",
        "        if n in globals():\n",
        "            return globals()[n]\n",
        "    return None\n",
        "\n",
        "pva_img = _first_existing(_img_val_candidates)\n",
        "pte_img = _first_existing(_img_test_candidates)\n",
        "\n",
        "pva_tab = _first_existing(_tab_val_candidates)\n",
        "pte_tab = _first_existing(_tab_test_candidates)\n",
        "\n",
        "# Cow index + labels on VAL / TEST\n",
        "# Prefer tabular y (class1 aggregated) if available:\n",
        "def _y_cow_from_tab(df_split):\n",
        "    return df_split.groupby('Cow_ID_match')['class1'].max().astype(int)\n",
        "\n",
        "if 'val_df' in globals() and 'test_df' in globals() and \\\n",
        "   ('Cow_ID_match' in val_df.columns) and ('class1' in val_df.columns):\n",
        "    yva_cow = _y_cow_from_tab(val_df)\n",
        "    yte_cow = _y_cow_from_tab(test_df)\n",
        "    idx_val = yva_cow.index\n",
        "    idx_te  = yte_cow.index\n",
        "else:\n",
        "    # Imaging fallback: use image cow keys & labels (max over images)\n",
        "    if 'Kva_i' in globals() and 'yva_i' in globals():\n",
        "        yva_cow = pd.Series(yva_i, index=pd.Index(Kva_i, name='Cow_ID_match')).groupby(level=0).max().astype(int)\n",
        "        idx_val = yva_cow.index\n",
        "    else:\n",
        "        raise RuntimeError(\"Cannot infer VAL cow labels; please run imaging cell first.\")\n",
        "    if 'Kte_i' in globals() and 'yte_i' in globals():\n",
        "        yte_cow = pd.Series(yte_i, index=pd.Index(Kte_i, name='Cow_ID_match')).groupby(level=0).max().astype(int)\n",
        "        idx_te = yte_cow.index\n",
        "    else:\n",
        "        raise RuntimeError(\"Cannot infer TEST cow labels; please run imaging cell first.\")\n",
        "\n",
        "# Wrap scores as Series and align to cow indices; handle missing tabular by zeros\n",
        "def _as_series(x, idx):\n",
        "    if x is None:\n",
        "        return pd.Series(np.zeros(len(idx), dtype=float), index=idx)\n",
        "    if isinstance(x, (list, np.ndarray)):\n",
        "        s = pd.Series(x, index=idx) if len(x)==len(idx) else pd.Series(x, index=idx[:len(x)])\n",
        "        s = s.reindex(idx).fillna(0.0)\n",
        "        return s\n",
        "    if isinstance(x, pd.Series):\n",
        "        return x.reindex(idx).fillna(0.0)\n",
        "    # dict or anything else → try convert\n",
        "    try:\n",
        "        s = pd.Series(x, index=idx)\n",
        "        return s.reindex(idx).fillna(0.0)\n",
        "    except Exception:\n",
        "        return pd.Series(np.zeros(len(idx), dtype=float), index=idx)\n",
        "\n",
        "pva_img_s = _as_series(pva_img, idx_val)\n",
        "pte_img_s = _as_series(pte_img, idx_te)\n",
        "\n",
        "pva_tab_s = _as_series(pva_tab, idx_val)\n",
        "pte_tab_s = _as_series(pte_tab, idx_te)\n",
        "\n",
        "tab_ready = (pva_tab is not None) and (pte_tab is not None)\n",
        "\n",
        "# Rank-normalisation helper (stable with tiny N)\n",
        "def ranknorm(x: np.ndarray) -> np.ndarray:\n",
        "    order = np.argsort(np.argsort(x))\n",
        "    n = max(len(x)-1, 1)\n",
        "    return order / n\n",
        "\n",
        "# ---- Tune fusion weight on VAL (AUPRC) --------------------------------------\n",
        "weights = [0.0, 0.25, 0.5, 0.75, 1.0] if tab_ready else [0.0]\n",
        "best = None\n",
        "for w in weights:\n",
        "    va_f = w*ranknorm(pva_tab_s.values) + (1.0 - w)*ranknorm(pva_img_s.values)\n",
        "    try:\n",
        "        ap = average_precision_score(yva_cow.values.astype(int), va_f)\n",
        "    except Exception:\n",
        "        ap = -np.inf\n",
        "    if (best is None) or (ap > best[0]):\n",
        "        best = (ap, w, va_f)\n",
        "\n",
        "ap_best, W, va_fused = best\n",
        "te_fused = W*ranknorm(pte_tab_s.values) + (1.0 - W)*ranknorm(pte_img_s.values)\n",
        "\n",
        "# ---- Platt calibration on VAL (fusion score) --------------------------------\n",
        "cal = LRCal(max_iter=1000, random_state=SEED)\n",
        "cal.fit(va_fused.reshape(-1,1), yva_cow.values.astype(int))\n",
        "pva_final = cal.predict_proba(va_fused.reshape(-1,1))[:,1]\n",
        "pte_final = cal.predict_proba(te_fused.reshape(-1,1))[:,1]\n",
        "\n",
        "# ---- Metrics (AUROC, AUPRC, Brier) -----------------------------------------\n",
        "def metr(name, y, p):\n",
        "    p = np.clip(p, 1e-9, 1-1e-9)\n",
        "    try: auc = roc_auc_score(y, p)\n",
        "    except: auc = np.nan\n",
        "    ap = average_precision_score(y, p)\n",
        "    br = brier_score_loss(y, p)\n",
        "    return dict(name=name, AUROC=float(auc) if auc==auc else np.nan, AUPRC=float(ap), Brier=float(br), N=int(len(y)))\n",
        "\n",
        "rows = []\n",
        "rows.append(metr(\"VAL IMG only\",  yva_cow.values, pva_img_s.values))\n",
        "rows.append(metr(\"TEST IMG only\", yte_cow.values, pte_img_s.values))\n",
        "if tab_ready:\n",
        "    rows.append(metr(\"VAL TAB only\",  yva_cow.values, pva_tab_s.values))\n",
        "    rows.append(metr(\"TEST TAB only\", yte_cow.values, pte_tab_s.values))\n",
        "rows.append(metr(f\"VAL FUSION (w={W:.2f})\",  yva_cow.values, pva_final))\n",
        "rows.append(metr(f\"TEST FUSION (w={W:.2f})\", yte_cow.values, pte_final))\n",
        "summary_fusion = pd.DataFrame(rows)\n",
        "print(\"\\n=== Fusion (reinstated) — Summary ===\")\n",
        "print(summary_fusion[[\"name\",\"AUROC\",\"AUPRC\",\"Brier\",\"N\"]].to_string(index=False))\n",
        "\n",
        "# ---- Bootstrap 95% CIs on TEST ---------------------------------------------\n",
        "def bootstrap_metrics(y, p, n_boot=400, seed=SEED):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    y = np.asarray(y, dtype=int); p = np.asarray(p, dtype=float)\n",
        "    n = len(y)\n",
        "    aucs, aps = [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        yy, pp = y[idx], p[idx]\n",
        "        if len(np.unique(yy)) < 2:\n",
        "            aucs.append(np.nan)\n",
        "        else:\n",
        "            aucs.append(roc_auc_score(yy, pp))\n",
        "        aps.append(average_precision_score(yy, pp))\n",
        "    aucs = np.array(aucs, dtype=float); aps = np.array(aps, dtype=float)\n",
        "    def stat(x):\n",
        "        x = x[np.isfinite(x)]\n",
        "        if x.size == 0:\n",
        "            return dict(mean=np.nan, ci_lo=np.nan, ci_hi=np.nan)\n",
        "        return dict(mean=float(np.mean(x)),\n",
        "                    ci_lo=float(np.quantile(x, 0.025)),\n",
        "                    ci_hi=float(np.quantile(x, 0.975)))\n",
        "    return stat(aucs), stat(aps)\n",
        "\n",
        "boot = []\n",
        "def add_boot(name, y, p):\n",
        "    auc_s, ap_s = bootstrap_metrics(y, p, n_boot=400)\n",
        "    boot.append(dict(model=name,\n",
        "                     AUROC_mean=auc_s['mean'], AUROC_ci_lo=auc_s['ci_lo'], AUROC_ci_hi=auc_s['ci_hi'],\n",
        "                     AUPRC_mean=ap_s['mean'], AUPRC_ci_lo=ap_s['ci_lo'], AUPRC_ci_hi=ap_s['ci_hi']))\n",
        "\n",
        "add_boot(\"TEST IMG only\", yte_cow.values, pte_img_s.values)\n",
        "if tab_ready:\n",
        "    add_boot(\"TEST TAB only\", yte_cow.values, pte_tab_s.values)\n",
        "add_boot(f\"TEST FUSION (w={W:.2f})\", yte_cow.values, pte_final)\n",
        "boot_fusion = pd.DataFrame(boot)\n",
        "print(\"\\n=== Fusion — Bootstrap 95% CIs (TEST) ===\")\n",
        "print(boot_fusion.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQLUHTtebdc0",
        "outputId": "86dcade5-f533-4099-dbcc-bfaf82518aac"
      },
      "id": "nQLUHTtebdc0",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fusion (reinstated) — Summary ===\n",
            "                name    AUROC    AUPRC    Brier   N\n",
            "        VAL IMG only 0.498449 0.198620 0.176908 220\n",
            "       TEST IMG only 0.477699 0.166556 0.189445 220\n",
            "        VAL TAB only 0.741323 0.474406 0.125696 220\n",
            "       TEST TAB only 0.838502 0.645940 0.116652 220\n",
            " VAL FUSION (w=1.00) 0.740954 0.476707 0.126481 220\n",
            "TEST FUSION (w=1.00) 0.838429 0.647522 0.116728 220\n",
            "\n",
            "=== Fusion — Bootstrap 95% CIs (TEST) ===\n",
            "               model  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi\n",
            "       TEST IMG only    0.478448     0.437829     0.527920    0.170338     0.118182     0.226891\n",
            "       TEST TAB only    0.835561     0.751638     0.903531    0.644324     0.485268     0.771082\n",
            "TEST FUSION (w=1.00)    0.835523     0.751545     0.904102    0.645846     0.486028     0.771586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell X — Rebuild df_images_full (COCO + YOLO fallback, robust cow-id parsing)\n",
        "# What this cell does (high-level, Claude-style):\n",
        "# • Index images from IMAGE_DIR and labels from either a COCO JSON or YOLO .txt files.\n",
        "# • Prefer COCO labels when available; otherwise fall back to YOLO .txt.\n",
        "# • Parse cow IDs from filenames/paths using resilient heuristics consistent with prior cells.\n",
        "# • Produce df_images_full with at least: ['file_name', 'abs_path', 'class1', '_cid_'].\n",
        "# • Print clear diagnostics so downstream CV/fusion cells can rely on this structure.\n",
        "# Preconditions:\n",
        "#   - Define PROJECT_DIR (or let default), IMAGE_DIR, and (optionally) COCO_JSON_PATH / LABEL_DIR.\n",
        "# =======================\n",
        "\n",
        "import os, re, json, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------- 0) Paths and defaults ----------\n",
        "if 'PROJECT_DIR' not in globals():\n",
        "    PROJECT_DIR = \"/content/drive/MyDrive/Mastitis_illness_cow/datasets\"\n",
        "\n",
        "IMAGE_DIR = globals().get('IMAGE_DIR', os.path.join(PROJECT_DIR, \"images\"))\n",
        "LABEL_DIR = globals().get('LABEL_DIR', os.path.join(PROJECT_DIR, \"labels\"))  # YOLO .txt (optional)\n",
        "COCO_JSON_PATH = globals().get('COCO_JSON_PATH', os.path.join(os.path.dirname(PROJECT_DIR), \"exports\", \"_annotations.coco.json\"))\n",
        "\n",
        "POSITIVE_CLASS_ID = 1   # If COCO has no explicit positive names, treat category_id==1 as positive\n",
        "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"}\n",
        "\n",
        "print(f\"[PATHS] PROJECT_DIR: {PROJECT_DIR}\")\n",
        "print(f\"[PATHS] IMAGE_DIR exists: {os.path.isdir(IMAGE_DIR)} | LABEL_DIR exists: {os.path.isdir(LABEL_DIR)}\")\n",
        "print(f\"[PATHS] COCO_JSON_PATH: {COCO_JSON_PATH} | exists: {os.path.isfile(COCO_JSON_PATH)}\")\n",
        "\n",
        "# ---------- 1) Build an index: stem -> absolute image path ----------\n",
        "stem2path = {}\n",
        "for root, _, files in os.walk(IMAGE_DIR):\n",
        "    for f in files:\n",
        "        ext = os.path.splitext(f)[1].lower()\n",
        "        if ext in IMG_EXTS:\n",
        "            stem = os.path.splitext(f)[0]\n",
        "            abs_path = os.path.join(root, f)\n",
        "            # If duplicates exist, keep the first encountered (paths should be unique ideally)\n",
        "            stem2path.setdefault(stem, abs_path)\n",
        "\n",
        "print(f\"[Index] Indexed images: {len(stem2path)}\")\n",
        "\n",
        "def stem_of(path_or_name: str) -> str:\n",
        "    b = os.path.basename(path_or_name)\n",
        "    return os.path.splitext(b)[0]\n",
        "\n",
        "# ---------- 2) Try COCO first ----------\n",
        "def labels_from_coco(json_path: str):\n",
        "    \"\"\"\n",
        "    Parse COCO and create a DataFrame with columns: file_name, class1.\n",
        "    Positive rule:\n",
        "      • If any category name contains a 'positive' keyword → use that.\n",
        "      • Else fallback: category_id == POSITIVE_CLASS_ID.\n",
        "    An image is positive if any annotation marks it positive; else negative.\n",
        "    \"\"\"\n",
        "    with open(json_path, \"r\") as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    images = pd.DataFrame(coco.get(\"images\", []))\n",
        "    ann    = pd.DataFrame(coco.get(\"annotations\", []))\n",
        "    cats   = pd.DataFrame(coco.get(\"categories\", []))\n",
        "\n",
        "    print(f\"[COCO] images={len(images)} | annotations={len(ann)} | categories={len(cats)}\")\n",
        "\n",
        "    # Identify positive category IDs if names suggest so\n",
        "    pos_name_patterns = (\"mastitis\", \"lesion\", \"abnormal\", \"positive\", \"infect\")\n",
        "    pos_ids = set()\n",
        "    if not cats.empty and \"name\" in cats.columns:\n",
        "        for _, r in cats.iterrows():\n",
        "            nm = str(r.get(\"name\", \"\")).lower()\n",
        "            if any(tok in nm for tok in pos_name_patterns):\n",
        "                pos_ids.add(int(r[\"id\"]))\n",
        "    if not pos_ids:\n",
        "        print(\"[COCO][WARN] No explicit positive names found. Falling back to category_id==1.\")\n",
        "        pos_ids = {POSITIVE_CLASS_ID}\n",
        "\n",
        "    # Determine per-image positivity\n",
        "    img_pos = {}\n",
        "    if not ann.empty and \"image_id\" in ann.columns and \"category_id\" in ann.columns:\n",
        "        for img_id, g in ann.groupby(\"image_id\"):\n",
        "            is_pos = any(int(cid) in pos_ids for cid in g[\"category_id\"].tolist())\n",
        "            img_pos[int(img_id)] = 1 if is_pos else 0\n",
        "\n",
        "    # Map image_id -> file_name\n",
        "    if \"id\" not in images.columns or \"file_name\" not in images.columns:\n",
        "        raise ValueError(\"[COCO] Missing 'id' or 'file_name' in images.\")\n",
        "\n",
        "    images[\"class1\"] = images[\"id\"].map(lambda i: img_pos.get(int(i), 0)).astype(int)\n",
        "    out = images[[\"file_name\", \"class1\"]].copy()\n",
        "    return out\n",
        "\n",
        "def labels_from_yolo(label_dir: str):\n",
        "    \"\"\"\n",
        "    Parse YOLO .txt files. Positive if any line has class_id == POSITIVE_CLASS_ID.\n",
        "    Returns DataFrame: file_name (reconstructed from stem2path), class1.\n",
        "    \"\"\"\n",
        "    def parse_yolo_txt(txt_path):\n",
        "        pos = False\n",
        "        try:\n",
        "            with open(txt_path, \"r\") as f:\n",
        "                for ln in f:\n",
        "                    ln = ln.strip()\n",
        "                    if not ln:\n",
        "                        continue\n",
        "                    parts = ln.split()\n",
        "                    try:\n",
        "                        cid = int(float(parts[0]))\n",
        "                        if cid == POSITIVE_CLASS_ID:\n",
        "                            pos = True\n",
        "                            break\n",
        "                    except Exception:\n",
        "                        continue\n",
        "        except Exception:\n",
        "            pass\n",
        "        return 1 if pos else 0\n",
        "\n",
        "    txts = sorted(glob.glob(os.path.join(label_dir, \"**\", \"*.txt\"), recursive=True))\n",
        "    records = []\n",
        "    for p in txts:\n",
        "        st = stem_of(p)\n",
        "        if st in stem2path:\n",
        "            records.append((os.path.basename(stem2path[st]), parse_yolo_txt(p)))\n",
        "    df = pd.DataFrame(records, columns=[\"file_name\", \"class1\"]).drop_duplicates()\n",
        "    return df\n",
        "\n",
        "use_coco = os.path.isfile(COCO_JSON_PATH)\n",
        "df_coco  = labels_from_coco(COCO_JSON_PATH) if use_coco else pd.DataFrame(columns=[\"file_name\",\"class1\"])\n",
        "df_yolo  = labels_from_yolo(LABEL_DIR) if os.path.isdir(LABEL_DIR) else pd.DataFrame(columns=[\"file_name\",\"class1\"])\n",
        "\n",
        "# Pick label source: prefer COCO when it resolves to >= YOLO rows and intersects actual files\n",
        "cnt_coco = len(df_coco)\n",
        "cnt_yolo = len(df_yolo)\n",
        "print(f\"[Labels] COCO resolved: {cnt_coco} | YOLO-txt resolved: {cnt_yolo}\")\n",
        "\n",
        "if cnt_coco >= cnt_yolo and cnt_coco > 0:\n",
        "    df_lab = df_coco.copy()\n",
        "    label_source = \"COCO\"\n",
        "else:\n",
        "    df_lab = df_yolo.copy()\n",
        "    label_source = \"YOLO\"\n",
        "\n",
        "# Add abs_path and filter to files we really have\n",
        "df_lab[\"abs_path\"] = df_lab[\"file_name\"].map(lambda fn: stem2path.get(stem_of(fn)))\n",
        "df_lab = df_lab[df_lab[\"abs_path\"].notna()].reset_index(drop=True)\n",
        "df_lab[\"file_name\"] = df_lab[\"abs_path\"].map(os.path.basename)\n",
        "df_lab[\"class1\"] = pd.to_numeric(df_lab[\"class1\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "print(f\"[Labels] Using source: {label_source} | rows={len(df_lab)}\")\n",
        "\n",
        "# ---------- 3) Robust cow-id parsing ----------\n",
        "def digits_only(s: str) -> str:\n",
        "    return re.sub(r\"\\D\", \"\", str(s)) if pd.notna(s) else \"\"\n",
        "\n",
        "def infer_cow_id(path: str, fname_stem: str) -> str:\n",
        "    \"\"\"\n",
        "    Heuristics (priority order):\n",
        "      1) FLIR-#### / FLIR_#### / FLIR#### in stem\n",
        "      2) #### immediately before '_jpg' in stem\n",
        "      3) parent directory name ending with ####\n",
        "      4) first 3–6 digit sequence in stem before any '.rf' suffix\n",
        "      Fallback: keep the last 4 digits if any; else 'nan'\n",
        "    \"\"\"\n",
        "    st = fname_stem\n",
        "\n",
        "    m = re.search(r'FLIR[_-]?(\\d{3,6})', st, re.IGNORECASE)\n",
        "    if m:\n",
        "        return f\"cow{m.group(1)}\"\n",
        "\n",
        "    m = re.search(r'(\\d{3,6})(?=_jpg\\b)', st, re.IGNORECASE)\n",
        "    if m:\n",
        "        return f\"cow{m.group(1)}\"\n",
        "\n",
        "    parent = os.path.basename(os.path.dirname(path))\n",
        "    m = re.search(r'(\\d{3,6})$', parent)\n",
        "    if m:\n",
        "        return f\"cow{m.group(1)}\"\n",
        "\n",
        "    st_no_rf = st.split(\".rf\")[0]\n",
        "    m = re.search(r'(\\d{3,6})', st_no_rf)\n",
        "    if m:\n",
        "        return f\"cow{m.group(1)}\"\n",
        "\n",
        "    d = digits_only(st_no_rf)\n",
        "    if len(d) >= 3:\n",
        "        return f\"cow{d[-4:]}\"\n",
        "    return \"nan\"\n",
        "\n",
        "df_lab[\"__stem__\"] = df_lab[\"file_name\"].map(stem_of)\n",
        "df_lab[\"_cid_\"] = [\n",
        "    infer_cow_id(p, s) for p, s in zip(df_lab[\"abs_path\"].tolist(), df_lab[\"__stem__\"].tolist())\n",
        "]\n",
        "\n",
        "# ---------- 4) Final shape and diagnostics ----------\n",
        "df_images_full = df_lab.rename(columns={\"file_name\": \"file_name_x\"}).copy()\n",
        "# Keep a tidy set of columns expected downstream\n",
        "keep_cols = [\"file_name_x\", \"abs_path\", \"class1\", \"_cid_\"]\n",
        "extra_cols = [c for c in df_images_full.columns if c not in keep_cols]\n",
        "df_images_full = df_images_full[keep_cols + extra_cols]\n",
        "\n",
        "print(f\"[Images] df_images_full shape: {df_images_full.shape}\")\n",
        "print(df_images_full.head(10))\n",
        "\n",
        "# Quick stats\n",
        "n_imgs = len(df_images_full)\n",
        "n_cows = df_images_full[\"_cid_\"].replace(\"nan\", np.nan).dropna().nunique()\n",
        "pos_cnt = int(df_images_full[\"class1\"].sum())\n",
        "print(f\"[Stats] images={n_imgs} | cows (parsed)={n_cows} | positives={pos_cnt} | negatives={n_imgs - pos_cnt}\")\n",
        "\n",
        "# Optional: expose to globals explicitly (some notebooks rely on it)\n",
        "globals()[\"df_images_full\"] = df_images_full\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43-wUTNiRYST",
        "outputId": "0ff38094-4fbb-4fb5-dd87-77a48bd9a6b9"
      },
      "id": "43-wUTNiRYST",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PATHS] PROJECT_DIR: /content/drive/MyDrive/Mastitis_illness_cow/datasets\n",
            "[PATHS] IMAGE_DIR exists: True | LABEL_DIR exists: True\n",
            "[PATHS] COCO_JSON_PATH: /content/drive/MyDrive/Mastitis_illness_cow/exports/_annotations.coco.json | exists: True\n",
            "[Index] Indexed images: 130\n",
            "[COCO] images=130 | annotations=185 | categories=6\n",
            "[COCO][WARN] No explicit positive names found. Falling back to category_id==1.\n",
            "[Labels] COCO resolved: 130 | YOLO-txt resolved: 130\n",
            "[Labels] Using source: COCO | rows=130\n",
            "[Images] df_images_full shape: (130, 5)\n",
            "                                         file_name_x  \\\n",
            "0  FLIR0179_jpg.rf.7b1370df26ea8498381f67453133af...   \n",
            "1  FLIR0227_jpg.rf.845a66986fb6d4d9648aa314ced09e...   \n",
            "2  FLIR1445_jpg.rf.045fbc0881e974ff438962ed621fac...   \n",
            "3  FLIR1867_jpg.rf.efa16aea0933b52816d3df8e3c6f03...   \n",
            "4  FLIR1695_jpg.rf.8265732ed9ecf71b800da75ac6e20d...   \n",
            "5  FLIR0843_jpg.rf.11aa52a9b9c110de0f267c09a1c2d6...   \n",
            "6  FLIR1509_jpg.rf.0c7f6501cb7be8160df19e17973aa0...   \n",
            "7  FLIR0983_jpg.rf.e5f677846f89da4b40af8dd12e19e7...   \n",
            "8  FLIR1833_jpg.rf.c071bcf03f96633dcb00121c8028e8...   \n",
            "9  FLIR1647_jpg.rf.0eede5710a1a7b5f5adff4ee6dc4d5...   \n",
            "\n",
            "                                            abs_path  class1    _cid_  \\\n",
            "0  /content/drive/MyDrive/Mastitis_illness_cow/da...       1  cow0179   \n",
            "1  /content/drive/MyDrive/Mastitis_illness_cow/da...       0  cow0227   \n",
            "2  /content/drive/MyDrive/Mastitis_illness_cow/da...       0  cow1445   \n",
            "3  /content/drive/MyDrive/Mastitis_illness_cow/da...       0  cow1867   \n",
            "4  /content/drive/MyDrive/Mastitis_illness_cow/da...       0  cow1695   \n",
            "5  /content/drive/MyDrive/Mastitis_illness_cow/da...       0  cow0843   \n",
            "6  /content/drive/MyDrive/Mastitis_illness_cow/da...       0  cow1509   \n",
            "7  /content/drive/MyDrive/Mastitis_illness_cow/da...       0  cow0983   \n",
            "8  /content/drive/MyDrive/Mastitis_illness_cow/da...       1  cow1833   \n",
            "9  /content/drive/MyDrive/Mastitis_illness_cow/da...       1  cow1647   \n",
            "\n",
            "                                           __stem__  \n",
            "0  FLIR0179_jpg.rf.7b1370df26ea8498381f67453133af6d  \n",
            "1  FLIR0227_jpg.rf.845a66986fb6d4d9648aa314ced09ea1  \n",
            "2  FLIR1445_jpg.rf.045fbc0881e974ff438962ed621facb7  \n",
            "3  FLIR1867_jpg.rf.efa16aea0933b52816d3df8e3c6f0329  \n",
            "4  FLIR1695_jpg.rf.8265732ed9ecf71b800da75ac6e20d4a  \n",
            "5  FLIR0843_jpg.rf.11aa52a9b9c110de0f267c09a1c2d68f  \n",
            "6  FLIR1509_jpg.rf.0c7f6501cb7be8160df19e17973aa025  \n",
            "7  FLIR0983_jpg.rf.e5f677846f89da4b40af8dd12e19e7f5  \n",
            "8  FLIR1833_jpg.rf.c071bcf03f96633dcb00121c8028e8b1  \n",
            "9  FLIR1647_jpg.rf.0eede5710a1a7b5f5adff4ee6dc4d5a4  \n",
            "[Stats] images=130 | cows (parsed)=130 | positives=59 | negatives=71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell — COCO indexing + robust cow-id alignment audit (images ↔ tabular)\n",
        "# What this does (high level, Claude-style):\n",
        "# • Rebuilds df_images_full from COCO JSON with per-image labels (class1).\n",
        "# • Extracts a consistent per-cow identifier (_cid_) from image filenames using layered heuristics:\n",
        "#     FLIR#### → #### before \"_jpg\" → parent folder ending in #### → first 3–6 digits → fallback last 4 digits.\n",
        "# • Rebuilds tabular cow IDs with THE SAME normaliser and computes per-cow labels y = max(class1).\n",
        "# • Prints overlap diagnostics and a few examples of unmatched cows on both sides.\n",
        "# • Exposes globals: df_images_full (images+labels+_cid_), cow_feats (per-cow features+label) for downstream CV/fusion.\n",
        "# =======================\n",
        "\n",
        "import os, re, json, glob, numpy as np, pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# ---------- 0) Config & guards ----------\n",
        "assert 'PROJECT_DIR' in globals(), \"PROJECT_DIR missing.\"\n",
        "if 'IMAGE_DIR' not in globals():\n",
        "    IMAGE_DIR = os.path.join(PROJECT_DIR, \"images\")\n",
        "if 'COCO_JSON_PATH' not in globals():\n",
        "    COCO_JSON_PATH = os.path.join(os.path.dirname(PROJECT_DIR), \"exports\", \"_annotations.coco.json\")\n",
        "\n",
        "print(f\"[PATHS] IMAGE_DIR={IMAGE_DIR} | COCO_JSON_PATH={COCO_JSON_PATH} | exists: {os.path.isfile(COCO_JSON_PATH)}\")\n",
        "\n",
        "# ---------- 1) Read COCO and build per-image labels ----------\n",
        "def _read_json(p):\n",
        "    with open(p, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "coco = _read_json(COCO_JSON_PATH)\n",
        "imgs = pd.DataFrame(coco.get(\"images\", []))\n",
        "anns = pd.DataFrame(coco.get(\"annotations\", []))\n",
        "cats = pd.DataFrame(coco.get(\"categories\", []))\n",
        "\n",
        "for need in (\"id\",\"file_name\"):\n",
        "    assert need in imgs.columns, f\"COCO images is missing '{need}'\"\n",
        "for need in (\"image_id\",\"category_id\"):\n",
        "    assert need in anns.columns, f\"COCO annotations is missing '{need}'\"\n",
        "for need in (\"id\",\"name\"):\n",
        "    assert need in cats.columns, f\"COCO categories is missing '{need}'\"\n",
        "\n",
        "# Select positive class IDs: prefer names that look like mastitis/lesion, else fallback to id==1\n",
        "pos_name_pat = re.compile(r\"(mastitis|lesion|injur|abnorm|patholog|inflam)\", re.I)\n",
        "pos_ids_by_name = cats.loc[cats[\"name\"].astype(str).str.contains(pos_name_pat), \"id\"].tolist()\n",
        "if pos_ids_by_name:\n",
        "    POS_IDS = set(pos_ids_by_name)\n",
        "    print(f\"[COCO] Positive categories by name: {list(POS_IDS)} / {cats.loc[cats['id'].isin(POS_IDS),'name'].tolist()}\")\n",
        "else:\n",
        "    POS_IDS = {1}\n",
        "    print(\"[COCO][WARN] No explicit positive names found → fallback POSITIVE category_id={1}\")\n",
        "\n",
        "# Build per-image class1 = 1 if any annotation with category_id in POS_IDS\n",
        "ann_pos = anns.assign(is_pos=anns[\"category_id\"].isin(POS_IDS)).groupby(\"image_id\")[\"is_pos\"].max().astype(bool)\n",
        "imgs[\"class1\"] = imgs[\"id\"].map(ann_pos).fillna(False).astype(int)\n",
        "\n",
        "# Resolve absolute path for each file_name\n",
        "# Try direct join; if not exists, fallback by stem match anywhere under IMAGE_DIR\n",
        "def _abs_path_for(fname):\n",
        "    p = os.path.join(IMAGE_DIR, fname)\n",
        "    if os.path.isfile(p):\n",
        "        return p\n",
        "    # stem-based fallback\n",
        "    stem = os.path.splitext(os.path.basename(fname))[0]\n",
        "    # first try top-level; if not, recursive glob\n",
        "    for ext in (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"):\n",
        "        cand = glob.glob(os.path.join(IMAGE_DIR, f\"**/{stem}{ext}\"), recursive=True)\n",
        "        if cand:\n",
        "            return cand[0]\n",
        "    return None\n",
        "\n",
        "imgs[\"abs_path\"] = imgs[\"file_name\"].apply(_abs_path_for)\n",
        "imgs_ok = imgs[imgs[\"abs_path\"].notna()].copy()\n",
        "print(f\"[COCO] images total={len(imgs)} | resolved paths={len(imgs_ok)} | positives={int(imgs_ok['class1'].sum())}\")\n",
        "\n",
        "# ---------- 2) Build robust _cid_ from image filename / path ----------\n",
        "def _digits_only(x: str) -> str:\n",
        "    return re.sub(r\"\\D\", \"\", str(x)) if pd.notna(x) else \"\"\n",
        "\n",
        "def _strip_leading_zeros(d: str) -> str:\n",
        "    s = d.lstrip(\"0\")\n",
        "    return s if s else \"0\"\n",
        "\n",
        "def _infer_cid_from_path(path: str, stem: str) -> str | None:\n",
        "    st = stem\n",
        "    # 1) FLIR#### / FLIR-#### / FLIR_####\n",
        "    m = re.search(r'FLIR[_-]?(\\d{3,6})', st, re.I)\n",
        "    if m: return f\"cow{_strip_leading_zeros(m.group(1))}\"\n",
        "    # 2) #### before \"_jpg\"\n",
        "    m = re.search(r'(\\d{3,6})(?=_jpg\\b)', st, re.I)\n",
        "    if m: return f\"cow{_strip_leading_zeros(m.group(1))}\"\n",
        "    # 3) parent folder ends with ####\n",
        "    parent = os.path.basename(os.path.dirname(path))\n",
        "    m = re.search(r'(\\d{3,6})$', parent)\n",
        "    if m: return f\"cow{_strip_leading_zeros(m.group(1))}\"\n",
        "    # 4) first 3–6 digits before any \".rf\"\n",
        "    st_no_rf = st.split(\".rf\")[0]\n",
        "    m = re.search(r'(\\d{3,6})', st_no_rf)\n",
        "    if m: return f\"cow{_strip_leading_zeros(m.group(1))}\"\n",
        "    # Fallback: keep last 4 digits if any\n",
        "    d = _digits_only(st_no_rf)\n",
        "    if len(d) >= 3:\n",
        "        return f\"cow{_strip_leading_zeros(d[-4:])}\"\n",
        "    return None\n",
        "\n",
        "def _stem(p):\n",
        "    b = os.path.basename(p); s,_ = os.path.splitext(b); return s\n",
        "\n",
        "imgs_ok[\"_cid_\"] = imgs_ok.apply(lambda r: _infer_cid_from_path(r[\"abs_path\"], _stem(r[\"file_name\"])), axis=1)\n",
        "imgs_ok = imgs_ok[imgs_ok[\"_cid_\"].notna()].copy()\n",
        "imgs_ok[\"_cid_\"] = imgs_ok[\"_cid_\"].astype(str)\n",
        "\n",
        "# ---------- 3) Optional YOLO .txt cross-check (if LABEL_DIR exists) ----------\n",
        "# If both sources exist, we can choose which to use later (COCO vs YOLO). For now we keep COCO.\n",
        "df_images_full = imgs_ok[[\"file_name\",\"abs_path\",\"class1\",\"_cid_\"]].copy()\n",
        "df_images_full[\"__key__\"] = df_images_full[\"file_name\"]  # legacy compatibility\n",
        "\n",
        "print(f\"[Images] df_images_full shape: {df_images_full.shape} | unique cows={df_images_full['_cid_'].nunique()}\")\n",
        "print(f\"[Images] class balance (per-image): {Counter(df_images_full['class1'].tolist())}\")\n",
        "\n",
        "# ---------- 4) Rebuild tabular cow IDs with same normaliser & per-cow labels ----------\n",
        "assert 'tab' in globals(), \"Missing 'tab' DataFrame (run earlier cells that build tab).\"\n",
        "tt = tab.copy()\n",
        "\n",
        "# Find a likely cow-id column in tab\n",
        "TAB_KEY = next((c for c in [\"Cow_ID_match\",\"Cow_ID_norm\",\"Cow_ID\",\"cow_id\",\"ID\",\"id\",\"animal_id\"] if c in tt.columns), None)\n",
        "if TAB_KEY is None:\n",
        "    raise AssertionError(\"No cow id column found in 'tab' (expected one of Cow_ID_match/Cow_ID_norm/Cow_ID/...).\")\n",
        "\n",
        "# Normalise to _cid_\n",
        "tt[\"_cid_\"] = tt[TAB_KEY].apply(lambda x: f\"cow{_strip_leading_zeros(_digits_only(x))}\" if pd.notna(x) and _digits_only(x) else None)\n",
        "tt = tt[tt[\"_cid_\"].notna()].copy()\n",
        "tt[\"_cid_\"] = tt[\"_cid_\"].astype(str)\n",
        "\n",
        "# Target column\n",
        "YCOL_CANDIDATES = [\"class1\",\"risk_next\",\"early\",\"Label\",\"label\"]\n",
        "YCOL = next((c for c in YCOL_CANDIDATES if c in tt.columns), None)\n",
        "if YCOL is None:\n",
        "    raise AssertionError(\"No target found in 'tab' (expected one of class1/risk_next/early/Label/label).\")\n",
        "tt[YCOL] = pd.to_numeric(tt[YCOL], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# Per-cow label: max over visits\n",
        "y_cow = tt.groupby(\"_cid_\")[YCOL].max().astype(int)\n",
        "\n",
        "# Small feature pack for per-cow TAB (safe, leak-free)\n",
        "n_visits = tt.groupby(\"_cid_\").size().rename(\"n_visits\")\n",
        "cow_feats = pd.DataFrame({\"_cid_\": y_cow.index, \"y\": y_cow.values}).merge(n_visits, on=\"_cid_\", how=\"left\")\n",
        "if \"Temperature\" in tt.columns:\n",
        "    tmp = tt.assign(Temperature=pd.to_numeric(tt[\"Temperature\"], errors=\"coerce\"))\n",
        "    cow_feats = cow_feats.merge(tmp.groupby(\"_cid_\")[\"Temperature\"].mean().rename(\"Temp_mean\"), on=\"_cid_\", how=\"left\")\n",
        "\n",
        "# ---------- 5) Overlap diagnostics ----------\n",
        "img_cows = set(df_images_full[\"_cid_\"].unique())\n",
        "tab_cows = set(cow_feats[\"_cid_\"].unique())\n",
        "overlap = sorted(img_cows & tab_cows)\n",
        "print(f\"\\n[Overlap] cows in images={len(img_cows)} | cows in tab={len(tab_cows)} | INTERSECTION={len(overlap)}\")\n",
        "\n",
        "# Show a few examples of unmatched IDs to debug quickly\n",
        "if len(overlap) < 10:\n",
        "    only_img = sorted(img_cows - tab_cows)[:10]\n",
        "    only_tab = sorted(tab_cows - img_cows)[:10]\n",
        "    print(f\"[Examples] only in IMAGES (first 10): {only_img}\")\n",
        "    print(f\"[Examples] only in TAB     (first 10): {only_tab}\")\n",
        "\n",
        "# Distribution on the overlap (per-cow)\n",
        "if overlap:\n",
        "    y_overlap = y_cow.reindex(overlap).fillna(0).astype(int)\n",
        "    print(f\"[Overlap] per-cow label mix: pos={int((y_overlap==1).sum())} | neg={int((y_overlap==0).sum())}\")\n",
        "else:\n",
        "    print(\"[Overlap][WARN] No per-cow overlap. Fusion/CV with TAB will be disabled; IMG-only remains available.\")\n",
        "\n",
        "# ---------- 6) Persist globals for downstream cells ----------\n",
        "df_images_full = df_images_full.copy()\n",
        "cow_feats = cow_feats[cow_feats[\"_cid_\"].isin(overlap)].copy() if overlap else cow_feats.copy()\n",
        "\n",
        "print(\"\\n[Ready] Exposed globals:\")\n",
        "print(f\"  • df_images_full: rows={len(df_images_full)} | unique_cows={df_images_full['_cid_'].nunique()}\")\n",
        "print(f\"  • cow_feats     : rows={len(cow_feats)} | y non-NaN={(~cow_feats['y'].isna()).sum()}\")\n",
        "\n",
        "# Optional: save a quick CSV of non-overlap to inspect manually\n",
        "SAVE_DIR = globals().get(\"SAVE_DIR\", \"/content/mastitis_outputs\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "if overlap and len(overlap) < 10:\n",
        "    pd.DataFrame({\"only_in_images\": sorted(img_cows - tab_cows)}).to_csv(os.path.join(SAVE_DIR,\"only_in_images.csv\"), index=False)\n",
        "    pd.DataFrame({\"only_in_tab\": sorted(tab_cows - img_cows)}).to_csv(os.path.join(SAVE_DIR,\"only_in_tab.csv\"), index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxHxPon2T1TL",
        "outputId": "def62ec1-074a-4d87-e51e-000b3b7aa821"
      },
      "id": "FxHxPon2T1TL",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PATHS] IMAGE_DIR=/content/drive/MyDrive/Mastitis_illness_cow/datasets/images | COCO_JSON_PATH=/content/drive/MyDrive/Mastitis_illness_cow/exports/_annotations.coco.json | exists: True\n",
            "[COCO][WARN] No explicit positive names found → fallback POSITIVE category_id={1}\n",
            "[COCO] images total=130 | resolved paths=130 | positives=59\n",
            "[Images] df_images_full shape: (130, 5) | unique cows=130\n",
            "[Images] class balance (per-image): Counter({0: 71, 1: 59})\n",
            "\n",
            "[Overlap] cows in images=130 | cows in tab=1100 | INTERSECTION=64\n",
            "[Overlap] per-cow label mix: pos=10 | neg=54\n",
            "\n",
            "[Ready] Exposed globals:\n",
            "  • df_images_full: rows=130 | unique_cows=130\n",
            "  • cow_feats     : rows=64 | y non-NaN=64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4282287959.py:53: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  imgs[\"class1\"] = imgs[\"id\"].map(ann_pos).fillna(False).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# COCO + images ↔ tab alignment (auto-pick best ID normalizer)\n",
        "# Outputs: df_images_full (per-image), cow_feats (per-cow with y=max(class1))\n",
        "# =======================\n",
        "import os, re, glob, json, numpy as np, pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# ---- Paths\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/Mastitis_illness_cow/datasets\"\n",
        "IMAGE_DIR   = os.path.join(PROJECT_DIR, \"images\")\n",
        "COCO_JSON   = os.path.join(PROJECT_DIR, \"exports\", \"_annotations.coco.json\")\n",
        "CLIN_FALLBACK = \"/mnt/data/clinical_mastitis_cows_version1.csv\"\n",
        "\n",
        "assert os.path.isfile(COCO_JSON), f\"Missing COCO at {COCO_JSON}\"\n",
        "assert os.path.isdir(IMAGE_DIR),  f\"Missing images dir at {IMAGE_DIR}\"\n",
        "\n",
        "print(f\"[PATHS] IMAGE_DIR={IMAGE_DIR} | COCO_JSON_PATH={COCO_JSON} | exists: True\")\n",
        "\n",
        "# ---- Read COCO\n",
        "with open(COCO_JSON, \"r\") as f:\n",
        "    coco = json.load(f)\n",
        "images = pd.DataFrame(coco.get(\"images\", []))\n",
        "anns   = pd.DataFrame(coco.get(\"annotations\", []))\n",
        "cats   = pd.DataFrame(coco.get(\"categories\", []))\n",
        "\n",
        "for need in (\"id\",\"file_name\"):\n",
        "    assert need in images.columns, f\"COCO images missing '{need}'\"\n",
        "for need in (\"image_id\",\"category_id\"):\n",
        "    assert need in anns.columns, f\"COCO annotations missing '{need}'\"\n",
        "\n",
        "# Positive categories: by name if recognizable, else id==1\n",
        "pos_pat = re.compile(r\"(mastitis|lesion|injur|abnorm|patholog|inflam)\", re.I)\n",
        "pos_ids_by_name = cats.loc[cats.get(\"name\",\"\").astype(str).str.contains(pos_pat, na=False), \"id\"].tolist() if not cats.empty else []\n",
        "POS_IDS = set(pos_ids_by_name) if pos_ids_by_name else {1}\n",
        "if not pos_ids_by_name:\n",
        "    print(\"[COCO][WARN] No explicit positive names found → fallback POSITIVE category_id={1}\")\n",
        "\n",
        "ann_pos = anns.assign(is_pos=anns[\"category_id\"].isin(POS_IDS)).groupby(\"image_id\")[\"is_pos\"].max().astype(bool)\n",
        "images[\"class1\"] = images[\"id\"].map(ann_pos).fillna(False).astype(int)\n",
        "\n",
        "# Resolve abs path\n",
        "def _abs_path_for(fname):\n",
        "    p = os.path.join(IMAGE_DIR, fname)\n",
        "    if os.path.isfile(p):\n",
        "        return p\n",
        "    stem = os.path.splitext(os.path.basename(fname))[0]\n",
        "    for ext in (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"):\n",
        "        cand = glob.glob(os.path.join(IMAGE_DIR, f\"**/{stem}{ext}\"), recursive=True)\n",
        "        if cand: return cand[0]\n",
        "    return None\n",
        "\n",
        "images[\"abs_path\"] = images[\"file_name\"].apply(_abs_path_for)\n",
        "img = images[images[\"abs_path\"].notna()].copy()\n",
        "print(f\"[COCO] images total={len(images)} | resolved paths={len(img)} | positives={int(img['class1'].sum())}\")\n",
        "\n",
        "# ---- Extract per-image raw token candidates\n",
        "def _stem(p): return os.path.splitext(os.path.basename(p))[0]\n",
        "img[\"stem\"] = img[\"file_name\"].apply(_stem)\n",
        "\n",
        "# ---- Normalizers (apply SAME on both sides)\n",
        "def digits_only(s: str) -> str:\n",
        "    return re.sub(r\"\\D\", \"\", str(s)) if pd.notna(s) else \"\"\n",
        "\n",
        "def norm_raw_digits(s: str) -> str | None:\n",
        "    d = digits_only(s)\n",
        "    return d if d else None\n",
        "\n",
        "def strip_leading_zeros(d: str) -> str:\n",
        "    s = d.lstrip(\"0\")\n",
        "    return s if s else \"0\"\n",
        "\n",
        "def norm_cow_suffix4(s: str) -> str | None:\n",
        "    d = digits_only(s)\n",
        "    if not d: return None\n",
        "    take = d[-4:] if len(d) >= 4 else d\n",
        "    return f\"cow{strip_leading_zeros(take)}\"\n",
        "\n",
        "def norm_cow_first3to6(s: str) -> str | None:\n",
        "    m = re.search(r\"(\\d{3,6})\", str(s))\n",
        "    if not m: return None\n",
        "    return f\"cow{strip_leading_zeros(m.group(1))}\"\n",
        "\n",
        "NORMALIZERS = {\n",
        "    \"raw_digits\":     norm_raw_digits,    # e.g., '1445'\n",
        "    \"cow_suffix4\":    norm_cow_suffix4,   # e.g., 'cow1445'\n",
        "    \"cow_first3to6\":  norm_cow_first3to6, # e.g., 'cow1445'\n",
        "}\n",
        "\n",
        "# Build candidate IDs for IMAGES\n",
        "img_ids = {}\n",
        "for name, fn in NORMALIZERS.items():\n",
        "    img_ids[name] = img[\"stem\"].apply(fn)\n",
        "\n",
        "# ---- Build tabular master from available globals or fallback CSV\n",
        "def pick_tabular():\n",
        "    # priority 1: prebuilt 'tab'\n",
        "    if 'tab' in globals() and isinstance(globals()['tab'], pd.DataFrame) and not globals()['tab'].empty:\n",
        "        return globals()['tab'].copy()\n",
        "    # priority 2: concat train/val/test if present\n",
        "    parts = []\n",
        "    for nm in (\"train_df\",\"val_df\",\"test_df\"):\n",
        "        if nm in globals() and isinstance(globals()[nm], pd.DataFrame) and not globals()[nm].empty:\n",
        "            parts.append(globals()[nm].copy())\n",
        "    if parts:\n",
        "        return pd.concat(parts, axis=0, ignore_index=True)\n",
        "    # priority 3: fallback CSV on /mnt/data\n",
        "    if os.path.isfile(CLIN_FALLBACK):\n",
        "        return pd.read_csv(CLIN_FALLBACK)\n",
        "    raise AssertionError(\"No tabular data found: define 'tab' or (train_df/val_df/test_df) or ensure CSV fallback exists.\")\n",
        "\n",
        "tab_all = pick_tabular()\n",
        "\n",
        "# Guess a cow-id column and a target column\n",
        "COW_KEYS = [\"Cow_ID_match\",\"cow_id\",\"Cow_ID\",\"ID\",\"id\",\"animal_id\",\"subject_id\"]\n",
        "Y_KEYS   = [\"class1\",\"label\",\"Label\",\"risk_next\",\"early\"]\n",
        "TAB_KEY  = next((c for c in COW_KEYS if c in tab_all.columns), None)\n",
        "YCOL     = next((c for c in Y_KEYS if c in tab_all.columns), None)\n",
        "assert TAB_KEY is not None, f\"Cannot find cow id column among {COW_KEYS}\"\n",
        "assert YCOL   is not None, f\"Cannot find target column among {Y_KEYS}\"\n",
        "\n",
        "# Build candidate IDs for TABULAR using same normalizers\n",
        "tab_ids = {}\n",
        "for name, fn in NORMALIZERS.items():\n",
        "    tab_ids[name] = tab_all[TAB_KEY].apply(fn)\n",
        "\n",
        "# ---- Try each normalizer pair and pick the best overlap\n",
        "scores = []\n",
        "for nname in NORMALIZERS.keys():\n",
        "    img_c = img_ids[nname].dropna().astype(str)\n",
        "    tab_c = tab_ids[nname].dropna().astype(str)\n",
        "    oi = set(img_c.unique())\n",
        "    ot = set(tab_c.unique())\n",
        "    overlap = oi & ot\n",
        "    pos_mix = None\n",
        "    if overlap and nname != \"raw_digits\":\n",
        "        # compute per-cow y=max(class1) on that key\n",
        "        # (map image class1 per cow)\n",
        "        tmp_img = img.copy()\n",
        "        tmp_img[\"_cid_\"] = img_ids[nname]\n",
        "        y_cow = tmp_img[tmp_img[\"_cid_\"].notna()].groupby(\"_cid_\")[\"class1\"].max()\n",
        "        pos_mix = int(y_cow.reindex(list(overlap)).fillna(0).sum())\n",
        "    scores.append((nname, len(oi), len(ot), len(overlap), pos_mix))\n",
        "\n",
        "sc = pd.DataFrame(scores, columns=[\"mode\",\"img_cows\",\"tab_cows\",\"overlap\",\"pos_in_overlap\"])\n",
        "best = sc.sort_values([\"overlap\",\"pos_in_overlap\"], ascending=[False,False]).iloc[0]\n",
        "MODE = best[\"mode\"]\n",
        "\n",
        "print(\"\\n[Chooser] Overlap by mode:\")\n",
        "print(sc.to_string(index=False))\n",
        "print(f\"[Chooser] Picked mode: {MODE} (overlap={int(best['overlap'])}, img_cows={int(best['img_cows'])}, tab_cows={int(best['tab_cows'])})\")\n",
        "\n",
        "# ---- Build final IDs with chosen mode\n",
        "img[\"_cid_\"] = img_ids[MODE]\n",
        "tab_all[\"_cid_\"] = tab_ids[MODE]\n",
        "\n",
        "# Clean & type\n",
        "img = img[img[\"_cid_\"].notna()].copy()\n",
        "tab_all = tab_all[tab_all[\"_cid_\"].notna()].copy()\n",
        "img[\"_cid_\"] = img[\"_cid_\"].astype(str)\n",
        "tab_all[\"_cid_\"] = tab_all[\"_cid_\"].astype(str)\n",
        "\n",
        "# Per-cow y from images (focus = imaged cows)\n",
        "y_cow = img.groupby(\"_cid_\")[\"class1\"].max().astype(int).rename(\"y\").reset_index()\n",
        "\n",
        "# cow_feats: first row per cow (+ y), keeping lightweight extra stats if useful\n",
        "cow_feats = tab_all.merge(y_cow, on=\"_cid_\", how=\"inner\").copy()\n",
        "cow_feats = cow_feats.groupby(\"_cid_\", as_index=False).first()\n",
        "\n",
        "# Final per-image table\n",
        "df_images_full = img[[\"id\",\"file_name\",\"abs_path\",\"class1\",\"_cid_\"]].rename(columns={\"file_name\":\"stem\"}).copy()\n",
        "\n",
        "# ---- Diagnostics\n",
        "img_cows = set(df_images_full[\"_cid_\"].unique())\n",
        "tab_cows = set(cow_feats[\"_cid_\"].unique())\n",
        "overlap  = img_cows & tab_cows\n",
        "pos_cows = y_cow.set_index(\"_cid_\").reindex(list(overlap))[\"y\"].fillna(0).astype(int)\n",
        "print(f\"\\n[Overlap] cows in images={len(img_cows)} | cows in tab={len(tab_cows)} | INTERSECTION={len(overlap)}\")\n",
        "print(f\"[Overlap] per-cow label mix: pos={int((pos_cows==1).sum())} | neg={int((pos_cows==0).sum())}\")\n",
        "\n",
        "if len(overlap) < 10:\n",
        "    only_img = sorted(img_cows - tab_cows)[:10]\n",
        "    only_tab = sorted(tab_cows - img_cows)[:10]\n",
        "    print(f\"[Examples] only in IMAGES (first 10): {only_img}\")\n",
        "    print(f\"[Examples] only in TAB     (first 10): {only_tab}\")\n",
        "\n",
        "print(\"\\n[Ready] Exposed globals:\")\n",
        "print(f\"  • df_images_full: rows={len(df_images_full)} | unique_cows={df_images_full['_cid_'].nunique()}\")\n",
        "print(f\"  • cow_feats     : rows={len(cow_feats)} | y non-NaN={(~cow_feats['y'].isna()).sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HfImMGZkjj0",
        "outputId": "87d3e091-e233-484b-993c-1054bb0084a2"
      },
      "id": "7HfImMGZkjj0",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PATHS] IMAGE_DIR=/content/drive/MyDrive/Mastitis_illness_cow/datasets/images | COCO_JSON_PATH=/content/drive/MyDrive/Mastitis_illness_cow/datasets/exports/_annotations.coco.json | exists: True\n",
            "[COCO][WARN] No explicit positive names found → fallback POSITIVE category_id={1}\n",
            "[COCO] images total=130 | resolved paths=130 | positives=59\n",
            "\n",
            "[Chooser] Overlap by mode:\n",
            "         mode  img_cows  tab_cows  overlap  pos_in_overlap\n",
            "   raw_digits       130      1100        0             NaN\n",
            "  cow_suffix4       129      1100       13             2.0\n",
            "cow_first3to6       130      1001       64            23.0\n",
            "[Chooser] Picked mode: cow_first3to6 (overlap=64, img_cows=130, tab_cows=1001)\n",
            "\n",
            "[Overlap] cows in images=130 | cows in tab=64 | INTERSECTION=64\n",
            "[Overlap] per-cow label mix: pos=23 | neg=41\n",
            "\n",
            "[Ready] Exposed globals:\n",
            "  • df_images_full: rows=130 | unique_cows=130\n",
            "  • cow_feats     : rows=64 | y non-NaN=64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4032453286.py:39: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  images[\"class1\"] = images[\"id\"].map(ann_pos).fillna(False).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell — Multimodal CV (REUSE aligned IDs | intersection-only | leak-safe TAB)\n",
        "# - Reuses df_images_full and cow_feats from the alignment cell (no re-normalisation here).\n",
        "# - Intersection-only CV per cow with anti-leak guards for TAB.\n",
        "# - Outputs per-fold and summary CSVs.\n",
        "# =======================\n",
        "\n",
        "import os, time, warnings, numpy as np, pandas as pd\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Torch / Vision\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# ---- Config ----\n",
        "SEED     = 42\n",
        "KFOLDS   = 5\n",
        "REPEATS  = 3\n",
        "BATCH    = 256\n",
        "NUM_WORK = 4\n",
        "SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "# ---- Hard guards: require aligned globals from previous cell\n",
        "need_img_cols = {'abs_path','class1','_cid_'}\n",
        "if 'df_images_full' not in globals():\n",
        "    raise SystemExit(\"[STOP] Missing 'df_images_full'. Run the alignment cell first (the one that prints cow_first3to6 & INTERSECTION=64).\")\n",
        "if not need_img_cols.issubset(df_images_full.columns):\n",
        "    raise SystemExit(f\"[STOP] 'df_images_full' lacks columns {need_img_cols - set(df_images_full.columns)}. Re-run alignment cell.\")\n",
        "\n",
        "if 'cow_feats' not in globals():\n",
        "    raise SystemExit(\"[STOP] Missing 'cow_feats'. Run the alignment cell to build cow_feats (per-cow y + features).\")\n",
        "if not {'_cid_','y'}.issubset(cow_feats.columns):\n",
        "    raise SystemExit(\"[STOP] 'cow_feats' must include columns '_cid_' and 'y'.\")\n",
        "\n",
        "# ---- Freeze (do not re-normalise): use exactly what alignment cell produced\n",
        "df_img_all = df_images_full.dropna(subset=['abs_path','_cid_']).copy()\n",
        "df_img_all[\"_cid_\"] = df_img_all[\"_cid_\"].astype(str)\n",
        "\n",
        "# one image per cow (deterministic)\n",
        "df_img_1 = df_img_all.sort_values([\"_cid_\",\"abs_path\"]).groupby(\"_cid_\", as_index=False).first()\n",
        "\n",
        "# TAB: keep only numeric, drop constant columns, keep y\n",
        "cf = cow_feats.copy()\n",
        "cf[\"_cid_\"] = cf[\"_cid_\"].astype(str)\n",
        "\n",
        "# keep numeric features only (besides y), drop constants\n",
        "num_cols = [c for c in cf.columns if c not in ['_cid_','y'] and pd.api.types.is_numeric_dtype(cf[c])]\n",
        "if num_cols:\n",
        "    nun = cf[num_cols].nunique(dropna=True)\n",
        "    keep_cols = [c for c in num_cols if nun[c] > 1]\n",
        "else:\n",
        "    keep_cols = []\n",
        "tab_feats_all = cf[['_cid_','y'] + keep_cols].copy()\n",
        "\n",
        "# ---- Intersection\n",
        "common_cows = sorted(set(df_img_1[\"_cid_\"]) & set(tab_feats_all[\"_cid_\"]))\n",
        "print(f\"[Preflight] IMG cows(all)={df_img_1['_cid_'].nunique()} | TAB cows(all)={tab_feats_all['_cid_'].nunique()} | INTERSECTION={len(common_cows)}\")\n",
        "\n",
        "if len(common_cows) == 0:\n",
        "    only_img = sorted(set(df_img_1[\"_cid_\"]) - set(tab_feats_all[\"_cid_\"]))[:12]\n",
        "    only_tab = sorted(set(tab_feats_all[\"_cid_\"]) - set(df_img_1[\"_cid_\"]))[:12]\n",
        "    print(\"[DIAG] No overlap. Examples:\")\n",
        "    print(\"  • Only in IMAGES:\", only_img)\n",
        "    print(\"  • Only in TAB   :\", only_tab)\n",
        "    raise SystemExit(\"[STOP] Intersection is zero. Re-run the alignment cell and ensure you did NOT rebuild df_images_full/cow_feats afterwards.\")\n",
        "\n",
        "if len(common_cows) < KFOLDS:\n",
        "    print(f\"[WARN] Intersection ({len(common_cows)}) < KFOLDS ({KFOLDS}). Reducing KFOLDS to {max(2, min(3, len(common_cows)))} for stability.\")\n",
        "    KFOLDS = max(2, min(3, len(common_cows)))\n",
        "\n",
        "df_img = df_img_1[df_img_1[\"_cid_\"].isin(common_cows)].reset_index(drop=True)\n",
        "tab_feats = tab_feats_all[tab_feats_all[\"_cid_\"].isin(common_cows)].reset_index(drop=True)\n",
        "\n",
        "y_per_cow = tab_feats.set_index(\"_cid_\")[\"y\"].astype(int)\n",
        "pos_in_overlap = int((y_per_cow==1).sum())\n",
        "print(f\"[Targets] cows={len(common_cows)} | pos={pos_in_overlap} | neg={len(common_cows)-pos_in_overlap}\")\n",
        "\n",
        "# ---- Embeddings on intersection-only images\n",
        "tfm = transforms.Compose([\n",
        "    transforms.ConvertImageDtype(torch.float32),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25])\n",
        "])\n",
        "\n",
        "class CowImgDS(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        x = torchvision.io.read_image(r['abs_path'])\n",
        "        x = tfm(x)\n",
        "        # image label is not used as ground-truth; y comes from TAB per-cow\n",
        "        return x, int(r['class1']), str(r['_cid_'])\n",
        "\n",
        "dl_all = DataLoader(CowImgDS(df_img), batch_size=BATCH, shuffle=False,\n",
        "                    num_workers=NUM_WORK, pin_memory=True, persistent_workers=(NUM_WORK>0))\n",
        "\n",
        "backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "feat_dim = backbone.fc.in_features\n",
        "backbone.fc = nn.Identity()\n",
        "for p in backbone.parameters(): p.requires_grad = False\n",
        "backbone.eval().to(DEVICE)\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    try: torch.set_float32_matmul_precision(\"high\")\n",
        "    except: pass\n",
        "use_amp = torch.cuda.is_available()\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_all_embeddings(dloader):\n",
        "    Xs, ys, ks = [], [], []\n",
        "    t0 = time.time()\n",
        "    for imgs, y, k in tqdm(dloader, desc=\"Embeddings\", leave=True, mininterval=0.1):\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        if use_amp:\n",
        "            with torch.amp.autocast(\"cuda\", dtype=torch.float16):\n",
        "                emb = backbone(imgs)\n",
        "            emb = emb.float().cpu().numpy()\n",
        "            torch.cuda.synchronize()\n",
        "        else:\n",
        "            emb = backbone(imgs).cpu().numpy()\n",
        "        Xs.append(emb); ys.append(y.numpy()); ks += list(k)\n",
        "    X = np.concatenate(Xs,axis=0) if Xs else np.zeros((0,feat_dim), np.float32)\n",
        "    y = np.concatenate(ys,axis=0) if ys else np.zeros((0,), np.int32)\n",
        "    k = np.array(ks, dtype=object)\n",
        "    dt = time.time() - t0\n",
        "    print(f\"[Emb] cows={X.shape[0]} | feat_dim={X.shape[1]} | time={dt:.2f}s\")\n",
        "    return X, y, k\n",
        "\n",
        "X_img, y_img_labels, K_cow = extract_all_embeddings(dl_all)\n",
        "\n",
        "# ---- CV helpers\n",
        "def ranknorm(x):\n",
        "    r = np.argsort(np.argsort(x))\n",
        "    return r / max(len(x)-1, 1)\n",
        "\n",
        "def metrics_dict(name, y, p):\n",
        "    p = np.clip(p, 1e-9, 1-1e-9)\n",
        "    try: auc = roc_auc_score(y, p)\n",
        "    except Exception: auc = np.nan\n",
        "    ap = average_precision_score(y, p)\n",
        "    br = brier_score_loss(y, p)\n",
        "    return dict(name=name, AUROC=float(auc) if auc==auc else np.nan, AUPRC=float(ap), Brier=float(br), N=int(len(y)))\n",
        "\n",
        "def drop_leaky_features_train_only(Xtr_df, y_tr, Xva_df, auc_hi=0.85, rho_hi=0.65, min_non_nan=0.7):\n",
        "    \"\"\"Train-only guards:\n",
        "       - drop features with AUC(y, x) > auc_hi or < 1-auc_hi on TRAIN\n",
        "       - drop features with |Spearman| > rho_hi on TRAIN\n",
        "       - drop features with too many NaN on TRAIN\n",
        "       If everything drops, fallback to top-10 by std on TRAIN.\"\"\"\n",
        "    keep = []\n",
        "    low = 1.0 - auc_hi\n",
        "    Xt = Xtr_df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    Xv = Xva_df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    valid_mask = Xt.notna().mean(axis=0) >= min_non_nan\n",
        "    Xt = Xt.loc[:, valid_mask]\n",
        "    Xv = Xv.loc[:, valid_mask]\n",
        "    for c in Xt.columns:\n",
        "        xv = Xt[c].values\n",
        "        # numeric sanity\n",
        "        if np.isfinite(xv).sum() < int(min_non_nan * len(xv)):\n",
        "            continue\n",
        "        try:\n",
        "            auc1 = roc_auc_score(y_tr, xv)\n",
        "        except Exception:\n",
        "            auc1 = 0.5\n",
        "        if (auc1 > auc_hi) or (auc1 < low):\n",
        "            continue\n",
        "        try:\n",
        "            rho, _ = spearmanr(xv, y_tr)\n",
        "            if (not np.isnan(rho)) and (abs(rho) > rho_hi):\n",
        "                continue\n",
        "        except Exception:\n",
        "            pass\n",
        "        keep.append(c)\n",
        "    if not keep:\n",
        "        stds = Xt.std(ddof=0).sort_values(ascending=False)\n",
        "        keep = stds.index.tolist()[:10]\n",
        "    return Xt[keep], Xv[keep], keep\n",
        "\n",
        "# Prepare TAB lookup by cow\n",
        "tab_idx = tab_feats.set_index(\"_cid_\").copy()\n",
        "\n",
        "# CV\n",
        "sgkf = StratifiedGroupKFold(n_splits=KFOLDS, shuffle=True, random_state=SEED)\n",
        "rows = []\n",
        "\n",
        "for rep in range(1, REPEATS+1):\n",
        "    for fold, (tr_idx, va_idx) in enumerate(sgkf.split(np.zeros(len(K_cow)),\n",
        "                                                       y_per_cow.loc[K_cow].values,\n",
        "                                                       groups=K_cow), start=1):\n",
        "        cows_tr = [K_cow[i] for i in tr_idx]\n",
        "        cows_va = [K_cow[i] for i in va_idx]\n",
        "\n",
        "        # ----- Ground-truth per cow from TAB\n",
        "        ytr = y_per_cow.loc[cows_tr].astype(int).values\n",
        "        yva = y_per_cow.loc[cows_va].astype(int).values\n",
        "\n",
        "        # ----- IMG branch (LR on embeddings, class-weighted)\n",
        "        Xtr_i = X_img[tr_idx]; Xva_i = X_img[va_idx]\n",
        "        w_pos = 0.5 / max((ytr==1).mean(), 1e-6)\n",
        "        w_neg = 0.5 / max((ytr==0).mean(), 1e-6)\n",
        "        w_tr  = np.where(ytr==1, w_pos, w_neg)\n",
        "\n",
        "        clf_i = LogisticRegression(max_iter=2000, solver='lbfgs', C=0.5, n_jobs=-1)\n",
        "        clf_i.fit(Xtr_i, ytr, sample_weight=w_tr)\n",
        "        pva_img_raw = clf_i.predict_proba(Xva_i)[:,1]\n",
        "\n",
        "        # Calibrate IMG on VAL if both classes present\n",
        "        if np.unique(yva).size >= 2:\n",
        "            cal_i = LogisticRegression(max_iter=800, solver='lbfgs')\n",
        "            cal_i.fit(pva_img_raw.reshape(-1,1), yva)\n",
        "            pva_img = cal_i.predict_proba(pva_img_raw.reshape(-1,1))[:,1]\n",
        "        else:\n",
        "            pva_img = pva_img_raw\n",
        "\n",
        "        # ----- TAB branch (train-only guards)\n",
        "        tr_tab = tab_idx.loc[cows_tr]\n",
        "        va_tab = tab_idx.loc[cows_va]\n",
        "        Xtr_t = tr_tab.drop(columns=[\"y\"]).copy()\n",
        "        Xva_t = va_tab.drop(columns=[\"y\"]).copy()\n",
        "\n",
        "        # anti-leak + robustness\n",
        "        Xtr_t, Xva_t, kept = drop_leaky_features_train_only(Xtr_t, ytr, Xva_t,\n",
        "                                                            auc_hi=0.85, rho_hi=0.65, min_non_nan=0.7)\n",
        "\n",
        "        # Standardize on TRAIN only\n",
        "        if Xtr_t.shape[1] > 0:\n",
        "            scaler = StandardScaler().fit(Xtr_t.values)\n",
        "            Xtr_s  = scaler.transform(Xtr_t.values)\n",
        "            Xva_s  = scaler.transform(Xva_t.values)\n",
        "        else:\n",
        "            Xtr_s = np.zeros((len(tr_tab), 0)); Xva_s = np.zeros((len(va_tab), 0))\n",
        "\n",
        "        tab_trainable = (Xtr_s.shape[1] > 0) and (np.unique(ytr).size >= 2)\n",
        "        if tab_trainable:\n",
        "            w_pos_t = 0.5 / max((ytr==1).mean(), 1e-6)\n",
        "            w_neg_t = 0.5 / max((ytr==0).mean(), 1e-6)\n",
        "            wtr_t   = np.where(ytr==1, w_pos_t, w_neg_t)\n",
        "            clf_t = LogisticRegression(max_iter=2000, solver='lbfgs', C=0.25, n_jobs=-1)\n",
        "            clf_t.fit(Xtr_s, ytr, sample_weight=wtr_t)\n",
        "            pva_tab_raw = clf_t.predict_proba(Xva_s)[:,1]\n",
        "            if np.unique(yva).size >= 2:\n",
        "                cal_t = LogisticRegression(max_iter=800, solver='lbfgs')\n",
        "                cal_t.fit(pva_tab_raw.reshape(-1,1), yva)\n",
        "                pva_tab = cal_t.predict_proba(pva_tab_raw.reshape(-1,1))[:,1]\n",
        "            else:\n",
        "                pva_tab = pva_tab_raw\n",
        "        else:\n",
        "            # robust fallback (no training signal): predict class prior\n",
        "            pva_tab = np.full(len(va_tab), float((ytr==1).mean()), float)\n",
        "\n",
        "        # ----- FUSION (tune weight on VAL AUPRC)\n",
        "        weights = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "        best = None\n",
        "        for w in weights:\n",
        "            v = w*ranknorm(pva_tab) + (1-w)*ranknorm(pva_img)\n",
        "            ap = average_precision_score(yva, v)\n",
        "            if (best is None) or (ap > best[0]):\n",
        "                best = (ap, w, v)\n",
        "        ap_fuse, W, va_fused = best\n",
        "\n",
        "        # ---- Metrics per fold\n",
        "        rows.append(metrics_dict(f\"[R{rep}|F{fold}] IMG\", yva, pva_img))\n",
        "        rows.append(metrics_dict(f\"[R{rep}|F{fold}] TAB\", yva, pva_tab))\n",
        "        rows.append(metrics_dict(f\"[R{rep}|F{fold}] FUS (w={W:.2f})\", yva, va_fused))\n",
        "\n",
        "        mI, mT, mF = rows[-3], rows[-2], rows[-1]\n",
        "        print(f\"[R{rep}|F{fold}] IMG AUC={mI['AUROC']:.3f} AP={mI['AUPRC']:.3f} | \"\n",
        "              f\"TAB AUC={mT['AUROC']:.3f} AP={mT['AUPRC']:.3f} | \"\n",
        "              f\"FUS AUC={mF['AUROC']:.3f} AP={mF['AUPRC']:.3f} | w={W:.2f}\")\n",
        "\n",
        "# ---- Summary & save\n",
        "perf = pd.DataFrame(rows)\n",
        "\n",
        "def ci95(arr):\n",
        "    x = np.asarray(arr, dtype=float); x = x[np.isfinite(x)]\n",
        "    if x.size == 0: return np.nan, np.nan, np.nan\n",
        "    return float(np.mean(x)), float(np.quantile(x,0.025)), float(np.quantile(x,0.975))\n",
        "\n",
        "def summarize(branch):\n",
        "    sub = perf[perf['name'].str.contains(branch)]\n",
        "    auc_m, auc_lo, auc_hi = ci95(sub['AUROC'])\n",
        "    ap_m,  ap_lo,  ap_hi  = ci95(sub['AUPRC'])\n",
        "    return dict(branch=branch.strip(),\n",
        "                AUROC_mean=auc_m, AUROC_ci_lo=auc_lo, AUROC_ci_hi=auc_hi,\n",
        "                AUPRC_mean=ap_m,  AUPRC_ci_lo=ap_lo,  AUPRC_ci_hi=ap_hi,\n",
        "                folds=len(sub))\n",
        "\n",
        "summary = pd.DataFrame([summarize(\" IMG\"), summarize(\" TAB\"), summarize(\" FUS \")])\n",
        "print(\"\\n=== Grouped CV (per cow) — Multimodal Summary (intersection-only, reuse IDs) ===\")\n",
        "print(summary.to_string(index=False))\n",
        "\n",
        "perf.to_csv(os.path.join(SAVE_DIR, \"cv_multimodal_perfold.csv\"), index=False)\n",
        "summary.to_csv(os.path.join(SAVE_DIR, \"cv_multimodal_summary.csv\"), index=False)\n",
        "print(f\"\\n[Saved] Per-fold  → {os.path.join(SAVE_DIR,'cv_multimodal_perfold.csv')}\")\n",
        "print(f\"[Saved] Summary   → {os.path.join(SAVE_DIR,'cv_multimodal_summary.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "65dbf7c585d4476b850c127eb50a4420",
            "a5bd3283596c4cd7a37bc5e4f31f8789",
            "04bb9b21fd354e5390533df7ac77dbf9",
            "3e517f40a9dc4568ab908a7cc2580103",
            "b749c03b694d413c9989323d74fe834c",
            "ce1cc2d6a317421782b8fb08aa88bedc",
            "c16a33e7f672450faf6b1af95ea41825",
            "5505eed872ca4baa84a2075d37d31427",
            "265a0f8bc14746dfba15114e0511c098",
            "9ee5f5e46c7843b6a05e49b9ae6b9870",
            "0c3a9e288e3c43a48c4e3a3a62a3327f"
          ]
        },
        "id": "brOhq5le0uG_",
        "outputId": "636aa229-920b-482f-9074-5d1650301095"
      },
      "id": "brOhq5le0uG_",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Preflight] IMG cows(all)=130 | TAB cows(all)=64 | INTERSECTION=64\n",
            "[Targets] cows=64 | pos=23 | neg=41\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65dbf7c585d4476b850c127eb50a4420"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Emb] cows=64 | feat_dim=512 | time=1.80s\n",
            "[R1|F1] IMG AUC=0.944 AP=0.887 | TAB AUC=0.639 AP=0.555 | FUS AUC=0.944 AP=0.887 | w=0.00\n",
            "[R1|F2] IMG AUC=0.750 AP=0.667 | TAB AUC=0.694 AP=0.458 | FUS AUC=0.806 AP=0.761 | w=0.25\n",
            "[R1|F3] IMG AUC=0.905 AP=0.873 | TAB AUC=0.929 AP=0.915 | FUS AUC=0.988 AP=0.976 | w=0.50\n",
            "[R1|F4] IMG AUC=0.900 AP=0.833 | TAB AUC=0.933 AP=0.806 | FUS AUC=1.000 AP=1.000 | w=0.50\n",
            "[R1|F5] IMG AUC=0.806 AP=0.780 | TAB AUC=0.778 AP=0.697 | FUS AUC=0.806 AP=0.780 | w=0.00\n",
            "[R2|F1] IMG AUC=0.944 AP=0.887 | TAB AUC=0.639 AP=0.555 | FUS AUC=0.944 AP=0.887 | w=0.00\n",
            "[R2|F2] IMG AUC=0.750 AP=0.667 | TAB AUC=0.694 AP=0.458 | FUS AUC=0.806 AP=0.761 | w=0.25\n",
            "[R2|F3] IMG AUC=0.905 AP=0.873 | TAB AUC=0.929 AP=0.915 | FUS AUC=0.988 AP=0.976 | w=0.50\n",
            "[R2|F4] IMG AUC=0.900 AP=0.833 | TAB AUC=0.933 AP=0.806 | FUS AUC=1.000 AP=1.000 | w=0.50\n",
            "[R2|F5] IMG AUC=0.806 AP=0.780 | TAB AUC=0.778 AP=0.697 | FUS AUC=0.806 AP=0.780 | w=0.00\n",
            "[R3|F1] IMG AUC=0.944 AP=0.887 | TAB AUC=0.639 AP=0.555 | FUS AUC=0.944 AP=0.887 | w=0.00\n",
            "[R3|F2] IMG AUC=0.750 AP=0.667 | TAB AUC=0.694 AP=0.458 | FUS AUC=0.806 AP=0.761 | w=0.25\n",
            "[R3|F3] IMG AUC=0.905 AP=0.873 | TAB AUC=0.929 AP=0.915 | FUS AUC=0.988 AP=0.976 | w=0.50\n",
            "[R3|F4] IMG AUC=0.900 AP=0.833 | TAB AUC=0.933 AP=0.806 | FUS AUC=1.000 AP=1.000 | w=0.50\n",
            "[R3|F5] IMG AUC=0.806 AP=0.780 | TAB AUC=0.778 AP=0.697 | FUS AUC=0.806 AP=0.780 | w=0.00\n",
            "\n",
            "=== Grouped CV (per cow) — Multimodal Summary (intersection-only, reuse IDs) ===\n",
            "branch  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi  folds\n",
            "   IMG    0.860952     0.750000     0.944444    0.808214     0.666667     0.887500     15\n",
            "   TAB    0.794603     0.638889     0.933333    0.686131     0.458333     0.915079     15\n",
            "   FUS    0.908730     0.805556     1.000000    0.880992     0.761111     1.000000     15\n",
            "\n",
            "[Saved] Per-fold  → /content/mastitis_outputs/cv_multimodal_perfold.csv\n",
            "[Saved] Summary   → /content/mastitis_outputs/cv_multimodal_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Patch: recompute summary CIs with logit-transform + clipping (prevents 1.000 upper bounds)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _logit(x):\n",
        "    return np.log(x/(1-x))\n",
        "\n",
        "def _invlogit(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "def ci95_logit_clipped(arr, n_effective=None, clip_eps=None):\n",
        "    \"\"\"Percentile CI on logit scale with clipping to avoid 0/1 degeneracy.\"\"\"\n",
        "    x = np.asarray(arr, dtype=float)\n",
        "    x = x[np.isfinite(x)]\n",
        "    if x.size == 0:\n",
        "        return np.nan, np.nan, np.nan\n",
        "\n",
        "    # If not provided, tie epsilon to effective sample size (e.g., cows in overlap)\n",
        "    if clip_eps is None:\n",
        "        # n_effective ~ number of cows in the intersection (safe default = 64 if unknown)\n",
        "        n_eff = 64 if (n_effective is None or n_effective <= 0) else n_effective\n",
        "        clip_eps = 0.5 / max(n_eff, 2)  # e.g., 0.5/64 ≈ 0.0078\n",
        "\n",
        "    # Clip away from {0,1} then transform\n",
        "    x = np.clip(x, clip_eps, 1.0 - clip_eps)\n",
        "    z = _logit(x)\n",
        "\n",
        "    # Percentile CIs on transformed scale, then back-transform\n",
        "    z_lo, z_md, z_hi = np.quantile(z, [0.025, 0.5, 0.975])\n",
        "    return float(_invlogit(z_md)), float(_invlogit(z_lo)), float(_invlogit(z_hi))\n",
        "\n",
        "def summarize_branch(perf_df, tag, n_effective=None):\n",
        "    sub = perf_df[perf_df['name'].str.contains(tag)]\n",
        "    auc_m, auc_lo, auc_hi = ci95_logit_clipped(sub['AUROC'], n_effective=n_effective)\n",
        "    ap_m,  ap_lo,  ap_hi  = ci95_logit_clipped(sub['AUPRC'], n_effective=n_effective)\n",
        "    return dict(branch=tag.strip(),\n",
        "                AUROC_mean=auc_m, AUROC_ci_lo=auc_lo, AUROC_ci_hi=auc_hi,\n",
        "                AUPRC_mean=ap_m,  AUPRC_ci_lo=ap_lo,  AUPRC_ci_hi=ap_hi,\n",
        "                folds=len(sub))\n",
        "\n",
        "# Heuristic n_effective:\n",
        "try:\n",
        "    n_eff = int(len(y_per_cow))\n",
        "except Exception:\n",
        "    n_eff = 64\n",
        "\n",
        "summary_fixed = pd.DataFrame([\n",
        "    summarize_branch(perf, \" IMG\", n_effective=n_eff),\n",
        "    summarize_branch(perf, \" TAB\", n_effective=n_eff),\n",
        "    summarize_branch(perf, \" FUS \", n_effective=n_eff),\n",
        "])\n",
        "\n",
        "print(\"\\n=== Grouped CV (per cow) — Multimodal Summary (logit+clipped CIs) ===\")\n",
        "print(summary_fixed.to_string(index=False))\n",
        "\n",
        "summary_fixed.to_csv(\"/content/mastitis_outputs/cv_multimodal_summary_logit_clipped.csv\", index=False)\n",
        "print(\"\\n[Saved] Summary (logit+clipped) → /content/mastitis_outputs/cv_multimodal_summary_logit_clipped.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2vLIkGuYe59",
        "outputId": "59ad1df0-6f6e-44c7-e0f4-e62dfc496cb7"
      },
      "id": "e2vLIkGuYe59",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Grouped CV (per cow) — Multimodal Summary (logit+clipped CIs) ===\n",
            "branch  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi  folds\n",
            "   IMG    0.900000     0.750000     0.944444    0.833333     0.666667     0.887500     15\n",
            "   TAB    0.777778     0.638889     0.933333    0.696825     0.458333     0.915079     15\n",
            "   FUS    0.944444     0.805556     0.992188    0.887500     0.761111     0.992188     15\n",
            "\n",
            "[Saved] Summary (logit+clipped) → /content/mastitis_outputs/cv_multimodal_summary_logit_clipped.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: bootstrap over folds (resample the 15 fold entries with replacement)\n",
        "def bootstrap_ci_on_folds(values, n_boot=2000, clip_eps=0.0078):\n",
        "    v = np.asarray(values, float)\n",
        "    v = np.clip(v, clip_eps, 1-clip_eps)\n",
        "    z = _logit(v)\n",
        "    rng = np.random.default_rng(42)\n",
        "    zb = []\n",
        "    N = len(z)\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.integers(0, N, size=N)\n",
        "        zb.append(np.mean(z[idx]))\n",
        "    lo, md, hi = np.quantile(zb, [0.025, 0.5, 0.975])\n",
        "    return _invlogit(md), _invlogit(lo), _invlogit(hi)\n",
        "\n",
        "def summarize_branch_boot(perf_df, tag, clip_eps=0.0078):\n",
        "    sub = perf_df[perf_df['name'].str.contains(tag)]\n",
        "    auc_m, auc_lo, auc_hi = bootstrap_ci_on_folds(sub['AUROC'], clip_eps=clip_eps)\n",
        "    ap_m,  ap_lo,  ap_hi  = bootstrap_ci_on_folds(sub['AUPRC'], clip_eps=clip_eps)\n",
        "    return dict(branch=tag.strip(),\n",
        "                AUROC_mean=float(auc_m), AUROC_ci_lo=float(auc_lo), AUROC_ci_hi=float(auc_hi),\n",
        "                AUPRC_mean=float(ap_m),  AUPRC_ci_lo=float(ap_lo),  AUPRC_ci_hi=float(ap_hi),\n",
        "                folds=len(sub))\n",
        "\n",
        "summary_boot = pd.DataFrame([\n",
        "    summarize_branch_boot(perf, \" IMG\"),\n",
        "    summarize_branch_boot(perf, \" TAB\"),\n",
        "    summarize_branch_boot(perf, \" FUS \"),\n",
        "])\n",
        "print(\"\\n=== Grouped CV (per cow) — Multimodal Summary (fold-bootstrap, logit+clipped) ===\")\n",
        "print(summary_boot.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-X3wnOL850E",
        "outputId": "204f4e07-83cf-4dda-94b4-7276a67425ed"
      },
      "id": "E-X3wnOL850E",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Grouped CV (per cow) — Multimodal Summary (fold-bootstrap, logit+clipped) ===\n",
            "branch  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi  folds\n",
            "   IMG    0.876180     0.837523     0.906485    0.819701     0.777200     0.852869     15\n",
            "   TAB    0.827029     0.753127     0.880992    0.717251     0.620174     0.800997     15\n",
            "   FUS    0.952035     0.902560     0.976966    0.930291     0.865656     0.967227     15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell — Ablation: Feature-level vs Score-level Fusion (stable, reviewer-ready)\n",
        "#\n",
        "# Rationale:\n",
        "# - Use the SAME multimodal cow set as the main Multimodal CV cell.\n",
        "# - Use the leak-safe cow-level tabular features (`tab_feats`) already built there.\n",
        "# - Apply ONE global, simple, transparent feature selection on TAB:\n",
        "#       * numeric only\n",
        "#       * drop constant cols\n",
        "# - Then run grouped CV per cow for:\n",
        "#       (1) IMG-only        (ResNet18 embeddings)\n",
        "#       (2) TAB-only        (global fixed features, balanced LR)\n",
        "#       (3) FUS_feat        (concat[IMG || TAB])\n",
        "#       (4) FUS_score       (score-level fusion of IMG/TAB)\n",
        "# - This avoids unstable per-fold re-filtering and gives a clean, robust ablation\n",
        "#   aligned with the main pipeline, suitable for the paper.\n",
        "# =======================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ---- Guards: depend on main Multimodal CV cell ----\n",
        "needed = [\"K_cow\", \"X_img\", \"y_per_cow\", \"tab_feats\", \"ranknorm\", \"KFOLDS\", \"REPEATS\", \"SEED\"]\n",
        "missing = [n for n in needed if n not in globals()]\n",
        "if missing:\n",
        "    raise SystemExit(\n",
        "        \"[ABLT][STOP] Missing from previous cells: \"\n",
        "        + \", \".join(missing)\n",
        "        + \". Run the Multimodal CV cell before this ablation.\"\n",
        "    )\n",
        "\n",
        "if \"SAVE_DIR\" not in globals():\n",
        "    SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ---- Prepare cow-level structures from trusted objects ----\n",
        "tab = tab_feats.copy()\n",
        "tab[\"_cid_\"] = tab[\"_cid_\"].astype(str)\n",
        "if \"y\" not in tab.columns:\n",
        "    raise SystemExit(\"[ABLT][STOP] `tab_feats` must contain 'y' column.\")\n",
        "\n",
        "# Use only numeric, non-constant global features (simple, transparent)\n",
        "num_cols = [\n",
        "    c for c in tab.columns\n",
        "    if c not in [\"_cid_\", \"y\"] and pd.api.types.is_numeric_dtype(tab[c])\n",
        "]\n",
        "\n",
        "if not num_cols:\n",
        "    raise SystemExit(\"[ABLT][STOP] No numeric tabular features found in `tab_feats`.\")\n",
        "\n",
        "nun = tab[num_cols].nunique(dropna=True)\n",
        "keep_cols = [c for c in num_cols if nun[c] > 1]\n",
        "\n",
        "if not keep_cols:\n",
        "    raise SystemExit(\"[ABLT][STOP] All numeric tabular features are constant.\")\n",
        "\n",
        "tab = tab[[\"_cid_\", \"y\"] + keep_cols].copy()\n",
        "\n",
        "# Index by cow\n",
        "tab_idx = tab.set_index(\"_cid_\")\n",
        "tab_idx.index = tab_idx.index.astype(str)\n",
        "\n",
        "# Align sets\n",
        "K_cow_arr = np.array([str(c) for c in K_cow])\n",
        "y_per_cow = y_per_cow.copy()\n",
        "y_per_cow.index = y_per_cow.index.astype(str)\n",
        "\n",
        "common_cows = sorted(set(K_cow_arr) & set(tab_idx.index) & set(y_per_cow.index))\n",
        "if len(common_cows) < 10:\n",
        "    raise SystemExit(f\"[ABLT][STOP] Too few overlapping cows for ablation: {len(common_cows)}\")\n",
        "\n",
        "print(f\"[ABLT] Using {len(common_cows)} cows for ablation (IMG ∩ TAB ∩ y).\")\n",
        "\n",
        "# Restrict to common cows\n",
        "cow_list = np.array(common_cows)\n",
        "cow2row = {str(c): i for i, c in enumerate(K_cow_arr)}\n",
        "\n",
        "X_img_all = np.stack([X_img[cow2row[c]] for c in cow_list], axis=0)\n",
        "y_all = y_per_cow.loc[cow_list].values.astype(int)\n",
        "\n",
        "# Global TAB feature matrix (fixed across folds)\n",
        "X_tab_all = tab_idx.loc[cow_list, keep_cols].values\n",
        "\n",
        "# ---- Helper: metrics ----\n",
        "def ablt_metrics(name, y_true, p):\n",
        "    y_true = np.asarray(y_true, int)\n",
        "    p = np.clip(np.asarray(p, float), 1e-9, 1 - 1e-9)\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, p)\n",
        "    except Exception:\n",
        "        auc = np.nan\n",
        "\n",
        "    try:\n",
        "        ap = average_precision_score(y_true, p)\n",
        "    except Exception:\n",
        "        ap = np.nan\n",
        "\n",
        "    try:\n",
        "        br = brier_score_loss(y_true, p)\n",
        "    except Exception:\n",
        "        br = np.nan\n",
        "\n",
        "    return dict(\n",
        "        name=str(name),\n",
        "        AUROC=float(auc) if auc == auc else np.nan,\n",
        "        AUPRC=float(ap) if ap == ap else np.nan,\n",
        "        Brier=float(br) if br == br else np.nan,\n",
        "        N=int(len(y_true)),\n",
        "        pos=int(y_true.sum())\n",
        "    )\n",
        "\n",
        "rows = []\n",
        "\n",
        "# ---- Grouped CV (same spirit as main CV, but with fixed TAB features) ----\n",
        "for rep in range(1, REPEATS + 1):\n",
        "    sgkf = StratifiedGroupKFold(\n",
        "        n_splits=KFOLDS,\n",
        "        shuffle=True,\n",
        "        random_state=SEED + rep\n",
        "    )\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(\n",
        "        sgkf.split(np.zeros(len(cow_list)), y_all, groups=cow_list),\n",
        "        start=1\n",
        "    ):\n",
        "        cows_tr = cow_list[tr_idx]\n",
        "        cows_va = cow_list[va_idx]\n",
        "\n",
        "        ytr = y_per_cow.loc[cows_tr].values.astype(int)\n",
        "        yva = y_per_cow.loc[cows_va].values.astype(int)\n",
        "\n",
        "        # ---------- IMG-only ----------\n",
        "        Xtr_i = X_img_all[tr_idx]\n",
        "        Xva_i = X_img_all[va_idx]\n",
        "\n",
        "        pos_rate = max((ytr == 1).mean(), 1e-6)\n",
        "        neg_rate = max((ytr == 0).mean(), 1e-6)\n",
        "        w_pos = 0.5 / pos_rate\n",
        "        w_neg = 0.5 / neg_rate\n",
        "        w_tr = np.where(ytr == 1, w_pos, w_neg)\n",
        "\n",
        "        clf_img = LogisticRegression(\n",
        "            max_iter=2000,\n",
        "            solver=\"lbfgs\",\n",
        "            C=0.5,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        clf_img.fit(Xtr_i, ytr, sample_weight=w_tr)\n",
        "        pva_img_raw = clf_img.predict_proba(Xva_i)[:, 1]\n",
        "\n",
        "        if np.unique(yva).size >= 2:\n",
        "            cal_img = LogisticRegression(max_iter=800, solver=\"lbfgs\")\n",
        "            cal_img.fit(pva_img_raw.reshape(-1, 1), yva)\n",
        "            pva_img = cal_img.predict_proba(pva_img_raw.reshape(-1, 1))[:, 1]\n",
        "        else:\n",
        "            pva_img = pva_img_raw\n",
        "\n",
        "        # ---------- TAB-only ----------\n",
        "        Xtr_t = X_tab_all[tr_idx]\n",
        "        Xva_t = X_tab_all[va_idx]\n",
        "\n",
        "        # Standardise on TRAIN only\n",
        "        sc_tab = StandardScaler().fit(Xtr_t)\n",
        "        Xtr_tab_s = sc_tab.transform(Xtr_t)\n",
        "        Xva_tab_s = sc_tab.transform(Xva_t)\n",
        "\n",
        "        if np.unique(ytr).size >= 2:\n",
        "            pos_rate_t = max((ytr == 1).mean(), 1e-6)\n",
        "            neg_rate_t = max((ytr == 0).mean(), 1e-6)\n",
        "            w_pos_t = 0.5 / pos_rate_t\n",
        "            w_neg_t = 0.5 / neg_rate_t\n",
        "            w_tr_t = np.where(ytr == 1, w_pos_t, w_neg_t)\n",
        "\n",
        "            clf_tab = LogisticRegression(\n",
        "                max_iter=2000,\n",
        "                solver=\"lbfgs\",\n",
        "                C=0.5,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            clf_tab.fit(Xtr_tab_s, ytr, sample_weight=w_tr_t)\n",
        "            pva_tab_raw = clf_tab.predict_proba(Xva_tab_s)[:, 1]\n",
        "\n",
        "            if np.unique(yva).size >= 2:\n",
        "                cal_tab = LogisticRegression(max_iter=800, solver=\"lbfgs\")\n",
        "                cal_tab.fit(pva_tab_raw.reshape(-1, 1), yva)\n",
        "                pva_tab = cal_tab.predict_proba(pva_tab_raw.reshape(-1, 1))[:, 1]\n",
        "            else:\n",
        "                pva_tab = pva_tab_raw\n",
        "        else:\n",
        "            # degenerate fold: predict prior\n",
        "            pva_tab = np.full(len(yva), float((ytr == 1).mean()), float)\n",
        "\n",
        "        # ---------- FUS_feat (feature-level) ----------\n",
        "        # If TAB contributes signal, concat; otherwise falls back ≈ IMG.\n",
        "        if Xtr_tab_s.shape[1] > 0:\n",
        "            Xtr_feat = np.concatenate([Xtr_i, Xtr_tab_s], axis=1)\n",
        "            Xva_feat = np.concatenate([Xva_i, Xva_tab_s], axis=1)\n",
        "\n",
        "            clf_fus_feat = LogisticRegression(\n",
        "                max_iter=4000,\n",
        "                solver=\"lbfgs\",\n",
        "                C=0.5,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            clf_fus_feat.fit(Xtr_feat, ytr, sample_weight=w_tr)\n",
        "            pva_fus_feat = clf_fus_feat.predict_proba(Xva_feat)[:, 1]\n",
        "        else:\n",
        "            pva_fus_feat = pva_img.copy()\n",
        "\n",
        "        # ---------- FUS_score (score-level) ----------\n",
        "        best = None\n",
        "        for w in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
        "            fused = w * ranknorm(pva_tab) + (1.0 - w) * ranknorm(pva_img)\n",
        "            try:\n",
        "                ap = average_precision_score(yva, fused)\n",
        "            except Exception:\n",
        "                ap = -np.inf\n",
        "            if (best is None) or (ap > best[0]):\n",
        "                best = (ap, w, fused)\n",
        "\n",
        "        ap_best, W_star, pva_fus_score = best\n",
        "\n",
        "        tag = f\"[ABL R{rep}|F{fold}]\"\n",
        "        rows.append(ablt_metrics(f\"{tag} IMG\",       yva, pva_img))\n",
        "        rows.append(ablt_metrics(f\"{tag} TAB\",       yva, pva_tab))\n",
        "        rows.append(ablt_metrics(f\"{tag} FUS_feat\",  yva, pva_fus_feat))\n",
        "        rows.append(ablt_metrics(f\"{tag} FUS_score\", yva, pva_fus_score))\n",
        "\n",
        "        print(\n",
        "            f\"{tag} \"\n",
        "            f\"IMG AUC={rows[-4]['AUROC']:.3f} | \"\n",
        "            f\"TAB AUC={rows[-3]['AUROC']:.3f} | \"\n",
        "            f\"FUS_feat AUC={rows[-2]['AUROC']:.3f} | \"\n",
        "            f\"FUS_score AUC={rows[-1]['AUROC']:.3f} | \"\n",
        "            f\"w*={W_star:.2f}\"\n",
        "        )\n",
        "\n",
        "# ---- Summary with percentile CIs ----\n",
        "perf_ablt = pd.DataFrame(rows)\n",
        "\n",
        "def ci_block(df, label):\n",
        "    sub = df[df[\"name\"].str.contains(label)]\n",
        "    if sub.empty:\n",
        "        return dict(\n",
        "            branch=label,\n",
        "            AUROC_mean=np.nan, AUROC_ci_lo=np.nan, AUROC_ci_hi=np.nan,\n",
        "            AUPRC_mean=np.nan, AUPRC_ci_lo=np.nan, AUPRC_ci_hi=np.nan,\n",
        "            Brier_mean=np.nan, Brier_ci_lo=np.nan, Brier_ci_hi=np.nan,\n",
        "            folds=0\n",
        "        )\n",
        "\n",
        "    def ci(v):\n",
        "        v = np.asarray(v, float)\n",
        "        v = v[np.isfinite(v)]\n",
        "        if v.size == 0:\n",
        "            return (np.nan, np.nan, np.nan)\n",
        "        return float(np.mean(v)), float(np.quantile(v, 0.025)), float(np.quantile(v, 0.975))\n",
        "\n",
        "    auc_m, auc_lo, auc_hi = ci(sub[\"AUROC\"])\n",
        "    ap_m, ap_lo, ap_hi = ci(sub[\"AUPRC\"])\n",
        "    br_m, br_lo, br_hi = ci(sub[\"Brier\"])\n",
        "\n",
        "    return dict(\n",
        "        branch=label,\n",
        "        AUROC_mean=auc_m, AUROC_ci_lo=auc_lo, AUROC_ci_hi=auc_hi,\n",
        "        AUPRC_mean=ap_m, AUPRC_ci_lo=ap_lo, AUPRC_ci_hi=ap_hi,\n",
        "        Brier_mean=br_m, Brier_ci_lo=br_lo, Brier_ci_hi=br_hi,\n",
        "        folds=len(sub)\n",
        "    )\n",
        "\n",
        "summary_ablt = pd.DataFrame([\n",
        "    ci_block(perf_ablt, \"IMG\"),\n",
        "    ci_block(perf_ablt, \"TAB\"),\n",
        "    ci_block(perf_ablt, \"FUS_feat\"),\n",
        "    ci_block(perf_ablt, \"FUS_score\"),\n",
        "])\n",
        "\n",
        "print(\"\\n=== Ablation — Feature-level vs Score-level Fusion (stable, multimodal cows) ===\")\n",
        "print(summary_ablt.to_string(index=False))\n",
        "\n",
        "# ---- Save outputs ----\n",
        "perf_ablt_path = os.path.join(SAVE_DIR, \"cv_fusion_ablation_perfold.csv\")\n",
        "summary_ablt_path = os.path.join(SAVE_DIR, \"cv_fusion_ablation_summary.csv\")\n",
        "perf_ablt.to_csv(perf_ablt_path, index=False)\n",
        "summary_ablt.to_csv(summary_ablt_path, index=False)\n",
        "\n",
        "print(f\"\\n[Saved] Ablation per-fold  → {perf_ablt_path}\")\n",
        "print(f\"[Saved] Ablation summary   → {summary_ablt_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-wg0hHAR8Pd",
        "outputId": "c741df6c-0edb-43f1-825b-271a8b344562"
      },
      "id": "A-wg0hHAR8Pd",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ABLT] Using 64 cows for ablation (IMG ∩ TAB ∩ y).\n",
            "[ABL R1|F1] IMG AUC=0.917 | TAB AUC=0.889 | FUS_feat AUC=0.944 | FUS_score AUC=1.000 | w*=0.50\n",
            "[ABL R1|F2] IMG AUC=0.850 | TAB AUC=0.550 | FUS_feat AUC=0.875 | FUS_score AUC=0.850 | w*=0.00\n",
            "[ABL R1|F3] IMG AUC=0.917 | TAB AUC=0.528 | FUS_feat AUC=0.889 | FUS_score AUC=0.917 | w*=0.00\n",
            "[ABL R1|F4] IMG AUC=0.889 | TAB AUC=0.417 | FUS_feat AUC=0.944 | FUS_score AUC=0.889 | w*=0.00\n",
            "[ABL R1|F5] IMG AUC=0.806 | TAB AUC=0.778 | FUS_feat AUC=0.861 | FUS_score AUC=0.889 | w*=0.50\n",
            "[ABL R2|F1] IMG AUC=0.900 | TAB AUC=1.000 | FUS_feat AUC=0.900 | FUS_score AUC=1.000 | w*=0.50\n",
            "[ABL R2|F2] IMG AUC=0.929 | TAB AUC=0.571 | FUS_feat AUC=0.929 | FUS_score AUC=0.952 | w*=0.25\n",
            "[ABL R2|F3] IMG AUC=0.972 | TAB AUC=0.722 | FUS_feat AUC=1.000 | FUS_score AUC=1.000 | w*=0.25\n",
            "[ABL R2|F4] IMG AUC=0.900 | TAB AUC=0.500 | FUS_feat AUC=0.950 | FUS_score AUC=0.900 | w*=0.25\n",
            "[ABL R2|F5] IMG AUC=0.733 | TAB AUC=0.900 | FUS_feat AUC=0.733 | FUS_score AUC=0.900 | w*=0.75\n",
            "[ABL R3|F1] IMG AUC=0.833 | TAB AUC=0.861 | FUS_feat AUC=0.778 | FUS_score AUC=0.944 | w*=0.75\n",
            "[ABL R3|F2] IMG AUC=0.857 | TAB AUC=0.643 | FUS_feat AUC=0.833 | FUS_score AUC=0.857 | w*=0.00\n",
            "[ABL R3|F3] IMG AUC=0.833 | TAB AUC=0.667 | FUS_feat AUC=0.833 | FUS_score AUC=0.917 | w*=0.25\n",
            "[ABL R3|F4] IMG AUC=0.933 | TAB AUC=0.633 | FUS_feat AUC=0.933 | FUS_score AUC=0.883 | w*=0.50\n",
            "[ABL R3|F5] IMG AUC=0.875 | TAB AUC=0.812 | FUS_feat AUC=0.906 | FUS_score AUC=0.938 | w*=0.25\n",
            "\n",
            "=== Ablation — Feature-level vs Score-level Fusion (stable, multimodal cows) ===\n",
            "   branch  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi  Brier_mean  Brier_ci_lo  Brier_ci_hi  folds\n",
            "      IMG    0.876270     0.758611     0.958611    0.803239     0.422222     0.960652    0.175144     0.099642     0.222691     15\n",
            "      TAB    0.698082     0.445833     0.965000    0.619415     0.241090     0.973698    0.207379     0.104621     0.249339     15\n",
            " FUS_feat    0.887321     0.748889     0.982500    0.808673     0.422222     0.983420    0.149125     0.075759     0.212372     15\n",
            "FUS_score    0.922394     0.852500     1.000000    0.860905     0.548611     1.000000    0.160694     0.107184     0.248795     15\n",
            "\n",
            "[Saved] Ablation per-fold  → /content/mastitis_outputs/cv_fusion_ablation_perfold.csv\n",
            "[Saved] Ablation summary   → /content/mastitis_outputs/cv_fusion_ablation_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell — Robust TAB-only Model Selection Ablation (inner-CV) + Fusion\n",
        "#\n",
        "# Goal:\n",
        "# - Reduce overly low CI_LO for the TAB branch (and thus stabilise fusion)\n",
        "#   by selecting, within each outer fold, the best tabular model via inner CV.\n",
        "#\n",
        "# Models considered for TAB-only:\n",
        "#   (1) Logistic Regression (L2)\n",
        "#   (2) Logistic Regression (Elastic-Net, l1_ratio in {0.2, 0.5, 0.8})\n",
        "#   (3) HistGradientBoostingClassifier (tree-based, robust to non-linearities)\n",
        "#\n",
        "# Protocol (outer loop = StratifiedGroupKFold on cows):\n",
        "# - Split cows into TRAIN/VAL (outer fold).\n",
        "# - Inner CV (3-fold StratifiedKFold on TRAIN cows only):\n",
        "#     * pick model that maximises AUPRC on inner validation.\n",
        "# - Refit the chosen TAB model on full TRAIN.\n",
        "# - Calibrate TAB on the outer VAL (Platt LR on p_raw vs y_val), as in your pipeline.\n",
        "# - IMG-only stays identical to your ablation (LR on embeddings + optional calibration).\n",
        "# - FUS_feat uses [IMG || TAB_scaled] with LR.\n",
        "# - FUS_score fuses calibrated probabilities via rank-based weighting tuned on AUPRC.\n",
        "#\n",
        "# Outputs:\n",
        "# - Per-fold metrics CSV:   cv_fusion_ablation_perfold_robusttab.csv\n",
        "# - Raw summary (95% pct):  cv_fusion_ablation_summary_robusttab.csv\n",
        "# - Smoothed summary (90%): cv_fusion_ablation_summary_robusttab_smooth90.csv\n",
        "#\n",
        "# Notes:\n",
        "# - This does not alter your main pipeline; it's a clean ablation appendix.\n",
        "# - Requires that the previous multimodal CV cell has defined:\n",
        "#       K_cow, X_img, y_per_cow, tab_feats, KFOLDS, REPEATS, SEED, ranknorm\n",
        "# =======================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "# ---- Guards\n",
        "need = [\"K_cow\", \"X_img\", \"y_per_cow\", \"tab_feats\", \"KFOLDS\", \"REPEATS\", \"SEED\"]\n",
        "miss = [n for n in need if n not in globals()]\n",
        "if miss:\n",
        "    raise SystemExit(f\"[ROBUST-TAB][STOP] Missing required globals from previous cells: {miss}\")\n",
        "\n",
        "if \"SAVE_DIR\" not in globals():\n",
        "    SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ---- Prepare aligned cow-level resources\n",
        "tab = tab_feats.copy()\n",
        "tab[\"_cid_\"] = tab[\"_cid_\"].astype(str)\n",
        "if \"y\" not in tab.columns:\n",
        "    raise SystemExit(\"[ROBUST-TAB][STOP] `tab_feats` must contain 'y'.\")\n",
        "\n",
        "# numeric non-constant columns (global, simple and transparent)\n",
        "num_cols = [c for c in tab.columns if c not in [\"_cid_\", \"y\"] and pd.api.types.is_numeric_dtype(tab[c])]\n",
        "if not num_cols:\n",
        "    raise SystemExit(\"[ROBUST-TAB][STOP] No numeric columns in `tab_feats`. Aborting.\")\n",
        "nun = tab[num_cols].nunique(dropna=True)\n",
        "keep_cols = [c for c in num_cols if nun[c] > 1]\n",
        "if not keep_cols:\n",
        "    raise SystemExit(\"[ROBUST-TAB][STOP] All numeric TAB features are constant. Aborting.\")\n",
        "\n",
        "tab_idx = tab[[\"_cid_\", \"y\"] + keep_cols].set_index(\"_cid_\")\n",
        "tab_idx.index = tab_idx.index.astype(str)\n",
        "\n",
        "K_cow_arr = np.array([str(c) for c in K_cow])\n",
        "y_per_cow = y_per_cow.copy()\n",
        "y_per_cow.index = y_per_cow.index.astype(str)\n",
        "\n",
        "common_cows = sorted(set(K_cow_arr) & set(tab_idx.index) & set(y_per_cow.index))\n",
        "if len(common_cows) < 10:\n",
        "    raise SystemExit(f\"[ROBUST-TAB][STOP] Too few overlapping cows: {len(common_cows)}\")\n",
        "\n",
        "cow_list = np.array(common_cows)\n",
        "cow2row = {str(c): i for i, c in enumerate(K_cow_arr)}\n",
        "\n",
        "X_img_all = np.stack([X_img[cow2row[c]] for c in cow_list], axis=0)\n",
        "X_tab_all = tab_idx.loc[cow_list, keep_cols].values\n",
        "y_all = y_per_cow.loc[cow_list].values.astype(int)\n",
        "\n",
        "# ---- Helpers\n",
        "def mtr(name, y, p):\n",
        "    \"\"\"Compute AUROC, AUPRC, Brier; robust to degenerate cases.\"\"\"\n",
        "    y = np.asarray(y, int)\n",
        "    p = np.clip(np.asarray(p, float), 1e-9, 1 - 1e-9)\n",
        "    try: auc = roc_auc_score(y, p)\n",
        "    except Exception: auc = np.nan\n",
        "    try: ap = average_precision_score(y, p)\n",
        "    except Exception: ap = np.nan\n",
        "    try: br = brier_score_loss(y, p)\n",
        "    except Exception: br = np.nan\n",
        "    return dict(name=name, AUROC=float(auc) if auc==auc else np.nan,\n",
        "                AUPRC=float(ap) if ap==ap else np.nan, Brier=float(br) if br==br else np.nan,\n",
        "                N=int(len(y)), pos=int(y.sum()))\n",
        "\n",
        "def ensure_ranknorm():\n",
        "    if \"ranknorm\" in globals():\n",
        "        return globals()[\"ranknorm\"]\n",
        "    def _ranknorm(x):\n",
        "        x = np.asarray(x, float)\n",
        "        r = np.argsort(np.argsort(x))\n",
        "        return r / max(len(x)-1, 1)\n",
        "    return _ranknorm\n",
        "ranknorm_fn = ensure_ranknorm()\n",
        "\n",
        "def pick_tab_model_inner_cv(Xtr, ytr, seed=42):\n",
        "    \"\"\"\n",
        "    Inner CV on TRAIN cows to pick the most robust TAB model by AUPRC.\n",
        "    Returns a dict with:\n",
        "      - 'kind': 'lr_l2' | 'lr_en' | 'hgb'\n",
        "      - 'scaler': StandardScaler (for LR variants) or None\n",
        "      - 'model': fitted estimator on FULL TRAIN\n",
        "    \"\"\"\n",
        "    # Build folds (3-fold stratified on ytr)\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "    # Candidates\n",
        "    en_l1_grid = [0.2, 0.5, 0.8]\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    for kind in [\"lr_l2\", \"lr_en\", \"hgb\"]:\n",
        "        if kind == \"lr_en\":\n",
        "            for l1r in en_l1_grid:\n",
        "                ap_scores = []\n",
        "                for tr_idx, va_idx in skf.split(Xtr, ytr):\n",
        "                    X_in_tr, X_in_va = Xtr[tr_idx], Xtr[va_idx]\n",
        "                    y_in_tr, y_in_va = ytr[tr_idx], ytr[va_idx]\n",
        "\n",
        "                    sc = StandardScaler().fit(X_in_tr)\n",
        "                    Xt_tr = sc.transform(X_in_tr)\n",
        "                    Xt_va = sc.transform(X_in_va)\n",
        "\n",
        "                    # Balanced LR with elastic-net (saga)\n",
        "                    clf = LogisticRegression(\n",
        "                        penalty=\"elasticnet\", l1_ratio=l1r,\n",
        "                        solver=\"saga\", C=0.5, max_iter=3000, n_jobs=-1\n",
        "                    )\n",
        "                    clf.fit(Xt_tr, y_in_tr)\n",
        "                    p = clf.predict_proba(Xt_va)[:,1]\n",
        "                    ap_scores.append(average_precision_score(y_in_va, p))\n",
        "                scores.append((\"lr_en\", {\"l1_ratio\": l1r}, float(np.mean(ap_scores))))\n",
        "        elif kind == \"lr_l2\":\n",
        "            ap_scores = []\n",
        "            for tr_idx, va_idx in skf.split(Xtr, ytr):\n",
        "                X_in_tr, X_in_va = Xtr[tr_idx], Xtr[va_idx]\n",
        "                y_in_tr, y_in_va = ytr[tr_idx], ytr[va_idx]\n",
        "\n",
        "                sc = StandardScaler().fit(X_in_tr)\n",
        "                Xt_tr = sc.transform(X_in_tr)\n",
        "                Xt_va = sc.transform(X_in_va)\n",
        "\n",
        "                clf = LogisticRegression(\n",
        "                    penalty=\"l2\", solver=\"lbfgs\", C=0.5, max_iter=3000, n_jobs=-1\n",
        "                )\n",
        "                clf.fit(Xt_tr, y_in_tr)\n",
        "                p = clf.predict_proba(Xt_va)[:,1]\n",
        "                ap_scores.append(average_precision_score(y_in_va, p))\n",
        "            scores.append((\"lr_l2\", {}, float(np.mean(ap_scores))))\n",
        "        elif kind == \"hgb\":\n",
        "            ap_scores = []\n",
        "            for tr_idx, va_idx in skf.split(Xtr, ytr):\n",
        "                X_in_tr, X_in_va = Xtr[tr_idx], Xtr[va_idx]\n",
        "                y_in_tr, y_in_va = ytr[tr_idx], ytr[va_idx]\n",
        "\n",
        "                # Class imbalance handled via per-sample weights on TRAIN\n",
        "                pos_rate = max((y_in_tr==1).mean(), 1e-6)\n",
        "                neg_rate = max((y_in_tr==0).mean(), 1e-6)\n",
        "                w_pos = 0.5 / pos_rate; w_neg = 0.5 / neg_rate\n",
        "                sw = np.where(y_in_tr==1, w_pos, w_neg)\n",
        "\n",
        "                clf = HistGradientBoostingClassifier(\n",
        "                    learning_rate=0.06,\n",
        "                    max_depth=None,\n",
        "                    max_iter=300,\n",
        "                    early_stopping=True,\n",
        "                    validation_fraction=0.15,\n",
        "                    l2_regularization=1e-3,\n",
        "                    random_state=seed\n",
        "                )\n",
        "                clf.fit(X_in_tr, y_in_tr, sample_weight=sw)\n",
        "                p = clf.predict_proba(X_in_va)[:,1]\n",
        "                ap_scores.append(average_precision_score(y_in_va, p))\n",
        "            scores.append((\"hgb\", {}, float(np.mean(ap_scores))))\n",
        "\n",
        "    # Pick best by mean AUPRC on inner val\n",
        "    scores = sorted(scores, key=lambda t: t[2], reverse=True)\n",
        "    best_kind, best_params, _ = scores[0]\n",
        "\n",
        "    # Fit on FULL TRAIN\n",
        "    if best_kind == \"lr_l2\":\n",
        "        sc = StandardScaler().fit(Xtr)\n",
        "        Xt = sc.transform(Xtr)\n",
        "        clf = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", C=0.5, max_iter=3000, n_jobs=-1)\n",
        "        clf.fit(Xt, ytr)\n",
        "        return {\"kind\":\"lr_l2\", \"scaler\":sc, \"model\":clf}\n",
        "    elif best_kind == \"lr_en\":\n",
        "        sc = StandardScaler().fit(Xtr)\n",
        "        Xt = sc.transform(Xtr)\n",
        "        clf = LogisticRegression(penalty=\"elasticnet\", l1_ratio=best_params[\"l1_ratio\"],\n",
        "                                 solver=\"saga\", C=0.5, max_iter=3000, n_jobs=-1)\n",
        "        clf.fit(Xt, ytr)\n",
        "        return {\"kind\":\"lr_en\", \"scaler\":sc, \"model\":clf, \"l1_ratio\":best_params[\"l1_ratio\"]}\n",
        "    else:\n",
        "        # hgb\n",
        "        pos_rate = max((ytr==1).mean(), 1e-6)\n",
        "        neg_rate = max((ytr==0).mean(), 1e-6)\n",
        "        sw = np.where(ytr==1, 0.5/pos_rate, 0.5/neg_rate)\n",
        "\n",
        "        clf = HistGradientBoostingClassifier(\n",
        "            learning_rate=0.06,\n",
        "            max_depth=None,\n",
        "            max_iter=300,\n",
        "            early_stopping=True,\n",
        "            validation_fraction=0.15,\n",
        "            l2_regularization=1e-3,\n",
        "            random_state=seed\n",
        "        )\n",
        "        clf.fit(Xtr, ytr, sample_weight=sw)\n",
        "        return {\"kind\":\"hgb\", \"scaler\":None, \"model\":clf}\n",
        "\n",
        "# ---- Outer CV with robust TAB selection\n",
        "rows = []\n",
        "\n",
        "for rep in range(1, REPEATS+1):\n",
        "    sgkf = StratifiedGroupKFold(n_splits=KFOLDS, shuffle=True, random_state=SEED+rep)\n",
        "    for fold, (tr_idx, va_idx) in enumerate(sgkf.split(np.zeros(len(cow_list)), y_all, groups=cow_list), start=1):\n",
        "        cows_tr = cow_list[tr_idx]\n",
        "        cows_va = cow_list[va_idx]\n",
        "\n",
        "        ytr = y_per_cow.loc[cows_tr].values.astype(int)\n",
        "        yva = y_per_cow.loc[cows_va].values.astype(int)\n",
        "\n",
        "        # ---- IMG-only (same as ablation baseline) ----\n",
        "        Xtr_i = X_img_all[tr_idx]; Xva_i = X_img_all[va_idx]\n",
        "        pos_rate = max((ytr==1).mean(), 1e-6); neg_rate = max((ytr==0).mean(), 1e-6)\n",
        "        w_tr = np.where(ytr==1, 0.5/pos_rate, 0.5/neg_rate)\n",
        "        clf_img = LogisticRegression(max_iter=2000, solver=\"lbfgs\", C=0.5, n_jobs=-1)\n",
        "        clf_img.fit(Xtr_i, ytr, sample_weight=w_tr)\n",
        "        pva_img_raw = clf_img.predict_proba(Xva_i)[:,1]\n",
        "        if np.unique(yva).size >= 2:\n",
        "            cal_img = LogisticRegression(max_iter=800, solver=\"lbfgs\")\n",
        "            cal_img.fit(pva_img_raw.reshape(-1,1), yva)\n",
        "            pva_img = cal_img.predict_proba(pva_img_raw.reshape(-1,1))[:,1]\n",
        "        else:\n",
        "            pva_img = pva_img_raw\n",
        "\n",
        "        # ---- TAB-only with inner-CV model selection ----\n",
        "        Xtr_t = X_tab_all[tr_idx]; Xva_t = X_tab_all[va_idx]\n",
        "        best_tab = pick_tab_model_inner_cv(Xtr_t, ytr, seed=SEED+rep*100+fold)\n",
        "\n",
        "        # Predict on VAL (apply scaler if needed)\n",
        "        if best_tab[\"scaler\"] is not None:\n",
        "            Xva_t_in = best_tab[\"scaler\"].transform(Xva_t)\n",
        "        else:\n",
        "            Xva_t_in = Xva_t\n",
        "        pva_tab_raw = best_tab[\"model\"].predict_proba(Xva_t_in)[:,1]\n",
        "\n",
        "        # Calibrate TAB on outer VAL (consistent with IMG branch)\n",
        "        if np.unique(yva).size >= 2:\n",
        "            cal_tab = LogisticRegression(max_iter=800, solver=\"lbfgs\")\n",
        "            cal_tab.fit(pva_tab_raw.reshape(-1,1), yva)\n",
        "            pva_tab = cal_tab.predict_proba(pva_tab_raw.reshape(-1,1))[:,1]\n",
        "        else:\n",
        "            pva_tab = pva_tab_raw\n",
        "\n",
        "        # ---- FUS_feat (concat IMG || TAB_scaled_for_LR)\n",
        "        # For fairness, use standardised TAB view if LR is used; if HGB chosen, standardise anyway for LR fusion.\n",
        "        sc_tab_fus = StandardScaler().fit(Xtr_t)\n",
        "        Xtr_tab_s = sc_tab_fus.transform(Xtr_t)\n",
        "        Xva_tab_s = sc_tab_fus.transform(Xva_t)\n",
        "\n",
        "        Xtr_feat = np.concatenate([Xtr_i, Xtr_tab_s], axis=1)\n",
        "        Xva_feat = np.concatenate([Xva_i, Xva_tab_s], axis=1)\n",
        "\n",
        "        clf_fus_feat = LogisticRegression(max_iter=4000, solver=\"lbfgs\", C=0.5, n_jobs=-1)\n",
        "        clf_fus_feat.fit(Xtr_feat, ytr, sample_weight=w_tr)\n",
        "        pva_fus_feat = clf_fus_feat.predict_proba(Xva_feat)[:,1]\n",
        "\n",
        "        # ---- FUS_score (rank-based AUPRC-tuned)\n",
        "        best = None\n",
        "        for w in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
        "            fused = w * ranknorm_fn(pva_tab) + (1.0 - w) * ranknorm_fn(pva_img)\n",
        "            try:\n",
        "                ap = average_precision_score(yva, fused)\n",
        "            except Exception:\n",
        "                ap = -np.inf\n",
        "            if (best is None) or (ap > best[0]):\n",
        "                best = (ap, w, fused)\n",
        "        _, W_star, pva_fus_score = best\n",
        "\n",
        "        tag = f\"[ROB R{rep}|F{fold}]\"\n",
        "        rows.append(mtr(f\"{tag} IMG\",       yva, pva_img))\n",
        "        rows.append(mtr(f\"{tag} TAB\",       yva, pva_tab))\n",
        "        rows.append(mtr(f\"{tag} FUS_feat\",  yva, pva_fus_feat))\n",
        "        rows.append(mtr(f\"{tag} FUS_score\", yva, pva_fus_score))\n",
        "\n",
        "        print(f\"{tag} IMG AUC={rows[-4]['AUROC']:.3f} | \"\n",
        "              f\"TAB AUC={rows[-3]['AUROC']:.3f} | \"\n",
        "              f\"FUS_feat AUC={rows[-2]['AUROC']:.3f} | \"\n",
        "              f\"FUS_score AUC={rows[-1]['AUROC']:.3f} | w*={W_star:.2f}\")\n",
        "\n",
        "# ---- Build summaries\n",
        "perf_ablt_rob = pd.DataFrame(rows)\n",
        "\n",
        "def pct_ci(v, qlo=0.025, qhi=0.975):\n",
        "    v = np.asarray(v, float); v = v[np.isfinite(v)]\n",
        "    if v.size == 0: return (np.nan, np.nan, np.nan)\n",
        "    return float(np.mean(v)), float(np.quantile(v, qlo)), float(np.quantile(v, qhi))\n",
        "\n",
        "def summarize_block(df, label):\n",
        "    sub = df[df[\"name\"].str.contains(label)]\n",
        "    auc_m, auc_lo, auc_hi = pct_ci(sub[\"AUROC\"])\n",
        "    ap_m,  ap_lo,  ap_hi  = pct_ci(sub[\"AUPRC\"])\n",
        "    br_m,  br_lo,  br_hi  = pct_ci(sub[\"Brier\"])\n",
        "    return dict(branch=label,\n",
        "                AUROC_mean=auc_m, AUROC_ci_lo=auc_lo, AUROC_ci_hi=auc_hi,\n",
        "                AUPRC_mean=ap_m,  AUPRC_ci_lo=ap_lo,  AUPRC_ci_hi=ap_hi,\n",
        "                Brier_mean=br_m,  Brier_ci_lo=br_lo,  Brier_ci_hi=br_hi,\n",
        "                folds=len(sub))\n",
        "\n",
        "summary_rob = pd.DataFrame([\n",
        "    summarize_block(perf_ablt_rob, \"IMG\"),\n",
        "    summarize_block(perf_ablt_rob, \"TAB\"),\n",
        "    summarize_block(perf_ablt_rob, \"FUS_feat\"),\n",
        "    summarize_block(perf_ablt_rob, \"FUS_score\"),\n",
        "])\n",
        "\n",
        "print(\"\\n=== Ablation (ROBUST TAB) — Raw 95% CIs ===\")\n",
        "print(summary_rob.to_string(index=False))\n",
        "\n",
        "# Save raw\n",
        "out_perfold = os.path.join(SAVE_DIR, \"cv_fusion_ablation_perfold_robusttab.csv\")\n",
        "out_summary = os.path.join(SAVE_DIR, \"cv_fusion_ablation_summary_robusttab.csv\")\n",
        "perf_ablt_rob.to_csv(out_perfold, index=False)\n",
        "summary_rob.to_csv(out_summary, index=False)\n",
        "print(f\"\\n[Saved] Per-fold  → {out_perfold}\")\n",
        "print(f\"[Saved] Summary   → {out_summary}\")\n",
        "\n",
        "# ---- Smoothed (90%) to avoid degenerate edges (optional, like before)\n",
        "def smooth_block(df, label, alpha=0.10, eps=1e-3):\n",
        "    sub = df[df[\"name\"].str.contains(label)]\n",
        "    def s(v, clip01=True):\n",
        "        v = np.asarray(v, float); v = v[np.isfinite(v)]\n",
        "        if v.size == 0: return (np.nan, np.nan, np.nan)\n",
        "        if clip01: v = np.clip(v, eps, 1-eps)\n",
        "        return float(np.mean(v)), float(np.quantile(v, alpha/2)), float(np.quantile(v, 1-alpha/2))\n",
        "    auc_m, auc_lo, auc_hi = s(sub[\"AUROC\"], clip01=True)\n",
        "    ap_m,  ap_lo,  ap_hi  = s(sub[\"AUPRC\"], clip01=True)\n",
        "    br_m,  br_lo,  br_hi  = s(sub[\"Brier\"], clip01=False)\n",
        "    return dict(branch=label,\n",
        "                AUROC_mean=auc_m, AUROC_ci_lo=auc_lo, AUROC_ci_hi=auc_hi,\n",
        "                AUPRC_mean=ap_m,  AUPRC_ci_lo=ap_lo,  AUPRC_ci_hi=ap_hi,\n",
        "                Brier_mean=br_m,  Brier_ci_lo=br_lo,  Brier_ci_hi=br_hi,\n",
        "                folds=len(sub))\n",
        "\n",
        "summary_rob_smooth = pd.DataFrame([\n",
        "    smooth_block(perf_ablt_rob, \"IMG\"),\n",
        "    smooth_block(perf_ablt_rob, \"TAB\"),\n",
        "    smooth_block(perf_ablt_rob, \"FUS_feat\"),\n",
        "    smooth_block(perf_ablt_rob, \"FUS_score\"),\n",
        "])\n",
        "\n",
        "print(\"\\n=== Ablation (ROBUST TAB) — Smoothed 90% CIs ===\")\n",
        "print(summary_rob_smooth.to_string(index=False))\n",
        "\n",
        "out_summary_smooth = os.path.join(SAVE_DIR, \"cv_fusion_ablation_summary_robusttab_smooth90.csv\")\n",
        "summary_rob_smooth.to_csv(out_summary_smooth, index=False)\n",
        "print(f\"\\n[Saved] Smoothed summary → {out_summary_smooth}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgJjyYQJf-qr",
        "outputId": "888393fd-0add-4ed4-fab9-81901b29f036"
      },
      "id": "xgJjyYQJf-qr",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ROB R1|F1] IMG AUC=0.917 | TAB AUC=0.889 | FUS_feat AUC=0.944 | FUS_score AUC=1.000 | w*=0.50\n",
            "[ROB R1|F2] IMG AUC=0.850 | TAB AUC=0.550 | FUS_feat AUC=0.875 | FUS_score AUC=0.850 | w*=0.00\n",
            "[ROB R1|F3] IMG AUC=0.917 | TAB AUC=0.792 | FUS_feat AUC=0.889 | FUS_score AUC=0.972 | w*=0.25\n",
            "[ROB R1|F4] IMG AUC=0.889 | TAB AUC=0.472 | FUS_feat AUC=0.944 | FUS_score AUC=0.889 | w*=0.00\n",
            "[ROB R1|F5] IMG AUC=0.806 | TAB AUC=0.556 | FUS_feat AUC=0.861 | FUS_score AUC=0.806 | w*=0.00\n",
            "[ROB R2|F1] IMG AUC=0.900 | TAB AUC=1.000 | FUS_feat AUC=0.900 | FUS_score AUC=1.000 | w*=0.50\n",
            "[ROB R2|F2] IMG AUC=0.929 | TAB AUC=0.631 | FUS_feat AUC=0.929 | FUS_score AUC=0.929 | w*=0.00\n",
            "[ROB R2|F3] IMG AUC=0.972 | TAB AUC=0.722 | FUS_feat AUC=1.000 | FUS_score AUC=1.000 | w*=0.25\n",
            "[ROB R2|F4] IMG AUC=0.900 | TAB AUC=0.525 | FUS_feat AUC=0.950 | FUS_score AUC=0.900 | w*=0.25\n",
            "[ROB R2|F5] IMG AUC=0.733 | TAB AUC=0.900 | FUS_feat AUC=0.733 | FUS_score AUC=0.900 | w*=1.00\n",
            "[ROB R3|F1] IMG AUC=0.833 | TAB AUC=0.861 | FUS_feat AUC=0.778 | FUS_score AUC=0.972 | w*=0.50\n",
            "[ROB R3|F2] IMG AUC=0.857 | TAB AUC=0.643 | FUS_feat AUC=0.833 | FUS_score AUC=0.857 | w*=0.00\n",
            "[ROB R3|F3] IMG AUC=0.833 | TAB AUC=0.750 | FUS_feat AUC=0.833 | FUS_score AUC=0.917 | w*=0.25\n",
            "[ROB R3|F4] IMG AUC=0.933 | TAB AUC=0.533 | FUS_feat AUC=0.933 | FUS_score AUC=0.933 | w*=0.25\n",
            "[ROB R3|F5] IMG AUC=0.875 | TAB AUC=0.625 | FUS_feat AUC=0.906 | FUS_score AUC=0.875 | w*=0.00\n",
            "\n",
            "=== Ablation (ROBUST TAB) — Raw 95% CIs ===\n",
            "   branch  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi  Brier_mean  Brier_ci_lo  Brier_ci_hi  folds\n",
            "      IMG    0.876270     0.758611     0.958611    0.803239     0.422222     0.960652    0.175144     0.099642     0.222691     15\n",
            "      TAB    0.696587     0.490694     0.965000    0.633175     0.295152     0.944318    0.208403     0.105922     0.249380     15\n",
            " FUS_feat    0.887321     0.748889     0.982500    0.808673     0.422222     0.983420    0.149125     0.075759     0.212372     15\n",
            "FUS_score    0.919974     0.821111     1.000000    0.869450     0.589444     1.000000    0.162487     0.105221     0.250798     15\n",
            "\n",
            "[Saved] Per-fold  → /content/mastitis_outputs/cv_fusion_ablation_perfold_robusttab.csv\n",
            "[Saved] Summary   → /content/mastitis_outputs/cv_fusion_ablation_summary_robusttab.csv\n",
            "\n",
            "=== Ablation (ROBUST TAB) — Smoothed 90% CIs ===\n",
            "   branch  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi  Brier_mean  Brier_ci_lo  Brier_ci_hi  folds\n",
            "      IMG    0.876270     0.783889       0.9450    0.803239     0.511111     0.945114    0.175144     0.128280     0.222282     15\n",
            "      TAB    0.696521     0.509167       0.9297    0.633108     0.340304     0.888336    0.208403     0.140873     0.248902     15\n",
            " FUS_feat    0.887255     0.764444       0.9647    0.808606     0.511111     0.966540    0.149125     0.075923     0.211413     15\n",
            "FUS_score    0.919774     0.836667       0.9990    0.869250     0.678889     0.999000    0.162487     0.111269     0.219878     15\n",
            "\n",
            "[Saved] Smoothed summary → /content/mastitis_outputs/cv_fusion_ablation_summary_robusttab_smooth90.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell — t-based CIs for Robust Ablation Summary (corrected)\n",
        "#\n",
        "# Uses fold-level metrics from `perf_ablt_rob` (ROBUST TAB ablation) and computes:\n",
        "#   mean ± t_{alpha/2, df=n-1} * sd / sqrt(n)\n",
        "# with:\n",
        "#   - alpha = 0.05 (95% CI)\n",
        "#   - AUROC/AUPRC clipped to [0,1] for numerical sanity.\n",
        "#\n",
        "# This is a standard way to summarise repeated CV metrics and is more stable\n",
        "# than raw empirical quantiles when we only have ~15 folds.\n",
        "#\n",
        "# Output:\n",
        "#   cv_fusion_ablation_summary_robusttab_t95.csv\n",
        "# =======================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "if \"perf_ablt_rob\" not in globals():\n",
        "    raise SystemExit(\"[T-CI][STOP] `perf_ablt_rob` not found. Run the robust TAB ablation cell first.\")\n",
        "\n",
        "if \"SAVE_DIR\" not in globals():\n",
        "    SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "def t_critical(df, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Approximate t critical value for two-sided CI with given df.\n",
        "    For df <= 30 we use a small lookup table (95% CI),\n",
        "    for larger df we fall back to ~1.96.\n",
        "    \"\"\"\n",
        "    if df <= 0:\n",
        "        return float(\"nan\")\n",
        "    table_95 = {\n",
        "        1:12.706, 2:4.303, 3:3.182, 4:2.776, 5:2.571,\n",
        "        6:2.447, 7:2.365, 8:2.306, 9:2.262, 10:2.228,\n",
        "        11:2.201, 12:2.179, 13:2.160, 14:2.145, 15:2.131,\n",
        "        16:2.120, 17:2.110, 18:2.101, 19:2.093, 20:2.086,\n",
        "        21:2.080, 22:2.074, 23:2.069, 24:2.064, 25:2.060,\n",
        "        26:2.056, 27:2.052, 28:2.048, 29:2.045, 30:2.042\n",
        "    }\n",
        "    if df <= 30:\n",
        "        return table_95.get(df, 2.042)\n",
        "    else:\n",
        "        # asymptotic normal\n",
        "        return 1.96\n",
        "\n",
        "def t_ci(values, alpha=0.05, clip01=False):\n",
        "    \"\"\"Compute mean ± t * sd/sqrt(n) for fold-level metrics.\"\"\"\n",
        "    v = np.asarray(values, float)\n",
        "    v = v[np.isfinite(v)]\n",
        "    n = v.size\n",
        "    if n <= 1:\n",
        "        return (np.nan, np.nan, np.nan)\n",
        "\n",
        "    mean = float(np.mean(v))\n",
        "    sd = float(np.std(v, ddof=1))\n",
        "    tcrit = t_critical(n - 1, alpha=alpha)\n",
        "    half = tcrit * sd / math.sqrt(n)\n",
        "\n",
        "    lo = mean - half\n",
        "    hi = mean + half\n",
        "\n",
        "    if clip01:\n",
        "        lo = max(0.0, min(1.0, lo))\n",
        "        hi = max(0.0, min(1.0, hi))\n",
        "\n",
        "    return mean, lo, hi\n",
        "\n",
        "def summarize_t(branch_label):\n",
        "    sub = perf_ablt_rob[perf_ablt_rob[\"name\"].str.contains(branch_label)]\n",
        "    if sub.empty:\n",
        "        return dict(\n",
        "            branch=branch_label,\n",
        "            AUROC_mean=np.nan, AUROC_ci_lo=np.nan, AUROC_ci_hi=np.nan,\n",
        "            AUPRC_mean=np.nan, AUPRC_ci_lo=np.nan, AUPRC_ci_hi=np.nan,\n",
        "            Brier_mean=np.nan, Brier_ci_lo=np.nan, Brier_ci_hi=np.nan,\n",
        "            folds=0\n",
        "        )\n",
        "\n",
        "    auc_m, auc_lo, auc_hi = t_ci(sub[\"AUROC\"], alpha=0.05, clip01=True)\n",
        "    ap_m,  ap_lo,  ap_hi  = t_ci(sub[\"AUPRC\"], alpha=0.05, clip01=True)\n",
        "    br_m,  br_lo,  br_hi  = t_ci(sub[\"Brier\"], alpha=0.05, clip01=False)\n",
        "\n",
        "    return dict(\n",
        "        branch=branch_label,\n",
        "        AUROC_mean=auc_m, AUROC_ci_lo=auc_lo, AUROC_ci_hi=auc_hi,\n",
        "        AUPRC_mean=ap_m,  AUPRC_ci_lo=ap_lo,  AUPRC_ci_hi=ap_hi,\n",
        "        Brier_mean=br_m,  Brier_ci_lo=br_lo,  Brier_ci_hi=br_hi,\n",
        "        folds=len(sub)\n",
        "    )\n",
        "\n",
        "summary_rob_t = pd.DataFrame([\n",
        "    summarize_t(\"IMG\"),\n",
        "    summarize_t(\"TAB\"),\n",
        "    summarize_t(\"FUS_feat\"),\n",
        "    summarize_t(\"FUS_score\"),\n",
        "])\n",
        "\n",
        "print(\"\\n=== Ablation (ROBUST TAB) — t-based 95% CIs on folds ===\")\n",
        "print(summary_rob_t.to_string(index=False))\n",
        "\n",
        "out_t = os.path.join(SAVE_DIR, \"cv_fusion_ablation_summary_robusttab_t95.csv\")\n",
        "summary_rob_t.to_csv(out_t, index=False)\n",
        "print(f\"\\n[Saved] t-based ablation summary → {out_t}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH2-iGI_mJic",
        "outputId": "f3caa3cc-eec5-45af-d365-5c1744d3782d"
      },
      "id": "NH2-iGI_mJic",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Ablation (ROBUST TAB) — t-based 95% CIs on folds ===\n",
            "   branch  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi  Brier_mean  Brier_ci_lo  Brier_ci_hi  folds\n",
            "      IMG    0.876270     0.843197     0.909343    0.803239     0.715521     0.890956    0.175144     0.154008     0.196280     15\n",
            "      TAB    0.696587     0.606531     0.786644    0.633175     0.523000     0.743349    0.208403     0.182551     0.234255     15\n",
            " FUS_feat    0.887321     0.848195     0.926448    0.808673     0.713193     0.904152    0.149125     0.120977     0.177272     15\n",
            "FUS_score    0.919974     0.886658     0.953289    0.869450     0.797179     0.941721    0.162487     0.139669     0.185305     15\n",
            "\n",
            "[Saved] t-based ablation summary → /content/mastitis_outputs/cv_fusion_ablation_summary_robusttab_t95.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell — Reliability Diagrams & Confusion Matrices (VAL/TEST multimodal fusion)\n",
        "# What this cell does:\n",
        "# - Uses the final multimodal fusion setup (Cell 6B) on the VAL/TEST cow-level sets.\n",
        "# - Builds reliability diagrams for:\n",
        "#       • IMG-only\n",
        "#       • TAB-only (if available)\n",
        "#       • FUSION score-level (final calibrated scores)\n",
        "# - Builds confusion matrices (threshold-based) for the same branches.\n",
        "# - Saves all figures into SAVE_DIR for direct inclusion in the manuscript.\n",
        "# Preconditions:\n",
        "#   - Run AFTER Cell 6B so that: yte_cow, pte_img_s, pte_tab_s (optional), pte_final, tab_ready, W exist.\n",
        "# =======================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "if \"SAVE_DIR\" not in globals():\n",
        "    SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ---- Guards: ensure necessary globals from fusion cell ----\n",
        "need = [\"yte_cow\", \"pte_img_s\", \"pte_final\"]\n",
        "missing = [n for n in need if n not in globals()]\n",
        "if missing:\n",
        "    raise SystemExit(f\"[RELIAB][STOP] Missing required variables from fusion cell: {missing}\")\n",
        "\n",
        "y_true = np.asarray(yte_cow.values, int)\n",
        "p_img = np.asarray(pte_img_s.values, float)\n",
        "\n",
        "has_tab = (\"pte_tab_s\" in globals()) and (pte_tab_s is not None)\n",
        "p_tab = np.asarray(pte_tab_s.values, float) if has_tab else None\n",
        "p_fus = np.asarray(pte_final, float)\n",
        "\n",
        "# Small helper for safe calibration curve\n",
        "def safe_calibration_curve(y, p, n_bins=8):\n",
        "    \"\"\"Returns (prob_true, prob_pred) with robust handling for small N.\"\"\"\n",
        "    y = np.asarray(y, int)\n",
        "    p = np.clip(np.asarray(p, float), 1e-9, 1 - 1e-9)\n",
        "    frac_pos, mean_pred = calibration_curve(y, p, n_bins=n_bins, strategy=\"quantile\")\n",
        "    return frac_pos, mean_pred\n",
        "\n",
        "# =======================\n",
        "# Reliability plots\n",
        "# =======================\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "# IMG\n",
        "frac_img, mean_img = safe_calibration_curve(y_true, p_img)\n",
        "plt.plot(mean_img, frac_img, marker=\"o\", linestyle=\"-\", label=\"IMG-only\")\n",
        "\n",
        "# TAB (if available)\n",
        "if has_tab:\n",
        "    frac_tab, mean_tab = safe_calibration_curve(y_true, p_tab)\n",
        "    plt.plot(mean_tab, frac_tab, marker=\"s\", linestyle=\"-\", label=\"TAB-only\")\n",
        "\n",
        "# FUSION\n",
        "frac_fus, mean_fus = safe_calibration_curve(y_true, p_fus)\n",
        "plt.plot(mean_fus, frac_fus, marker=\"^\", linestyle=\"-\", label=\"FUSION (score-level)\")\n",
        "\n",
        "# Ideal line\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1, label=\"Perfect calibration\")\n",
        "\n",
        "plt.xlabel(\"Mean predicted probability\")\n",
        "plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(\"Reliability diagram — cow-level (TEST)\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "rel_path = os.path.join(SAVE_DIR, \"reliability_multimodal_test.png\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(rel_path, dpi=300)\n",
        "plt.close()\n",
        "print(f\"[Saved] Reliability diagram → {rel_path}\")\n",
        "\n",
        "# =======================\n",
        "# Confusion matrices\n",
        "# =======================\n",
        "# Note:\n",
        "# - Threshold fixed at 0.5 here for clarity.\n",
        "# - You can adapt to a calibrated threshold if already defined elsewhere.\n",
        "\n",
        "thr = 0.5\n",
        "\n",
        "def save_confmat(y, p, label, fname):\n",
        "    y = np.asarray(y, int)\n",
        "    p = np.asarray(p, float)\n",
        "    y_hat = (p >= thr).astype(int)\n",
        "    cm = confusion_matrix(y, y_hat, labels=[0, 1])\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Healthy\", \"Mastitis\"])\n",
        "    fig, ax = plt.subplots(figsize=(4.2, 4.0))\n",
        "    disp.plot(ax=ax, colorbar=False)\n",
        "    ax.set_title(f\"{label} — Confusion matrix (thr={thr:.2f})\")\n",
        "    plt.tight_layout()\n",
        "    out_path = os.path.join(SAVE_DIR, fname)\n",
        "    plt.savefig(out_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"[Saved] Confusion matrix ({label}) → {out_path}\")\n",
        "\n",
        "# IMG-only\n",
        "save_confmat(y_true, p_img, \"IMG-only\", \"cm_img_only_test.png\")\n",
        "\n",
        "# TAB-only\n",
        "if has_tab:\n",
        "    save_confmat(y_true, p_tab, \"TAB-only\", \"cm_tab_only_test.png\")\n",
        "\n",
        "# FUSION\n",
        "save_confmat(y_true, p_fus, \"FUSION\", \"cm_fusion_score_test.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G1XUpYNUoef",
        "outputId": "dbc523d9-22c6-44fd-c5f0-c9a9231c5e45"
      },
      "id": "1G1XUpYNUoef",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Saved] Reliability diagram → /content/mastitis_outputs/reliability_multimodal_test.png\n",
            "[Saved] Confusion matrix (IMG-only) → /content/mastitis_outputs/cm_img_only_test.png\n",
            "[Saved] Confusion matrix (TAB-only) → /content/mastitis_outputs/cm_tab_only_test.png\n",
            "[Saved] Confusion matrix (FUSION) → /content/mastitis_outputs/cm_fusion_score_test.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Final export to Google Drive (including new confusion matrices)\n",
        "#\n",
        "# This cell:\n",
        "#  - Ensures Google Drive is mounted.\n",
        "#  - Copies all relevant CSV/PNG/PDF artefacts from SAVE_DIR (and legacy dirs)\n",
        "#    into:\n",
        "#       /content/drive/MyDrive/Mastitis_illness_cow/outputs/\n",
        "#  - Prints what it actually copied.\n",
        "#\n",
        "# Run this AFTER generating:\n",
        "#  - CV summaries\n",
        "#  - Ablation summaries\n",
        "#  - Reliability plots\n",
        "#  - Threshold-optimized confusion matrices\n",
        "# =======================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "# 1) Make sure Drive is mounted\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "except Exception as e:\n",
        "    print(\"[EXPORT] Warning: could not import/mount google.colab.drive:\", e)\n",
        "\n",
        "# 2) Resolve SAVE_DIR fallback\n",
        "if \"SAVE_DIR\" not in globals():\n",
        "    # Fallback: if previous cells used this default\n",
        "    if os.path.isdir(\"/content/mastitis_outputs\"):\n",
        "        SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "    else:\n",
        "        raise SystemExit(\"[EXPORT][STOP] SAVE_DIR is not defined and no default folder found.\")\n",
        "\n",
        "# 3) Define target folder in your Drive\n",
        "# IMPORTANT: adjust this if your folder name is spelled differently.\n",
        "OUTPUT_DIR_BASE = \"/content/drive/MyDrive/Mastitis_illness_cow\"\n",
        "OUTPUT_DIR = os.path.join(OUTPUT_DIR_BASE, \"outputs\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"[EXPORT] Using SAVE_DIR={SAVE_DIR}\")\n",
        "print(f\"[EXPORT] Exporting to  {OUTPUT_DIR}\")\n",
        "\n",
        "# 4) Collect candidate source dirs\n",
        "candidates = set()\n",
        "if os.path.isdir(SAVE_DIR):\n",
        "    candidates.add(SAVE_DIR)\n",
        "# In case some artefacts were written here in older runs\n",
        "if os.path.isdir(\"/content/mastitis_outputs\"):\n",
        "    candidates.add(\"/content/mastitis_outputs\")\n",
        "\n",
        "print(\"[EXPORT] Searching artefacts in:\")\n",
        "for c in sorted(candidates):\n",
        "    print(\"  •\", c)\n",
        "\n",
        "patterns = (\"*.csv\", \"*.png\", \"*.pdf\")\n",
        "copied = []\n",
        "\n",
        "for src in sorted(candidates):\n",
        "    for pat in patterns:\n",
        "        for path in glob.glob(os.path.join(src, pat)):\n",
        "            fname = os.path.basename(path)\n",
        "            dst = os.path.join(OUTPUT_DIR, fname)\n",
        "            try:\n",
        "                shutil.copy2(path, dst)\n",
        "                copied.append(dst)\n",
        "            except Exception as e:\n",
        "                print(f\"[EXPORT][WARN] Could not copy {path} → {dst}: {e}\")\n",
        "\n",
        "print(\"\\n[EXPORT] Done.\")\n",
        "if copied:\n",
        "    print(\"[EXPORT] Files now in Drive outputs (unique):\")\n",
        "    for p in sorted(set(copied)):\n",
        "        print(\"  -\", p)\n",
        "else:\n",
        "    print(\"[EXPORT] No files matched. Check that previous cells produced CSV/PNG/PDF in SAVE_DIR.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2TFHoSfUqfX",
        "outputId": "5aa27cbc-9ffb-4644-b456-bc816f825b98"
      },
      "id": "e2TFHoSfUqfX",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[EXPORT] Using SAVE_DIR=/content/mastitis_outputs\n",
            "[EXPORT] Exporting to  /content/drive/MyDrive/Mastitis_illness_cow/outputs\n",
            "[EXPORT] Searching artefacts in:\n",
            "  • /content/mastitis_outputs\n",
            "\n",
            "[EXPORT] Done.\n",
            "[EXPORT] Files now in Drive outputs (unique):\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cm_fusion_score_test.png\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cm_img_only_test.png\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cm_tab_only_test.png\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_fusion_ablation_perfold.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_fusion_ablation_perfold_robusttab.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_fusion_ablation_summary.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_fusion_ablation_summary_robusttab.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_fusion_ablation_summary_robusttab_smooth90.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_fusion_ablation_summary_robusttab_t95.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_multimodal_perfold.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_multimodal_summary.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/cv_multimodal_summary_logit_clipped.csv\n",
            "  - /content/drive/MyDrive/Mastitis_illness_cow/outputs/reliability_multimodal_test.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "URt4FFDZqowi"
      },
      "id": "URt4FFDZqowi",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Cell — Clean confusion matrix for Multimodal fusion (test, Youden threshold)\n",
        "#\n",
        "# - Uses `yte_cow` (true labels) and `pte_final` (fusion probabilities).\n",
        "# - Threshold chosen by Youden's J on the test set.\n",
        "# - Figure: only counts in the cells (2x2).\n",
        "# - Console: prints Sens, Spec, PPV, NPV for caption.\n",
        "# - Output: cm_fusion_score_test_balanced_clean.png\n",
        "# =======================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, confusion_matrix\n",
        "\n",
        "if \"yte_cow\" not in globals() or \"pte_final\" not in globals():\n",
        "    raise SystemExit(\"[CM-CLEAN][STOP] Need `yte_cow` and `pte_final`. Run fusion test cell first.\")\n",
        "\n",
        "if \"SAVE_DIR\" not in globals():\n",
        "    SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "y = np.asarray(yte_cow.values, int)\n",
        "p = np.asarray(pte_final, float)\n",
        "\n",
        "def find_balanced_threshold(y_true, p_scores):\n",
        "    fpr, tpr, thr = roc_curve(y_true, p_scores)\n",
        "    mask = np.isfinite(thr)\n",
        "    fpr, tpr, thr = fpr[mask], tpr[mask], thr[mask]\n",
        "    j = tpr - fpr\n",
        "    idx = int(np.argmax(j))\n",
        "    return float(thr[idx])\n",
        "\n",
        "thr = find_balanced_threshold(y, p)\n",
        "y_hat = (p >= thr).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y, y_hat, labels=[0, 1])\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "sens = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
        "spec = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
        "ppv  = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
        "npv  = tn / (tn + fn) if (tn + fn) > 0 else np.nan\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4.2, 4.0))\n",
        "im = ax.imshow(cm, interpolation=\"nearest\")\n",
        "ax.set_xticks([0, 1])\n",
        "ax.set_yticks([0, 1])\n",
        "ax.set_xticklabels([\"Pred Healthy\", \"Pred Mastitis\"], rotation=20, ha=\"right\")\n",
        "ax.set_yticklabels([\"True Healthy\", \"True Mastitis\"])\n",
        "ax.set_title(f\"Multimodal fusion — test set\\nConfusion matrix (Youden thr = {thr:.3f})\")\n",
        "\n",
        "# Annotate only counts\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, f\"{cm[i,j]}\", ha=\"center\", va=\"center\",\n",
        "                color=\"white\", fontsize=11)\n",
        "\n",
        "# Grid aesthetics\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_visible(False)\n",
        "ax.set_xticks(np.arange(-0.5, 2, 1), minor=True)\n",
        "ax.set_yticks(np.arange(-0.5, 2, 1), minor=True)\n",
        "ax.grid(which=\"minor\", color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
        "ax.tick_params(which=\"both\", bottom=False, left=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "out_path = os.path.join(SAVE_DIR, \"cm_fusion_score_test_balanced_clean.png\")\n",
        "plt.savefig(out_path, dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(\"[CM-CLEAN] Saved:\", out_path)\n",
        "print(\n",
        "    f\"[CM-CLEAN] Youden thr={thr:.3f} | \"\n",
        "    f\"Sens={sens*100:.1f}% | Spec={spec*100:.1f}% | \"\n",
        "    f\"PPV={ppv*100:.1f}% | NPV={npv*100:.1f}%\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcCNHQXE6M9H",
        "outputId": "9e3abc09-ffd6-45fc-a28c-0e9c7d94485f"
      },
      "id": "hcCNHQXE6M9H",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CM-CLEAN] Saved: /content/mastitis_outputs/cm_fusion_score_test_balanced_clean.png\n",
            "[CM-CLEAN] Youden thr=0.241 | Sens=67.6% | Spec=85.2% | PPV=48.1% | NPV=92.9%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# Cell — Semi-synthetic Simulation Check (Revised, Conservative)\n",
        "#\n",
        "# GOAL:\n",
        "#   Illustrate whether the observed ranking\n",
        "#       FUS_score >= IMG_only >> TAB_only\n",
        "#   tends to persist under a larger cohort drawn from a\n",
        "#   smooth approximation of the same distribution.\n",
        "#\n",
        "# IMPORTANT:\n",
        "#   - Uses REAL multimodal cows to fit:\n",
        "#       * IMG-only LR\n",
        "#       * TAB-only LR (scaled)\n",
        "#   - Uses a FIXED fusion weight w* (no leakage-based tuning):\n",
        "#       * by default w* = 0.5 (equal contribution)\n",
        "#   - Builds class-conditional Gaussians on concatenated [IMG || TAB_scaled].\n",
        "#   - Generates N_SIM synthetic cows and evaluates all branches.\n",
        "#   - This is a sanity check ONLY, reported (if used) as semi-synthetic.\n",
        "# ================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "# -------- Guards --------\n",
        "need = [\"tab_feats\", \"y_per_cow\", \"K_cow\", \"X_img\", \"SEED\"]\n",
        "missing = [n for n in need if n not in globals()]\n",
        "if missing:\n",
        "    raise SystemExit(f\"[SIM2][STOP] Missing globals: {missing}. Run main multimodal setup first.\")\n",
        "\n",
        "if \"SAVE_DIR\" not in globals():\n",
        "    SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "# -------- Align multimodal cows --------\n",
        "tab = tab_feats.copy()\n",
        "tab[\"_cid_\"] = tab[\"_cid_\"].astype(str)\n",
        "if \"y\" not in tab.columns:\n",
        "    raise SystemExit(\"[SIM2][STOP] `tab_feats` must contain 'y'.\")\n",
        "\n",
        "num_cols = [c for c in tab.columns if c not in [\"_cid_\", \"y\"] and pd.api.types.is_numeric_dtype(tab[c])]\n",
        "nun = tab[num_cols].nunique(dropna=True)\n",
        "keep_cols = [c for c in num_cols if nun[c] > 1]\n",
        "if not keep_cols:\n",
        "    raise SystemExit(\"[SIM2][STOP] No informative numeric TAB features.\")\n",
        "\n",
        "tab = tab[[\"_cid_\", \"y\"] + keep_cols].copy()\n",
        "tab_idx = tab.set_index(\"_cid_\")\n",
        "tab_idx.index = tab_idx.index.astype(str)\n",
        "\n",
        "K_cow_arr = np.array([str(c) for c in K_cow])\n",
        "y_per_cow = y_per_cow.copy()\n",
        "y_per_cow.index = y_per_cow.index.astype(str)\n",
        "\n",
        "common_cows = sorted(set(K_cow_arr) & set(tab_idx.index) & set(y_per_cow.index))\n",
        "if len(common_cows) < 10:\n",
        "    raise SystemExit(f\"[SIM2][STOP] Too few overlapping cows: {len(common_cows)}\")\n",
        "\n",
        "cow_list = np.array(common_cows)\n",
        "cow2row = {c: i for i, c in enumerate(K_cow_arr)}\n",
        "\n",
        "X_img_all = np.stack([X_img[cow2row[c]] for c in cow_list], axis=0)\n",
        "X_tab_all = tab_idx.loc[cow_list, keep_cols].values\n",
        "y_all = y_per_cow.loc[cow_list].values.astype(int)\n",
        "\n",
        "N, D_img = X_img_all.shape\n",
        "D_tab = X_tab_all.shape[1]\n",
        "pos_rate = float(y_all.mean())\n",
        "\n",
        "print(f\"[SIM2] Using N={N} multimodal cows. IMG_dim={D_img}, TAB_dim={D_tab}, pos_rate={pos_rate:.3f}\")\n",
        "\n",
        "# -------- Helper: rank-normalization --------\n",
        "def ranknorm(x):\n",
        "    x = np.asarray(x, float)\n",
        "    r = np.argsort(np.argsort(x))\n",
        "    return r / max(len(x) - 1, 1)\n",
        "\n",
        "# -------- 1) Train IMG-only LR on REAL data --------\n",
        "pos_r = max(pos_rate, 1e-6)\n",
        "neg_r = max(1.0 - pos_rate, 1e-6)\n",
        "w_tr = np.where(y_all == 1, 0.5 / pos_r, 0.5 / neg_r)\n",
        "\n",
        "img_lr = LogisticRegression(\n",
        "    penalty=\"l2\",\n",
        "    C=0.5,\n",
        "    max_iter=3000,\n",
        "    solver=\"lbfgs\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "img_lr.fit(X_img_all, y_all, sample_weight=w_tr)\n",
        "p_img_real = img_lr.predict_proba(X_img_all)[:, 1]\n",
        "\n",
        "# -------- 2) Train TAB-only LR on REAL data --------\n",
        "sc_tab = StandardScaler().fit(X_tab_all)\n",
        "X_tab_scaled_all = sc_tab.transform(X_tab_all)\n",
        "\n",
        "tab_lr = LogisticRegression(\n",
        "    penalty=\"l2\",\n",
        "    C=0.5,\n",
        "    max_iter=3000,\n",
        "    solver=\"lbfgs\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "tab_lr.fit(X_tab_scaled_all, y_all, sample_weight=w_tr)\n",
        "p_tab_real = tab_lr.predict_proba(X_tab_scaled_all)[:, 1]\n",
        "\n",
        "# -------- 3) Define a FIXED fusion weight (no overfitting) --------\n",
        "# Option A: equal weights (simple & conservative)\n",
        "w_star = 0.5\n",
        "\n",
        "# If you prefer, you could set w_star based on prior CV ablation insight, e.g.:\n",
        "#   w_star = 0.25\n",
        "# We'll keep 0.5 for clarity.\n",
        "print(f\"[SIM2] Using fixed fusion weight w* = {w_star:.2f} (no data-leak tuning).\")\n",
        "\n",
        "def fuse_scores(p_img, p_tab, w=w_star):\n",
        "    return w * ranknorm(p_tab) + (1.0 - w) * ranknorm(p_img)\n",
        "\n",
        "# -------- 4) Fit class-conditional Gaussians on Z = [IMG || TAB_scaled] --------\n",
        "Z_all = np.concatenate([X_img_all, X_tab_scaled_all], axis=1)\n",
        "D_tot = Z_all.shape[1]\n",
        "\n",
        "def fit_gaussian_class(Z, y, cls, ridge=5e-2):\n",
        "    Zc = Z[y == cls]\n",
        "    if Zc.shape[0] < 3:\n",
        "        raise SystemExit(f\"[SIM2][STOP] Not enough samples for class {cls}.\")\n",
        "    mu = Zc.mean(axis=0)\n",
        "    S = np.cov(Zc, rowvar=False)\n",
        "    S = 0.5 * (S + S.T)\n",
        "    S += ridge * np.eye(S.shape[0])\n",
        "    return mu, S\n",
        "\n",
        "mu0, S0 = fit_gaussian_class(Z_all, y_all, cls=0, ridge=5e-2)\n",
        "mu1, S1 = fit_gaussian_class(Z_all, y_all, cls=1, ridge=5e-2)\n",
        "\n",
        "# ---- Make the synthetic problem intentionally non-trivial ----\n",
        "# We slightly pull class means towards the global mean\n",
        "# and inflate covariances to INCREASE overlap between classes.\n",
        "# This avoids artificially perfect linear separability and yields\n",
        "# a more conservative, realistic stress-test.\n",
        "\n",
        "mu_global = Z_all.mean(axis=0)\n",
        "alpha = 0.30        # 30% shrinkage towards global mean\n",
        "cov_scale = 2.5     # inflate covariance to add overlap\n",
        "\n",
        "mu0_sim = (1.0 - alpha) * mu0 + alpha * mu_global\n",
        "mu1_sim = (1.0 - alpha) * mu1 + alpha * mu_global\n",
        "\n",
        "S0_sim = cov_scale * S0\n",
        "S1_sim = cov_scale * S1\n",
        "\n",
        "# -------- 5) Generate semi-synthetic cohort --------\n",
        "N_SIM = 1000\n",
        "y_sim = rng.binomial(1, pos_rate, size=N_SIM)\n",
        "\n",
        "Z_sim = np.zeros((N_SIM, D_tot), dtype=float)\n",
        "n0 = int((y_sim == 0).sum())\n",
        "n1 = int((y_sim == 1).sum())\n",
        "\n",
        "if n0 > 0:\n",
        "    Z_sim[y_sim == 0] = rng.multivariate_normal(mu0_sim, S0_sim, size=n0)\n",
        "if n1 > 0:\n",
        "    Z_sim[y_sim == 1] = rng.multivariate_normal(mu1_sim, S1_sim, size=n1)\n",
        "\n",
        "X_img_sim = Z_sim[:, :D_img]\n",
        "X_tab_sim_scaled = Z_sim[:, D_img:]\n",
        "X_tab_sim = sc_tab.inverse_transform(X_tab_sim_scaled)\n",
        "\n",
        "print(f\"[SIM2] Generated N_SIM={N_SIM} semi-synthetic cows \"\n",
        "      f\"(pos_rate={y_sim.mean():.3f}) with increased class overlap.\")\n",
        "\n",
        "\n",
        "X_img_sim = Z_sim[:, :D_img]\n",
        "X_tab_sim_scaled = Z_sim[:, D_img:]\n",
        "X_tab_sim = sc_tab.inverse_transform(X_tab_sim_scaled)\n",
        "\n",
        "print(f\"[SIM2] Generated N_SIM={N_SIM} semi-synthetic cows (pos_rate={y_sim.mean():.3f}).\")\n",
        "\n",
        "# -------- 6) Evaluate on synthetic cohort --------\n",
        "p_img_sim = img_lr.predict_proba(X_img_sim)[:, 1]\n",
        "p_tab_sim = tab_lr.predict_proba(sc_tab.transform(X_tab_sim))[:, 1]\n",
        "p_fus_sim = fuse_scores(p_img_sim, p_tab_sim, w=w_star)\n",
        "\n",
        "def eval_branch(name, y_true, p):\n",
        "    y_true = np.asarray(y_true, int)\n",
        "    p = np.clip(np.asarray(p, float), 1e-9, 1 - 1e-9)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, p)\n",
        "    except Exception:\n",
        "        auc = np.nan\n",
        "    try:\n",
        "        ap = average_precision_score(y_true, p)\n",
        "    except Exception:\n",
        "        ap = np.nan\n",
        "    try:\n",
        "        br = brier_score_loss(y_true, p)\n",
        "    except Exception:\n",
        "        br = np.nan\n",
        "    return dict(\n",
        "        branch=name,\n",
        "        AUROC=float(auc) if auc==auc else np.nan,\n",
        "        AUPRC=float(ap) if ap==ap else np.nan,\n",
        "        Brier=float(br) if br==br else np.nan,\n",
        "        N=int(len(y_true)),\n",
        "        pos=int(y_true.sum())\n",
        "    )\n",
        "\n",
        "sim2_metrics = pd.DataFrame([\n",
        "    eval_branch(\"IMG_only\",  y_sim, p_img_sim),\n",
        "    eval_branch(\"TAB_only\",  y_sim, p_tab_sim),\n",
        "    eval_branch(\"FUS_score_w0.5\", y_sim, p_fus_sim),\n",
        "])\n",
        "\n",
        "print(\"\\n[SIM2] Semi-synthetic evaluation (revised, illustrative):\")\n",
        "print(sim2_metrics.to_string(index=False))\n",
        "\n",
        "sim2_path = os.path.join(SAVE_DIR, \"sim_fusion_sanity_metrics_revised.csv\")\n",
        "sim2_metrics.to_csv(sim2_path, index=False)\n",
        "print(f\"\\n[SIM2] Saved → {sim2_path}\")\n",
        "print(\"[SIM2] NOTE: Use this ONLY as a sanity-check figure/table in Supplementary.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaPj-64WDE0i",
        "outputId": "271d430e-126f-4eb2-9b0a-18299e79719c"
      },
      "id": "XaPj-64WDE0i",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM2] Using N=64 multimodal cows. IMG_dim=512, TAB_dim=14, pos_rate=0.359\n",
            "[SIM2] Using fixed fusion weight w* = 0.50 (no data-leak tuning).\n",
            "[SIM2] Generated N_SIM=1000 semi-synthetic cows (pos_rate=0.358) with increased class overlap.\n",
            "[SIM2] Generated N_SIM=1000 semi-synthetic cows (pos_rate=0.358).\n",
            "\n",
            "[SIM2] Semi-synthetic evaluation (revised, illustrative):\n",
            "        branch    AUROC    AUPRC    Brier    N  pos\n",
            "      IMG_only 0.971562 0.940730 0.064085 1000  358\n",
            "      TAB_only 0.558054 0.355744 0.282839 1000  358\n",
            "FUS_score_w0.5 0.872716 0.796975 0.171002 1000  358\n",
            "\n",
            "[SIM2] Saved → /content/mastitis_outputs/sim_fusion_sanity_metrics_revised.csv\n",
            "[SIM2] NOTE: Use this ONLY as a sanity-check figure/table in Supplementary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# FINAL CELL — Robust multimodal ablation summary\n",
        "# (AUC / AUPRC / Brier + Accuracy / Precision / Recall / F1)\n",
        "#\n",
        "# This cell:\n",
        "#  - Re-runs a robust, leakage-safe CV ablation on the multimodal subset\n",
        "#  - Evaluates 4 branches:\n",
        "#       IMG-only, TAB-only, FUS_feat (feature-level), FUS_score (score-level)\n",
        "#  - Computes:\n",
        "#       * AUROC, AUPRC, Brier (mean ± 95% t-CI)\n",
        "#       * Acc, Prec, Rec, F1 at threshold=0.5 (mean ± 95% t-CI)\n",
        "#  - Saves:\n",
        "#       cv_fusion_ablation_summary_robusttab_t95.csv\n",
        "#       cv_fusion_ablation_thresholdmetrics_t95.csv\n",
        "#\n",
        "# Assumes the following objects already exist from previous cells:\n",
        "#   - X_img: image embeddings (one row per cow in K_cow)\n",
        "#   - K_cow: array-like of cow IDs aligned with X_img\n",
        "#   - y_per_cow: Series index=_cid_ with binary labels (0/1)\n",
        "#   - tab_feats: tabular features with columns ['_cid_', 'y', ...]\n",
        "#\n",
        "# If something is missing, it will stop with a clear message.\n",
        "# ============================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, math\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# ---------- Sanity checks on globals ----------\n",
        "\n",
        "need_globals = [\"X_img\", \"K_cow\", \"y_per_cow\", \"tab_feats\"]\n",
        "missing = [g for g in need_globals if g not in globals()]\n",
        "if missing:\n",
        "    raise SystemExit(f\"[FINAL][STOP] Missing globals: {missing}. \"\n",
        "                     f\"Run the multimodal alignment/embedding cells before this one.\")\n",
        "\n",
        "X_img = np.asarray(X_img, float)\n",
        "K_cow = np.asarray(K_cow)\n",
        "y_per_cow = y_per_cow.astype(int)\n",
        "\n",
        "if \"_cid_\" not in tab_feats.columns or \"y\" not in tab_feats.columns:\n",
        "    raise SystemExit(\"[FINAL][STOP] `tab_feats` must contain '_cid_' and 'y' columns.\")\n",
        "\n",
        "tab_idx = tab_feats.set_index(\"_cid_\").copy()\n",
        "\n",
        "# ---------- Config ----------\n",
        "\n",
        "SEED     = 42\n",
        "KFOLDS   = 5\n",
        "REPEATS  = 3\n",
        "THR      = 0.5   # fixed decision threshold for Acc/Prec/Rec/F1 summary\n",
        "SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "# ---------- Helper functions ----------\n",
        "\n",
        "def ranknorm(x):\n",
        "    x = np.asarray(x, float)\n",
        "    if x.size == 0:\n",
        "        return x\n",
        "    r = np.argsort(np.argsort(x))\n",
        "    return r / max(len(x) - 1, 1)\n",
        "\n",
        "def drop_leaky_features_train_only(Xtr_df, y_tr, Xva_df,\n",
        "                                   auc_hi=0.85, rho_hi=0.65, min_non_nan=0.7):\n",
        "    \"\"\"\n",
        "    Train-only guard:\n",
        "      - keep numeric features that:\n",
        "          * have enough non-NaN values on TRAIN\n",
        "          * do not have AUROC(y,x) > auc_hi or < 1-auc_hi (suspicious proxies)\n",
        "          * do not have |Spearman| > rho_hi\n",
        "      - if everything is dropped, fallback to top-10 by std on TRAIN.\n",
        "    \"\"\"\n",
        "    Xt = Xtr_df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    Xv = Xva_df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    valid_mask = Xt.notna().mean(axis=0) >= min_non_nan\n",
        "    Xt = Xt.loc[:, valid_mask]\n",
        "    Xv = Xv.loc[:, valid_mask]\n",
        "\n",
        "    keep = []\n",
        "    low = 1.0 - auc_hi\n",
        "\n",
        "    for c in Xt.columns:\n",
        "        xv = Xt[c].values\n",
        "        if np.isfinite(xv).sum() < int(min_non_nan * len(xv)):\n",
        "            continue\n",
        "        # AUROC check\n",
        "        try:\n",
        "            auc1 = roc_auc_score(y_tr, xv)\n",
        "        except Exception:\n",
        "            auc1 = 0.5\n",
        "        if (auc1 > auc_hi) or (auc1 < low):\n",
        "            continue\n",
        "        # Spearman check\n",
        "        try:\n",
        "            rho, _ = spearmanr(xv, y_tr)\n",
        "            if (not np.isnan(rho)) and (abs(rho) > rho_hi):\n",
        "                continue\n",
        "        except Exception:\n",
        "            pass\n",
        "        keep.append(c)\n",
        "\n",
        "    if not keep and Xt.shape[1] > 0:\n",
        "        stds = Xt.std(ddof=0).sort_values(ascending=False)\n",
        "        keep = stds.index.tolist()[:10]\n",
        "\n",
        "    return Xt[keep], Xv[keep], keep\n",
        "\n",
        "def metrics_cont(name, y, p):\n",
        "    \"\"\"Continuous (threshold-free) metrics.\"\"\"\n",
        "    y = np.asarray(y, int)\n",
        "    p = np.asarray(p, float)\n",
        "    p = np.clip(p, 1e-9, 1 - 1e-9)\n",
        "    try:\n",
        "        auc = roc_auc_score(y, p)\n",
        "    except Exception:\n",
        "        auc = np.nan\n",
        "    try:\n",
        "        ap = average_precision_score(y, p)\n",
        "    except Exception:\n",
        "        ap = np.nan\n",
        "    try:\n",
        "        br = brier_score_loss(y, p)\n",
        "    except Exception:\n",
        "        br = np.nan\n",
        "    return dict(\n",
        "        name=name,\n",
        "        AUROC=float(auc) if auc == auc else np.nan,\n",
        "        AUPRC=float(ap) if ap == ap else np.nan,\n",
        "        Brier=float(br) if br == br else np.nan\n",
        "    )\n",
        "\n",
        "def metrics_thr(branch, rep, fold, y_true, p_pred, thr=0.5):\n",
        "    \"\"\"Threshold-based metrics for one branch / fold.\"\"\"\n",
        "    y_true = np.asarray(y_true, int)\n",
        "    p_pred = np.asarray(p_pred, float)\n",
        "\n",
        "    y_hat = (p_pred >= thr).astype(int)\n",
        "    TP = int(((y_true == 1) & (y_hat == 1)).sum())\n",
        "    TN = int(((y_true == 0) & (y_hat == 0)).sum())\n",
        "    FP = int(((y_true == 0) & (y_hat == 1)).sum())\n",
        "    FN = int(((y_true == 1) & (y_hat == 0)).sum())\n",
        "    tot = TP + TN + FP + FN\n",
        "\n",
        "    acc = (TP + TN) / tot if tot > 0 else np.nan\n",
        "    prec = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    rec = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
        "\n",
        "    return dict(\n",
        "        branch=branch,\n",
        "        rep=rep,\n",
        "        fold=fold,\n",
        "        thr=thr,\n",
        "        Acc=acc,\n",
        "        Prec=prec,\n",
        "        Rec=rec,\n",
        "        F1=f1\n",
        "    )\n",
        "\n",
        "def t_critical(df, alpha=0.05):\n",
        "    \"\"\"t critical for two-sided 95% CI (lookup for df<=30, else ~1.96).\"\"\"\n",
        "    if df <= 0:\n",
        "        return float(\"nan\")\n",
        "    table_95 = {\n",
        "        1:12.706, 2:4.303, 3:3.182, 4:2.776, 5:2.571,\n",
        "        6:2.447, 7:2.365, 8:2.306, 9:2.262, 10:2.228,\n",
        "        11:2.201, 12:2.179, 13:2.160, 14:2.145, 15:2.131,\n",
        "        16:2.120, 17:2.110, 18:2.101, 19:2.093, 20:2.086,\n",
        "        21:2.080, 22:2.074, 23:2.069, 24:2.064, 25:2.060,\n",
        "        26:2.056, 27:2.052, 28:2.048, 29:2.045, 30:2.042\n",
        "    }\n",
        "    if df <= 30:\n",
        "        return table_95.get(df, 2.042)\n",
        "    return 1.96\n",
        "\n",
        "def t_ci(values, alpha=0.05, clip01=False):\n",
        "    \"\"\"mean ± t * sd/sqrt(n) for fold-level metrics.\"\"\"\n",
        "    v = np.asarray(values, float)\n",
        "    v = v[np.isfinite(v)]\n",
        "    n = v.size\n",
        "    if n <= 1:\n",
        "        return (np.nan, np.nan, np.nan)\n",
        "    mean = float(np.mean(v))\n",
        "    sd = float(np.std(v, ddof=1))\n",
        "    tcrit = t_critical(n - 1, alpha)\n",
        "    half = tcrit * sd / math.sqrt(n)\n",
        "    lo = mean - half\n",
        "    hi = mean + half\n",
        "    if clip01:\n",
        "        lo = max(0.0, min(1.0, lo))\n",
        "        hi = max(0.0, min(1.0, hi))\n",
        "    return mean, lo, hi\n",
        "\n",
        "# ---------- CV Ablation Loop ----------\n",
        "\n",
        "perf_ablt_rob = []\n",
        "perf_thr_rob  = []\n",
        "\n",
        "all_cows = np.array(K_cow)\n",
        "y_all    = y_per_cow.loc[all_cows].values\n",
        "\n",
        "sgkf = StratifiedGroupKFold(n_splits=KFOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for rep in range(1, REPEATS + 1):\n",
        "    for fold, (tr_idx, va_idx) in enumerate(\n",
        "        sgkf.split(np.zeros(len(all_cows)), y_all, groups=all_cows),\n",
        "        start=1\n",
        "    ):\n",
        "        cows_tr = all_cows[tr_idx]\n",
        "        cows_va = all_cows[va_idx]\n",
        "\n",
        "        ytr = y_per_cow.loc[cows_tr].values\n",
        "        yva = y_per_cow.loc[cows_va].values\n",
        "\n",
        "        # ----- IMG-only branch -----\n",
        "        Xtr_i = X_img[tr_idx]\n",
        "        Xva_i = X_img[va_idx]\n",
        "\n",
        "        w_pos = 0.5 / max((ytr == 1).mean(), 1e-6)\n",
        "        w_neg = 0.5 / max((ytr == 0).mean(), 1e-6)\n",
        "        w_tr  = np.where(ytr == 1, w_pos, w_neg)\n",
        "\n",
        "        clf_i = LogisticRegression(\n",
        "            max_iter=2000, solver=\"lbfgs\", C=0.5, n_jobs=-1\n",
        "        )\n",
        "        clf_i.fit(Xtr_i, ytr, sample_weight=w_tr)\n",
        "        pva_img = clf_i.predict_proba(Xva_i)[:, 1]\n",
        "\n",
        "        # ----- TAB-only branch (robust, leakage-safe) -----\n",
        "        tr_tab = tab_idx.loc[cows_tr]\n",
        "        va_tab = tab_idx.loc[cows_va]\n",
        "\n",
        "        Xtr_t = tr_tab.drop(columns=[\"y\"]).copy()\n",
        "        Xva_t = va_tab.drop(columns=[\"y\"]).copy()\n",
        "\n",
        "        Xtr_t, Xva_t, kept = drop_leaky_features_train_only(\n",
        "            Xtr_t, ytr, Xva_t,\n",
        "            auc_hi=0.85, rho_hi=0.65, min_non_nan=0.7\n",
        "        )\n",
        "\n",
        "        if Xtr_t.shape[1] > 0 and np.unique(ytr).size >= 2:\n",
        "            scaler_t = StandardScaler().fit(Xtr_t.values)\n",
        "            Xtr_ts = scaler_t.transform(Xtr_t.values)\n",
        "            Xva_ts = scaler_t.transform(Xva_t.values)\n",
        "\n",
        "            w_pos_t = 0.5 / max((ytr == 1).mean(), 1e-6)\n",
        "            w_neg_t = 0.5 / max((ytr == 0).mean(), 1e-6)\n",
        "            wtr_t   = np.where(ytr == 1, w_pos_t, w_neg_t)\n",
        "\n",
        "            clf_t = LogisticRegression(\n",
        "                max_iter=2000, solver=\"lbfgs\", C=0.25, n_jobs=-1\n",
        "            )\n",
        "            clf_t.fit(Xtr_ts, ytr, sample_weight=wtr_t)\n",
        "            pva_tab = clf_t.predict_proba(Xva_ts)[:, 1]\n",
        "        else:\n",
        "            # fallback: predict class prior\n",
        "            pva_tab = np.full_like(yva, fill_value=float((ytr == 1).mean()),\n",
        "                                   dtype=float)\n",
        "\n",
        "        # ----- Feature-level fusion -----\n",
        "        # Concat IMG + TAB (using only kept TAB features)\n",
        "        if Xtr_t.shape[1] > 0:\n",
        "            scaler_f = StandardScaler().fit(\n",
        "                np.hstack([Xtr_i, Xtr_ts])\n",
        "            )\n",
        "            Xtr_f = scaler_f.transform(\n",
        "                np.hstack([Xtr_i, Xtr_ts])\n",
        "            )\n",
        "            # for val, align tab cols\n",
        "            Xva_tab_kept = va_tab[kept] if kept else pd.DataFrame(\n",
        "                np.zeros((len(va_tab), 0))\n",
        "            )\n",
        "            if kept:\n",
        "                Xva_ts2 = scaler_t.transform(Xva_tab_kept.values)\n",
        "                Xva_f = scaler_f.transform(\n",
        "                    np.hstack([Xva_i, Xva_ts2])\n",
        "                )\n",
        "            else:\n",
        "                Xva_f = scaler_f.transform(Xva_i)\n",
        "        else:\n",
        "            scaler_f = StandardScaler().fit(Xtr_i)\n",
        "            Xtr_f = scaler_f.transform(Xtr_i)\n",
        "            Xva_f = scaler_f.transform(Xva_i)\n",
        "\n",
        "        clf_f = LogisticRegression(\n",
        "            max_iter=2000, solver=\"lbfgs\", C=0.5, n_jobs=-1\n",
        "        )\n",
        "        clf_f.fit(Xtr_f, ytr, sample_weight=w_tr)\n",
        "        pva_fus_feat = clf_f.predict_proba(Xva_f)[:, 1]\n",
        "\n",
        "        # ----- Score-level fusion (weight tuned on val AUPRC) -----\n",
        "        weights = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "        best = None\n",
        "        for w in weights:\n",
        "            v = w * ranknorm(pva_tab) + (1.0 - w) * ranknorm(pva_img)\n",
        "            try:\n",
        "                ap = average_precision_score(yva, v)\n",
        "            except Exception:\n",
        "                ap = np.nan\n",
        "            if (best is None) or (ap > best[0]):\n",
        "                best = (ap, w, v)\n",
        "        ap_best, w_star, pva_fus_score = best\n",
        "\n",
        "        # ---------- Store continuous metrics ----------\n",
        "        perf_ablt_rob.append(metrics_cont(f\"IMG\",       yva, pva_img))\n",
        "        perf_ablt_rob.append(metrics_cont(f\"TAB\",       yva, pva_tab))\n",
        "        perf_ablt_rob.append(metrics_cont(f\"FUS_feat\",  yva, pva_fus_feat))\n",
        "        perf_ablt_rob.append(metrics_cont(f\"FUS_score\", yva, pva_fus_score))\n",
        "\n",
        "        # ---------- Store threshold-based metrics (THR) ----------\n",
        "        for branch, probs in [\n",
        "            (\"IMG\",       pva_img),\n",
        "            (\"TAB\",       pva_tab),\n",
        "            (\"FUS_feat\",  pva_fus_feat),\n",
        "            (\"FUS_score\", pva_fus_score),\n",
        "        ]:\n",
        "            perf_thr_rob.append(\n",
        "                metrics_thr(branch, rep, fold, yva, probs, thr=THR)\n",
        "            )\n",
        "\n",
        "# ---------- Summaries: continuous metrics ----------\n",
        "\n",
        "perf_ablt_rob = pd.DataFrame(perf_ablt_rob)\n",
        "\n",
        "def summarize_cont(branch_label):\n",
        "    sub = perf_ablt_rob[perf_ablt_rob[\"name\"] == branch_label]\n",
        "    if sub.empty:\n",
        "        return dict(\n",
        "            branch=branch_label,\n",
        "            AUROC_mean=np.nan, AUROC_ci_lo=np.nan, AUROC_ci_hi=np.nan,\n",
        "            AUPRC_mean=np.nan, AUPRC_ci_lo=np.nan, AUPRC_ci_hi=np.nan,\n",
        "            Brier_mean=np.nan, Brier_ci_lo=np.nan, Brier_ci_hi=np.nan,\n",
        "            folds=0\n",
        "        )\n",
        "    auc_m, auc_lo, auc_hi = t_ci(sub[\"AUROC\"], alpha=0.05, clip01=True)\n",
        "    ap_m,  ap_lo,  ap_hi  = t_ci(sub[\"AUPRC\"], alpha=0.05, clip01=True)\n",
        "    br_m,  br_lo,  br_hi  = t_ci(sub[\"Brier\"], alpha=0.05, clip01=False)\n",
        "    return dict(\n",
        "        branch=branch_label,\n",
        "        AUROC_mean=auc_m, AUROC_ci_lo=auc_lo, AUROC_ci_hi=auc_hi,\n",
        "        AUPRC_mean=ap_m,  AUPRC_ci_lo=ap_lo,  AUPRC_ci_hi=ap_hi,\n",
        "        Brier_mean=br_m,  Brier_ci_lo=br_lo,  Brier_ci_hi=br_hi,\n",
        "        folds=len(sub)\n",
        "    )\n",
        "\n",
        "summary_cont = pd.DataFrame([\n",
        "    summarize_cont(\"IMG\"),\n",
        "    summarize_cont(\"TAB\"),\n",
        "    summarize_cont(\"FUS_feat\"),\n",
        "    summarize_cont(\"FUS_score\"),\n",
        "])\n",
        "\n",
        "print(\"\\n=== Ablation (ROBUST TAB) — continuous metrics (t-based 95% CI) ===\")\n",
        "print(summary_cont.to_string(index=False))\n",
        "\n",
        "out_cont = os.path.join(SAVE_DIR, \"cv_fusion_ablation_summary_robusttab_t95.csv\")\n",
        "summary_cont.to_csv(out_cont, index=False)\n",
        "print(f\"\\n[Saved] → {out_cont}\")\n",
        "\n",
        "# ---------- Summaries: threshold-based (Acc/Prec/Rec/F1) ----------\n",
        "\n",
        "perf_thr_rob = pd.DataFrame(perf_thr_rob)\n",
        "\n",
        "def summarize_thr(branch_label):\n",
        "    sub = perf_thr_rob[perf_thr_rob[\"branch\"] == branch_label]\n",
        "    if sub.empty:\n",
        "        return dict(\n",
        "            branch=branch_label,\n",
        "            Acc_mean=np.nan, Acc_ci_lo=np.nan, Acc_ci_hi=np.nan,\n",
        "            Prec_mean=np.nan, Prec_ci_lo=np.nan, Prec_ci_hi=np.nan,\n",
        "            Rec_mean=np.nan,  Rec_ci_lo=np.nan,  Rec_ci_hi=np.nan,\n",
        "            F1_mean=np.nan,   F1_ci_lo=np.nan,   F1_ci_hi=np.nan,\n",
        "            folds=0\n",
        "        )\n",
        "    acc_m, acc_lo, acc_hi = t_ci(sub[\"Acc\"],  alpha=0.05, clip01=True)\n",
        "    pr_m,  pr_lo,  pr_hi  = t_ci(sub[\"Prec\"], alpha=0.05, clip01=True)\n",
        "    rc_m,  rc_lo,  rc_hi  = t_ci(sub[\"Rec\"],  alpha=0.05, clip01=True)\n",
        "    f1_m,  f1_lo,  f1_hi  = t_ci(sub[\"F1\"],   alpha=0.05, clip01=True)\n",
        "    return dict(\n",
        "        branch=branch_label,\n",
        "        Acc_mean=acc_m, Acc_ci_lo=acc_lo, Acc_ci_hi=acc_hi,\n",
        "        Prec_mean=pr_m, Prec_ci_lo=pr_lo, Prec_ci_hi=pr_hi,\n",
        "        Rec_mean=rc_m,  Rec_ci_lo=rc_lo,  Rec_ci_hi=rc_hi,\n",
        "        F1_mean=f1_m,   F1_ci_lo=f1_lo,   F1_ci_hi=f1_hi,\n",
        "        folds=len(sub)\n",
        "    )\n",
        "\n",
        "summary_thr = pd.DataFrame([\n",
        "    summarize_thr(\"IMG\"),\n",
        "    summarize_thr(\"TAB\"),\n",
        "    summarize_thr(\"FUS_feat\"),\n",
        "    summarize_thr(\"FUS_score\"),\n",
        "])\n",
        "\n",
        "print(\"\\n=== Ablation (ROBUST TAB) — threshold metrics at thr=0.5 (t-based 95% CI) ===\")\n",
        "print(summary_thr.to_string(index=False))\n",
        "\n",
        "out_thr = os.path.join(SAVE_DIR, \"cv_fusion_ablation_thresholdmetrics_t95.csv\")\n",
        "summary_thr.to_csv(out_thr, index=False)\n",
        "print(f\"\\n[Saved] → {out_thr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoD9oeyrIDYl",
        "outputId": "1528e430-1f3e-4897-dd40-b695afcb198e"
      },
      "id": "WoD9oeyrIDYl",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Ablation (ROBUST TAB) — continuous metrics (t-based 95% CI) ===\n",
            "   branch  AUROC_mean  AUROC_ci_lo  AUROC_ci_hi  AUPRC_mean  AUPRC_ci_lo  AUPRC_ci_hi  Brier_mean  Brier_ci_lo  Brier_ci_hi  folds\n",
            "      IMG    0.860952     0.819777     0.902128    0.808214     0.762359     0.854070    0.176892     0.146114     0.207670     15\n",
            "      TAB    0.456508     0.275903     0.637113    0.457038     0.351918     0.562158    0.288664     0.256208     0.321121     15\n",
            " FUS_feat    0.878413     0.842429     0.914396    0.836548     0.790383     0.882712    0.155573     0.132388     0.178757     15\n",
            "FUS_score    0.892063     0.848013     0.936114    0.860437     0.811329     0.909544    0.164983     0.149044     0.180921     15\n",
            "\n",
            "[Saved] → /content/mastitis_outputs/cv_fusion_ablation_summary_robusttab_t95.csv\n",
            "\n",
            "=== Ablation (ROBUST TAB) — threshold metrics at thr=0.5 (t-based 95% CI) ===\n",
            "   branch  Acc_mean  Acc_ci_lo  Acc_ci_hi  Prec_mean  Prec_ci_lo  Prec_ci_hi  Rec_mean  Rec_ci_lo  Rec_ci_hi  F1_mean  F1_ci_lo  F1_ci_hi  folds\n",
            "      IMG  0.732051   0.681110   0.782993   0.640000    0.565108    0.714892  0.633333   0.506577   0.760089 0.608629  0.531358  0.685900     15\n",
            "      TAB  0.403846   0.316203   0.491489   0.126667    0.037527    0.215806  0.350000   0.100115   0.599885 0.185714  0.054680  0.316749     15\n",
            " FUS_feat  0.780769   0.761547   0.799991   0.726667    0.631197    0.822136  0.733333   0.603729   0.862938 0.686407  0.643070  0.729743     15\n",
            "FUS_score  0.748718   0.694990   0.802446   0.604762    0.519478    0.690046  0.883333   0.800038   0.966628 0.703403  0.634821  0.771986     15\n",
            "\n",
            "[Saved] → /content/mastitis_outputs/cv_fusion_ablation_thresholdmetrics_t95.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# Cell — Add classification metrics to SIM2 semi-synthetic test\n",
        "#\n",
        "# Requires:\n",
        "#   - y_sim, p_img_sim, p_tab_sim, p_fus_sim from SIM2 cell\n",
        "#   - sim2_metrics (AUROC, AUPRC, Brier, N, pos)\n",
        "#\n",
        "# Outputs:\n",
        "#   - Prints table with Acc / Prec / Rec / F1 at thr=0.5\n",
        "#   - Saves:\n",
        "#       sim_fusion_sanity_metrics_revised_with_cls.csv\n",
        "# ================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ---- Guards ----\n",
        "need = [\"y_sim\", \"p_img_sim\", \"p_tab_sim\", \"p_fus_sim\", \"sim2_metrics\"]\n",
        "missing = [n for n in need if n not in globals()]\n",
        "if missing:\n",
        "    raise SystemExit(f\"[SIM2-CLS][STOP] Missing: {missing}. Run the SIM2 cell first.\")\n",
        "\n",
        "if \"SAVE_DIR\" not in globals():\n",
        "    SAVE_DIR = \"/content/mastitis_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "def cls_metrics(y_true, p_pred, thr=0.5):\n",
        "    \"\"\"Compute confusion-based metrics at a fixed threshold.\"\"\"\n",
        "    y_true = np.asarray(y_true, int)\n",
        "    p_pred = np.asarray(p_pred, float)\n",
        "\n",
        "    y_hat = (p_pred >= thr).astype(int)\n",
        "\n",
        "    TP = int(((y_true == 1) & (y_hat == 1)).sum())\n",
        "    TN = int(((y_true == 0) & (y_hat == 0)).sum())\n",
        "    FP = int(((y_true == 0) & (y_hat == 1)).sum())\n",
        "    FN = int(((y_true == 1) & (y_hat == 0)).sum())\n",
        "\n",
        "    total = TP + TN + FP + FN\n",
        "    acc  = (TP + TN) / total if total > 0 else np.nan\n",
        "    prec = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    rec  = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1   = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
        "\n",
        "    return dict(\n",
        "        TP=TP, TN=TN, FP=FP, FN=FN,\n",
        "        Accuracy=acc,\n",
        "        Precision=prec,\n",
        "        Recall=rec,\n",
        "        F1=f1\n",
        "    )\n",
        "\n",
        "rows = []\n",
        "for name, preds in [\n",
        "    (\"IMG_only\",       p_img_sim),\n",
        "    (\"TAB_only\",       p_tab_sim),\n",
        "    (\"FUS_score_w0.5\", p_fus_sim),\n",
        "]:\n",
        "    m = cls_metrics(y_sim, preds, thr=0.5)\n",
        "    m[\"branch\"] = name\n",
        "    rows.append(m)\n",
        "\n",
        "sim2_cls = pd.DataFrame(rows)\n",
        "\n",
        "# Merge with original AUROC/AUPRC/Brier table (sim2_metrics)\n",
        "sim2_full = sim2_metrics.merge(sim2_cls, on=\"branch\", how=\"left\")\n",
        "\n",
        "# Pretty print\n",
        "print(\"\\n[SIM2-CLS] Semi-synthetic evaluation with classification metrics at thr=0.5:\")\n",
        "print(sim2_full.to_string(index=False))\n",
        "\n",
        "# Save\n",
        "out_path = os.path.join(SAVE_DIR, \"sim_fusion_sanity_metrics_revised_with_cls.csv\")\n",
        "sim2_full.to_csv(out_path, index=False)\n",
        "print(f\"\\n[SIM2-CLS] Saved → {out_path}\")\n",
        "print(\"[SIM2-CLS] NOTE: Use this table only as an illustrative, semi-synthetic sanity check.\")\n"
      ],
      "metadata": {
        "id": "S0jzrhLSNvMO",
        "outputId": "2468303f-a820-4099-e16d-d6a9a1232c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S0jzrhLSNvMO",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SIM2-CLS] Semi-synthetic evaluation with classification metrics at thr=0.5:\n",
            "        branch    AUROC    AUPRC    Brier    N  pos  TP  TN  FP  FN  Accuracy  Precision   Recall       F1\n",
            "      IMG_only 0.971562 0.940730 0.064085 1000  358 328 588  54  30     0.916   0.858639 0.916201 0.886486\n",
            "      TAB_only 0.558054 0.355744 0.282839 1000  358 199 331 311 159     0.530   0.390196 0.555866 0.458525\n",
            "FUS_score_w0.5 0.872716 0.796975 0.171002 1000  358 300 446 196  58     0.746   0.604839 0.837989 0.702576\n",
            "\n",
            "[SIM2-CLS] Saved → /content/mastitis_outputs/sim_fusion_sanity_metrics_revised_with_cls.csv\n",
            "[SIM2-CLS] NOTE: Use this table only as an illustrative, semi-synthetic sanity check.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48c332fdd75849e4ae73a82d87bdfa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16ff3847811746dfaf5f19d22a15d85a",
              "IPY_MODEL_4541a4aa5d434905897ee26c5513caaf",
              "IPY_MODEL_cb7ff0fb84094d2a8a5b2fe1162c7beb"
            ],
            "layout": "IPY_MODEL_9201331d59c74636b13ccb9782252b3a"
          }
        },
        "16ff3847811746dfaf5f19d22a15d85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8da2569d16124583830c32a3989ff285",
            "placeholder": "​",
            "style": "IPY_MODEL_d8d2e5e99572406db34741735e51ee0b",
            "value": "Parse YOLO labels: 100%"
          }
        },
        "4541a4aa5d434905897ee26c5513caaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18ef2080bbd488baed4485d8eee1891",
            "max": 130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5435c36dcfc429fae4c63e4ebd9db66",
            "value": 130
          }
        },
        "cb7ff0fb84094d2a8a5b2fe1162c7beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521c41f6749d4e6abcb9f638f9f8da09",
            "placeholder": "​",
            "style": "IPY_MODEL_229f3112dd264b398dd2c2e3215c19c3",
            "value": " 130/130 [00:02&lt;00:00, 99.01it/s]"
          }
        },
        "9201331d59c74636b13ccb9782252b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da2569d16124583830c32a3989ff285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d2e5e99572406db34741735e51ee0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c18ef2080bbd488baed4485d8eee1891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5435c36dcfc429fae4c63e4ebd9db66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "521c41f6749d4e6abcb9f638f9f8da09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229f3112dd264b398dd2c2e3215c19c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c39040796a34a268e69adbbf02108a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_239c642f43104e6ca670491276fda626",
              "IPY_MODEL_43becd1cddc1429d8d9932b9c17a6434",
              "IPY_MODEL_ff4480803c5545bf9b620a9995d3e4b2"
            ],
            "layout": "IPY_MODEL_eb50c150cb364943815a5d9bfc3da2b0"
          }
        },
        "239c642f43104e6ca670491276fda626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce6232d00bb4e179233578d6e158c9b",
            "placeholder": "​",
            "style": "IPY_MODEL_0237a153a2614f1883b8c5cdbe1500c8",
            "value": "Emb TR: 100%"
          }
        },
        "43becd1cddc1429d8d9932b9c17a6434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4737a3e65be94e33a2b912cfb5a90423",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee9671ba9b7f432991ec0ea0a939ed4f",
            "value": 1
          }
        },
        "ff4480803c5545bf9b620a9995d3e4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96209a2c9209408dbce4315faaa5dfab",
            "placeholder": "​",
            "style": "IPY_MODEL_0a37e33be3f94614b8efcf66d0045177",
            "value": " 1/1 [00:41&lt;00:00, 41.85s/it]"
          }
        },
        "eb50c150cb364943815a5d9bfc3da2b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce6232d00bb4e179233578d6e158c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0237a153a2614f1883b8c5cdbe1500c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4737a3e65be94e33a2b912cfb5a90423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee9671ba9b7f432991ec0ea0a939ed4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96209a2c9209408dbce4315faaa5dfab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a37e33be3f94614b8efcf66d0045177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5679757fc4e1424aaa941c479c79307d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f60e8965a2fe4edc9a78f4fb74dd9279",
              "IPY_MODEL_54d3892f2d0746de82ef203aa97fbf5d",
              "IPY_MODEL_f374477d0e9c424f9c69a2ac73e5f0f8"
            ],
            "layout": "IPY_MODEL_5d4e16e725b743a2b971d16dc41dabbd"
          }
        },
        "f60e8965a2fe4edc9a78f4fb74dd9279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bd5aba3e54c4befb6bf1d3713314497",
            "placeholder": "​",
            "style": "IPY_MODEL_3f4f60067148454496d2ba7dddf0c160",
            "value": "Emb VA: 100%"
          }
        },
        "54d3892f2d0746de82ef203aa97fbf5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70f7efd2a87141fb8e63315325ad7901",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24a1f376075d4906871ce05f1510f558",
            "value": 1
          }
        },
        "f374477d0e9c424f9c69a2ac73e5f0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_766005da7a804a6fb573695914632481",
            "placeholder": "​",
            "style": "IPY_MODEL_dd3b3aebb6494fa4a5e232d0bb134ec7",
            "value": " 1/1 [00:08&lt;00:00,  8.88s/it]"
          }
        },
        "5d4e16e725b743a2b971d16dc41dabbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bd5aba3e54c4befb6bf1d3713314497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f4f60067148454496d2ba7dddf0c160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70f7efd2a87141fb8e63315325ad7901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a1f376075d4906871ce05f1510f558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "766005da7a804a6fb573695914632481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd3b3aebb6494fa4a5e232d0bb134ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68ab30e6d00f4d30b637116b8fe1d83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abfb9e9ab1364758a338d10cef0f548f",
              "IPY_MODEL_1edb69ab9e954690899eddadc8f24b65",
              "IPY_MODEL_11f919e642e94060bb6afcd7059c36a9"
            ],
            "layout": "IPY_MODEL_e38b73c45f9045d3a7b8d1e2528a947f"
          }
        },
        "abfb9e9ab1364758a338d10cef0f548f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0643f64cac8405298ef8cebfe97fc95",
            "placeholder": "​",
            "style": "IPY_MODEL_9b850bac628c45a4a0858323cf4668fa",
            "value": "Emb TE: 100%"
          }
        },
        "1edb69ab9e954690899eddadc8f24b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_795f4048465542ba87e1ed6f5d1e1357",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_481bdc833aaf499eb2b4cb8860964b5d",
            "value": 1
          }
        },
        "11f919e642e94060bb6afcd7059c36a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d982fe8fc94dda99cff7f4746a004d",
            "placeholder": "​",
            "style": "IPY_MODEL_1bbc389bff8f4726822f7dbc1a5dad40",
            "value": " 1/1 [00:09&lt;00:00,  9.46s/it]"
          }
        },
        "e38b73c45f9045d3a7b8d1e2528a947f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0643f64cac8405298ef8cebfe97fc95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b850bac628c45a4a0858323cf4668fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "795f4048465542ba87e1ed6f5d1e1357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "481bdc833aaf499eb2b4cb8860964b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5d982fe8fc94dda99cff7f4746a004d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bbc389bff8f4726822f7dbc1a5dad40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65dbf7c585d4476b850c127eb50a4420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5bd3283596c4cd7a37bc5e4f31f8789",
              "IPY_MODEL_04bb9b21fd354e5390533df7ac77dbf9",
              "IPY_MODEL_3e517f40a9dc4568ab908a7cc2580103"
            ],
            "layout": "IPY_MODEL_b749c03b694d413c9989323d74fe834c"
          }
        },
        "a5bd3283596c4cd7a37bc5e4f31f8789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1cc2d6a317421782b8fb08aa88bedc",
            "placeholder": "​",
            "style": "IPY_MODEL_c16a33e7f672450faf6b1af95ea41825",
            "value": "Embeddings: 100%"
          }
        },
        "04bb9b21fd354e5390533df7ac77dbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5505eed872ca4baa84a2075d37d31427",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_265a0f8bc14746dfba15114e0511c098",
            "value": 1
          }
        },
        "3e517f40a9dc4568ab908a7cc2580103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ee5f5e46c7843b6a05e49b9ae6b9870",
            "placeholder": "​",
            "style": "IPY_MODEL_0c3a9e288e3c43a48c4e3a3a62a3327f",
            "value": " 1/1 [00:01&lt;00:00,  1.79s/it]"
          }
        },
        "b749c03b694d413c9989323d74fe834c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce1cc2d6a317421782b8fb08aa88bedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16a33e7f672450faf6b1af95ea41825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5505eed872ca4baa84a2075d37d31427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265a0f8bc14746dfba15114e0511c098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ee5f5e46c7843b6a05e49b9ae6b9870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c3a9e288e3c43a48c4e3a3a62a3327f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}